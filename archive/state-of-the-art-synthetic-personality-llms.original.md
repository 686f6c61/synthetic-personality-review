# ESTADO DEL ARTE. LA PERSONALIDAD SINTÉTICA: EVALUACIÓN PSICOLÓGICA DE MODELOS DE LENGUAJE (LLMs)

---

## Artículos

<a id="article-1"></a>

### Artículo 1

**Título original:** Personality Traits in Large Language Models

**Categoría:** Evaluación y validación psicométrica

**Año:** 2023 | **Idioma:** Inglés

**Autores:** Greg Serapio-García, Mustafa Safdari, Clément Crepy, Luning Sun, Stephen Fitz, Peter Romero, Marwa Abdulhai, Aleksandra Faust, Maja Matarić

**Keywords:** Computation and Language, Artificial Intelligence, Computers and Society, Human-Computer Interaction

**URL:** https://arxiv.org/abs/2307.00184

#### Abstract (English)

Large language models have revolutionized natural language processing by enabling coherent and contextually relevant text generation. As these models increasingly power conversational agents, understanding and controlling their synthetic personality traits becomes critical. We present a comprehensive psychometrically valid methodology for administering personality tests to LLMs and shaping personality expression in generated text. Applying this method to 18 LLMs reveals that personality measurements are reliable and valid under specific prompting configurations, with stronger evidence in larger instruction-tuned models. The methodology successfully shapes LLM personality along desired dimensions to mimic specific human profiles, with implications for responsible AI deployment.

#### Resumen (Español)

Los modelos de lenguaje de gran escala han transformado el procesamiento del lenguaje natural mediante la generación de texto coherente y contextualmente relevante. Dado que estos modelos sustentan agentes conversacionales de uso público masivo, resulta crucial comprender y controlar los rasgos de personalidad sintéticos que exhiben. Se presenta una metodología psicométrica válida y fiable para administrar inventarios de personalidad a estos modelos y modular la expresión de rasgos en el texto generado. La aplicación del método a 18 modelos revela que las mediciones de personalidad resultan fiables y válidas bajo configuraciones específicas de instrucción, con evidencia más robusta en modelos de mayor escala refinados mediante ajuste instruccional. La metodología permite modular la personalidad de los modelos según dimensiones deseadas para reproducir perfiles humanos específicos, con implicaciones para el despliegue responsable de sistemas de inteligencia artificial.

---

<a id="article-2"></a>

### Artículo 2

**Título original:** PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Hang Jiang, Xiajie Zhang, Xubo Cao, Cynthia Breazeal, Deb Roy, Jad Kabbara

**Keywords:** Computation and Language, Artificial Intelligence, Human-Computer Interaction, Big Five personality model

**URL:** https://arxiv.org/abs/2305.02547

#### Abstract (English)

Despite numerous applications of LLMs for personalized chatbots, limited research evaluates whether these models generate content aligned with assigned personality profiles. We simulate distinct LLM personas based on the Big Five model, administering the 44-item Big Five Inventory and story writing tasks. Self-reported BFI scores demonstrate consistency with designated personality types, exhibiting large effect sizes across five traits. Generated writings display emerging linguistic patterns representative of personality traits when compared with human corpora. Human evaluators perceive personality traits with up to 80% accuracy, though accuracy decreases significantly when AI authorship is disclosed.

#### Resumen (Español)

Pese a las múltiples aplicaciones de los modelos de lenguaje de gran escala en el desarrollo de agentes conversacionales personalizados, existe investigación limitada que evalúe si estos modelos generan contenido alineado con perfiles de personalidad asignados. Se simulan personas LLM diferenciadas basadas en el modelo Big Five, administrando el inventario Big Five de 44 ítems y tareas de redacción narrativa. Las puntuaciones autoevaluadas en el BFI muestran coherencia con los tipos de personalidad designados, con tamaños de efecto elevados en los cinco rasgos. Los textos generados exhiben patrones lingüísticos emergentes representativos de rasgos de personalidad en comparación con corpus humanos. Evaluadores humanos perciben los rasgos de personalidad con precisión de hasta 80%, aunque esta disminuye significativamente cuando se revela la autoría artificial.

---

<a id="article-3"></a>

### Artículo 3

**Título original:** LLMs Simulate Big Five Personality Traits: Further Evidence

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Aleksandra Sorokovikova, Natalia Fedorova, Sharwin Rezagholi, Ivan P. Yamshchikov

**Keywords:** Computation and Language, Artificial Intelligence, Big Five personality traits, Large Language Models

**URL:** https://arxiv.org/abs/2402.01765

#### Abstract (English)

We present an empirical investigation into Big Five personality trait simulation by Llama2, GPT-4, and Mixtral. The study analyzes simulated personality traits and their temporal stability across models, contributing to understanding LLM capabilities for personality trait simulation and implications for personalized human-computer interaction.

#### Resumen (Español)

Se presenta una investigación empírica sobre la simulación de rasgos de personalidad Big Five en los modelos Llama2, GPT-4 y Mixtral. El estudio analiza los rasgos de personalidad simulados por estos modelos y su estabilidad temporal, contribuyendo a la comprensión de las capacidades de estos sistemas para simular rasgos de personalidad y sus implicaciones para la interacción persona-computadora personalizada.

---

<a id="article-4"></a>

### Artículo 4

**Título original:** Evaluating and Inducing Personality in Pre-trained Language Models

**Categoría:** Inducción y control de personalidad

**Año:** 2023 | **Idioma:** Inglés

**Autores:** Guangyuan Jiang, Manjie Xu, Song-Chun Zhu, Wenjuan Han, Chi Zhang, Yixin Zhu

**Keywords:** Language Models, Personality Assessment, Machine Behavior, Psychometric Studies, Big Five, Machine Personality Inventory (MPI)

**URL:** https://proceedings.neurips.cc/paper_files/paper/2023/hash/21f7b745f73ce0d1f9bcea7f40b1388e-Abstract-Conference.html

#### Abstract (English)

Standardized and quantified evaluation of machine behaviors constitutes a fundamental challenge in understanding LLMs. We introduce the Machine Personality Inventory (MPI), a tool grounded in Big Five Personality Factors theory for principled quantitative assessment of language model behaviors. Systematic evaluation with MPI provides evidence of its efficacy in characterizing LLM behaviors. We propose Personality Prompting (P²), a method enabling controlled induction of specific personalities, generating diverse and verifiable behavioral outputs. This work advocates personality assessment as a key indicator for evaluating machine behaviors across downstream applications.

#### Resumen (Español)

La evaluación estandarizada y cuantificada de comportamientos en sistemas artificiales constituye un desafío fundamental para comprender los modelos de lenguaje de gran escala. Se introduce el Inventario de Personalidad de Máquinas (MPI), una herramienta fundamentada en la teoría de los Cinco Grandes Factores de Personalidad para la evaluación cuantitativa y principista de comportamientos en modelos de lenguaje. La evaluación sistemática mediante MPI proporciona evidencia de su eficacia para caracterizar comportamientos. Se propone el método de Inducción de Personalidad mediante Instrucciones (P²), que permite la inducción controlada de personalidades específicas, generando salidas conductuales diversas y verificables. El trabajo propugna la evaluación de personalidad como indicador clave para evaluar comportamientos en aplicaciones posteriores.

---

<a id="article-5"></a>

### Artículo 5

**Título original:** Evaluating and Inducing Personality in Pre-trained Language Models

**Categoría:** Inducción y control de personalidad

**Año:** 2023 | **Idioma:** Inglés

**Autores:** Guangyuan Jiang, Manjie Xu, Song-Chun Zhu, Wenjuan Han, Chi Zhang, Yixin Zhu

**Keywords:** Language Models, Personality Assessment, Machine Behavior, Psychometric Studies, Big Five

**URL:** https://openreview.net/forum?id=I9xE1Jsjfx

#### Abstract (English)

Standardized and quantified evaluation of machine behaviors constitutes a fundamental challenge in understanding LLMs. We introduce the Machine Personality Inventory (MPI), a tool grounded in Big Five Personality Factors theory for principled quantitative assessment of language model behaviors. Systematic evaluation with MPI provides evidence of its efficacy in characterizing LLM behaviors. We propose Personality Prompting (P²), a method enabling controlled induction of specific personalities, generating diverse and verifiable behavioral outputs.

#### Resumen (Español)

La evaluación estandarizada y cuantificada de comportamientos en sistemas artificiales constituye un desafío fundamental para comprender los modelos de lenguaje de gran escala. Se introduce el Inventario de Personalidad de Máquinas (MPI), una herramienta fundamentada en la teoría de los Cinco Grandes Factores de Personalidad para la evaluación cuantitativa y principista de comportamientos en modelos de lenguaje. La evaluación sistemática mediante MPI proporciona evidencia de su eficacia para caracterizar comportamientos. Se propone el método de Inducción de Personalidad mediante Instrucciones (P²), que permite la inducción controlada de personalidades específicas, generando salidas conductuales diversas y verificables.

---

<a id="article-6"></a>

### Artículo 6

**Título original:** BIG5-CHAT: Shaping LLM Personalities Through Training on Human-Grounded Data

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Wenkai Li, Jiarui Liu, Andy Liu, Xuhui Zhou, Mona Diab, Maarten Sap

**Keywords:** Computation and Language, Personality traits, Human-grounded data, Personality assessment

**URL:** https://arxiv.org/abs/2410.16491

#### Abstract (English)

Embedding realistic human personality traits in LLMs remains challenging. Previous prompt-based approaches describing desired personality behaviors suffer from realism and validity issues. We introduce BIG5-CHAT, a large-scale dataset containing 100,000 dialogues grounding models in authentic human personality expression patterns. Leveraging this dataset, we explore Supervised Fine-Tuning and Direct Preference Optimization as training methods to align LLMs with human personality patterns. Our methods outperform prompting on personality assessments including BFI and IPIP-NEO, with trait correlations more closely matching human data. Experiments reveal models trained toward higher conscientiousness, agreeableness, lower extraversion, and lower neuroticism exhibit superior reasoning performance, consistent with psychological findings on these traits' cognitive impact.

#### Resumen (Español)

La incorporación de rasgos de personalidad humana realistas en modelos de lenguaje de gran escala constituye un desafío considerable. Los enfoques previos basados en instrucciones que describen comportamientos asociados a rasgos deseados adolecen de problemas de realismo y validez. Se introduce BIG5-CHAT, un conjunto de datos a gran escala con 100,000 diálogos que fundamentan los modelos en patrones auténticos de expresión de personalidad humana. Mediante este conjunto de datos se exploran el ajuste fino supervisado y la optimización directa de preferencias como métodos de entrenamiento para alinear los modelos con patrones de personalidad humana. Los métodos propuestos superan la inducción mediante instrucciones en evaluaciones de personalidad como BFI e IPIP-NEO, con correlaciones de rasgos que se aproximan más a datos humanos. Los experimentos revelan que los modelos entrenados hacia mayor responsabilidad, amabilidad, menor extraversión y menor neuroticismo exhiben desempeño superior en razonamiento, coherente con evidencia psicológica sobre el impacto cognitivo de estos rasgos.

---

<a id="article-7"></a>

### Artículo 7

**Título original:** BIG5-CHAT: Shaping LLM Personalities Through Training on Human-Grounded Data

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Wenkai Li, Jiarui Liu, Andy Liu, Xuhui Zhou, Mona Diab, Maarten Sap

**Keywords:** Computation and Language, Personality traits, Human-grounded data

**URL:** https://openreview.net/forum?id=TqwTzLjzGS

#### Abstract (English)

Embedding realistic human personality traits in LLMs remains challenging. We introduce BIG5-CHAT, a large-scale dataset containing 100,000 dialogues grounding models in authentic human personality expression patterns. Training-based methods explored here align LLMs with human personality patterns, outperforming prompting on personality assessments. Experiments reveal models trained to exhibit certain traits display superior reasoning performance, consistent with psychological findings.

#### Resumen (Español)

La incorporación de rasgos de personalidad humana realistas en modelos de lenguaje de gran escala constituye un desafío considerable. Se introduce BIG5-CHAT, un conjunto de datos a gran escala con 100,000 diálogos que fundamentan los modelos en patrones auténticos de expresión de personalidad humana. Los métodos de entrenamiento explorados alinean los modelos con patrones de personalidad humana, superando la inducción mediante instrucciones en evaluaciones de personalidad. Los experimentos revelan que los modelos entrenados para exhibir ciertos rasgos muestran desempeño superior en razonamiento, coherente con evidencia psicológica.

---

<a id="article-8"></a>

### Artículo 8

**Título original:** On the Reliability of Psychological Scales on Large Language Models

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Jen-tse Huang, Wenxiang Jiao, Man Ho Lam, Eric John Li, Wenxuan Wang, Michael Lyu

**Keywords:** Large Language Models, Psychological assessment, Personality traits, Big Five Inventory, Personality emulation

**URL:** https://aclanthology.org/2024.emnlp-main.354/

#### Abstract (English)

Determining the reliability of personality assessments applied to LLMs remains a fundamental methodological question. Analysis across 2,500 configuration settings per model reveals various LLMs demonstrate response consistency on the Big Five Inventory, indicating satisfactory reliability levels. The research further explores GPT-3.5's capacity to emulate diverse personality profiles and represent distinct demographic groups through targeted instruction configurations.

#### Resumen (Español)

La determinación de la fiabilidad de evaluaciones de personalidad aplicadas a modelos de lenguaje de gran escala constituye una cuestión metodológica fundamental. El análisis de 2,500 configuraciones por modelo revela que diversos modelos demuestran coherencia en las respuestas al Inventario Big Five, indicando niveles satisfactorios de fiabilidad. La investigación explora además la capacidad de GPT-3.5 para emular perfiles de personalidad diversos y representar grupos demográficos diferenciados mediante configuraciones de instrucciones específicas.

---

<a id="article-9"></a>

### Artículo 9

**Título original:** Manipulating the Perceived Personality Traits of Language Models

**Categoría:** Inducción y control de personalidad

**Año:** 2023 | **Idioma:** Inglés

**Autores:** Graham Caron, Shashank Srivastava

**Keywords:** Personality traits, Big Five personality model, Language models, Dialog systems, Computational psychology

**URL:** https://aclanthology.org/2023.findings-emnlp.156/

#### Abstract (English)

We explore whether LLM-generated text exhibits consistency in perceived Big Five personality traits. When exposed to diverse contexts including personality descriptions and diagnostic questionnaires, language models consistently identify and reflect personality markers. This demonstrates predictable malleability, with correlations reaching 0.84 between intended and realized personality shifts.

#### Resumen (Español)

Se explora si el texto generado por modelos de lenguaje de gran escala exhibe coherencia en los rasgos de personalidad Big Five percibidos. Cuando se exponen a contextos diversos que incluyen descripciones de personalidad y cuestionarios diagnósticos, los modelos de lenguaje identifican y reflejan de forma coherente marcadores de personalidad. Esto demuestra maleabilidad predecible, con correlaciones que alcanzan 0.84 entre cambios de personalidad pretendidos y realizados.

---

<a id="article-10"></a>

### Artículo 10

**Título original:** Who is GPT-3? An Exploration of Personality, Values and Demographics

**Categoría:** Evaluación y validación psicométrica

**Año:** 2022 | **Idioma:** Inglés

**Autores:** Marilù Miotto, Nicola Rossberg, Bennett Kleinberg

**Keywords:** Language models, GPT-3, Psychological assessment, Personality traits, Computational social science

**URL:** https://aclanthology.org/2022.nlpcss-1.24/

#### Abstract (English)

We administer two validated psychometric instruments to GPT-3 for assessing personality, values, and self-reported demographics. Results demonstrate GPT-3 scores comparably to human samples regarding personality and values when provided with response memory. This constitutes the first empirical psychological assessment of the GPT-3 model.

#### Resumen (Español)

Se administran dos instrumentos psicométricos validados a GPT-3 para evaluar personalidad, valores y demografía autorreportada. Los resultados demuestran que GPT-3 puntúa de forma comparable a muestras humanas respecto a personalidad y valores cuando se le proporciona memoria de respuestas. Esto constituye la primera evaluación psicológica empírica del modelo GPT-3.

---

<a id="article-11"></a>

### Artículo 11

**Título original:** Systematic Assessment of GPT-3 for Zero-Shot Personality Estimation

**Categoría:** Evaluación y validación psicométrica

**Año:** 2023 | **Idioma:** Inglés

**Autores:** Adithya V Ganesan, Yash Kumar Lal, August Nilsson, H. Andrew Schwartz

**Keywords:** Large Language Models, Zero-shot learning, Personality trait estimation, Big 5 personality traits, NLP

**URL:** https://aclanthology.org/2023.wassa-1.34/

#### Abstract (English)

We investigate GPT-3's zero-shot capacity to estimate Big Five personality traits from social media posts. Systematic experiments reveal zero-shot GPT-3 performance approximates existing pretrained models for coarse-grained classification, though performance degrades to near-baseline levels for fine-grained classification. The study analyzes performance differentials between GPT-3 and pretrained lexical models across classification granularities.

#### Resumen (Español)

Se investiga la capacidad sin entrenamiento previo de GPT-3 para estimar rasgos de personalidad Big Five desde publicaciones en redes sociales. Los experimentos sistemáticos revelan que el desempeño sin entrenamiento previo de GPT-3 se aproxima a modelos preentrenados existentes para clasificación de grano grueso, aunque el desempeño se degrada a niveles cercanos a la línea base para clasificación de grano fino. El estudio analiza diferenciales de desempeño entre GPT-3 y modelos léxicos preentrenados a través de granularidades de clasificación.

---

<a id="article-12"></a>

### Artículo 12

**Título original:** AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Max Pellert, Clemens M Lechner, Claudia Wagner, Beatrice Rammstedt, Markus Strohmaier

**Keywords:** Artificial intelligence, Psychometrics, Natural language processing, Personality, Values, Moral foundations, Gender diversity beliefs

**URL:** https://pmc.ncbi.nlm.nih.gov/articles/PMC11373167/

#### Abstract (English)

Standard psychometric inventories can be repurposed as diagnostic instruments for evaluating psychological traits in LLMs. These models inadvertently acquire psychological characteristics from vast training corpora. Eliciting LLM responses to psychometric inventories enables researchers to characterize their latent traits. We demonstrate zero-shot classification methodologies across multiple LLMs and established psychometric instruments.

#### Resumen (Español)

Los inventarios psicométricos estándar pueden reutilizarse como instrumentos diagnósticos para evaluar rasgos psicológicos en modelos de lenguaje de gran escala. Estos modelos adquieren de forma inadvertida características psicológicas desde los amplios corpus de entrenamiento. Obtener respuestas de los modelos a inventarios psicométricos permite a los investigadores caracterizar sus rasgos latentes. Se demuestran metodologías de clasificación sin entrenamiento previo a través de múltiples modelos e instrumentos psicométricos establecidos.

---

<a id="article-13"></a>

### Artículo 13

**Título original:** AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Max Pellert, Clemens M Lechner, Claudia Wagner, Beatrice Rammstedt, Markus Strohmaier

**Keywords:** Artificial intelligence, Psychometrics, Natural language processing, Personality, Values

**URL:** https://pubmed.ncbi.nlm.nih.gov/38165766/

#### Abstract (English)

Standard psychometric inventories can be repurposed as diagnostic instruments for evaluating psychological traits in LLMs. These models inadvertently acquire psychological characteristics from vast training corpora. Eliciting LLM responses to psychometric inventories enables researchers to characterize their latent traits. We demonstrate zero-shot classification methodologies across multiple LLMs and established psychometric instruments.

#### Resumen (Español)

Los inventarios psicométricos estándar pueden reutilizarse como instrumentos diagnósticos para evaluar rasgos psicológicos en modelos de lenguaje de gran escala. Estos modelos adquieren de forma inadvertida características psicológicas desde los amplios corpus de entrenamiento. Obtener respuestas de los modelos a inventarios psicométricos permite a los investigadores caracterizar sus rasgos latentes. Se demuestran metodologías de clasificación sin entrenamiento previo a través de múltiples modelos e instrumentos psicométricos establecidos.

---

<a id="article-14"></a>

### Artículo 14

**Título original:** Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset Designed for LLMs with Psychometrics

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Seungbeen Lee, Seungwon Lim, Seungju Han, Giyeong Oh, Hyungjoo Chae, Jiwan Chung, Minju Kim, Beong-woo Kwak, Yeonsoo Lee, Dongha Lee, Jinyoung Yeo, Youngjae Yu

**Keywords:** Computation and Language, Artificial Intelligence, Large Language Models, Personality Assessment, Psychometrics

**URL:** https://arxiv.org/abs/2406.14703

#### Abstract (English)

We introduce TRAIT, a benchmark comprising 8,000 multiple-choice questions for assessing LLM personality. TRAIT builds upon psychometrically validated questionnaires enhanced with the ATOMIC-10X knowledge graph. Results reveal LLMs exhibit distinct and consistent personalities strongly influenced by training data. Current instruction techniques demonstrate limited effectiveness in eliciting specific traits.

#### Resumen (Español)

Se introduce TRAIT, una batería de evaluación que comprende 8,000 preguntas de opción múltiple para evaluar personalidad en modelos de lenguaje. TRAIT se construye sobre cuestionarios psicométricamente validados mejorados con el grafo de conocimiento ATOMIC-10X. Los resultados revelan que los modelos exhiben personalidades diferenciadas y coherentes, fuertemente influenciadas por los datos de entrenamiento. Las técnicas de instrucción actuales demuestran efectividad limitada para elicitar rasgos específicos.

---

<a id="article-15"></a>

### Artículo 15

**Título original:** Evaluating the Alignment of LLMs on Personality Inference from Real-World Interview Data

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Jianfeng Zhu, Julina Maharjan, Xinyu Li, Karin G. Coifman, Ruoming Jin

**Keywords:** Computation and Language, Large Language Models, Personality Inference, Big Five Personality Traits, Machine Learning

**URL:** https://arxiv.org/abs/2509.13244

#### Abstract (English)

We introduce a benchmark comprising semi-structured interview transcripts paired with validated continuous Big Five trait scores. Systematic evaluation examines LLM performance across zero-shot instruction, fine-tuning, and regression methodologies. Results demonstrate all correlations between model predictions and ground-truth personality traits remain below 0.26, evidencing limited alignment of current LLMs with validated psychological constructs.

#### Resumen (Español)

Se introduce una batería de evaluación que comprende transcripciones de entrevistas semiestructuradas pareadas con puntuaciones validadas de rasgos Big Five continuos. La evaluación sistemática examina el desempeño de modelos a través de instrucción sin entrenamiento previo, ajuste fino y metodologías de regresión. Los resultados demuestran que todas las correlaciones entre predicciones del modelo y rasgos de personalidad reales permanecen por debajo de 0.26, evidenciando alineamiento limitado de los modelos actuales con constructos psicológicos validados.

---

<a id="article-16"></a>

### Artículo 16

**Título original:** Evaluating the Capability of Large Language Models in Emulating Personality

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Yilei Wang, Jiabao Zhao, Derek Siyuan Ong, Xuguang Xu, Lun Hong

**Keywords:** Large Language Models, Personality emulation, GPT-4, Big Five personality profiles, Role-playing

**URL:** https://www.nature.com/articles/s41598-024-84109-5

#### Abstract (English)

We present simulation studies evaluating GPT-4's capacity for role-playing individuals with diverse Big Five personality profiles. Emulated personality responses demonstrate superior internal consistency and more distinct factorial organization compared with human participants. These emulated scores exhibit remarkably high convergent validity with human self-reported personality assessments.

#### Resumen (Español)

Se presentan estudios de simulación que evalúan la capacidad de GPT-4 para emular individuos con perfiles de personalidad Big Five diversos. Las respuestas de personalidad emuladas demuestran coherencia interna superior y organización factorial más diferenciada en comparación con participantes humanos. Estas puntuaciones emuladas exhiben validez convergente notablemente elevada con evaluaciones de personalidad autorreportadas por humanos.

---

<a id="article-17"></a>

### Artículo 17

**Título original:** CAPE: Context-Aware Personality Evaluation Framework for Large Language Models

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Jivnesh Sandhan, Fei Cheng, Tushar Sandhan, Yugo Murawaki

**Keywords:** Computation and Language, Large Language Models, Personality Evaluation, Context-Aware Analysis

**URL:** https://arxiv.org/abs/2508.20385

#### Abstract (English)

We propose the first Context-Aware Personality Evaluation (CAPE) framework for LLMs, incorporating prior conversational interactions. Experiments across 7 LLMs reveal conversational history enhances response consistency through in-context learning while simultaneously inducing personality shifts. We introduce novel metrics quantifying LLM response consistency, a fundamental behavioral trait.

#### Resumen (Español)

Se propone el primer marco de Evaluación de Personalidad Sensible al Contexto (CAPE) para modelos de lenguaje, incorporando interacciones conversacionales previas. Los experimentos a través de 7 modelos revelan que el historial conversacional incrementa la coherencia de respuestas mediante aprendizaje en contexto mientras induce simultáneamente desplazamientos de personalidad. Se introducen métricas novedosas que cuantifican la coherencia de respuestas, un rasgo conductual fundamental.

---

<a id="article-18"></a>

### Artículo 18

**Título original:** Scaling Personality Control in LLMs with Big Five Scaling Prompts

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Gunhee Cho, Yun-Gyung Cheong

**Keywords:** Computation and Language, Multiagent Systems, Big Five personality traits, Prompt engineering

**URL:** https://arxiv.org/abs/2508.06149

#### Abstract (English)

We present Big5-Scaler, an instruction-based framework for conditioning LLMs with controllable Big Five personality traits. Embedding numeric trait values into natural language instructions enables fine-grained personality control without additional training. Results demonstrate consistent induction of distinguishable personality traits across models, with performance varying by instruction type and scale.

#### Resumen (Español)

Se presenta Big5-Scaler, un marco basado en instrucciones para condicionar modelos de lenguaje con rasgos de personalidad Big Five controlables. La incrustación de valores numéricos de rasgos en instrucciones de lenguaje natural permite control de personalidad de grano fino sin entrenamiento adicional. Los resultados demuestran inducción coherente de rasgos de personalidad diferenciables a través de modelos, con desempeño variable según tipo e intensidad de instrucción.

---

<a id="article-19"></a>

### Artículo 19

**Título original:** Predicting Big Five Personality Traits in Chinese Counselling Dialogues Using Large Language Models

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Yang Yan, Lizhi Ma, Anqi Li, Jingsong Ma, Zhenzhong Lan

**Keywords:** Computation and Language, Artificial Intelligence, Computational Psychometrics, Personality Trait Prediction

**URL:** https://arxiv.org/abs/2406.17287

#### Abstract (English)

We examine whether LLMs can predict Big Five personality traits directly from counseling dialogues. The framework applies role-playing and questionnaire-based instruction to condition LLMs on counseling sessions. Evaluation across 853 real-world sessions reveals significant correlation between LLM-predicted and actual Big Five traits. Fine-tuned Llama3-8B achieves 130.95% improvement, surpassing Qwen1.5-110B by 36.94%.

#### Resumen (Español)

Se examina si los modelos de lenguaje pueden predecir rasgos de personalidad Big Five directamente desde diálogos de orientación psicológica. El marco aplica simulación de roles e instrucciones basadas en cuestionarios para condicionar los modelos sobre sesiones de orientación. La evaluación a través de 853 sesiones reales revela correlación significativa entre rasgos Big Five predichos por el modelo y reales. Llama3-8B con ajuste fino logra mejora del 130.95%, superando a Qwen1.5-110B en 36.94%.

---

<a id="article-20"></a>

### Artículo 20

**Título original:** A Framework for the Early Phases of Personality Test Development Using Large Language Models and Artificial Personas

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Patrick M. Markey, Hanna Campbell, Samantha Goldman

**Keywords:** Large Language Models, Personality test development, Artificial personas, Psychometrics, Five-Factor Model, Self-esteem

**URL:** https://www.sciencedirect.com/science/article/abs/pii/S0092656625000790

#### Abstract (English)

We explore LLM applications in early-phase personality test construction, presenting a methodology for efficient assessment of item relevance to psychological constructs. Study 1 employed artificial personas for evaluating personality test items; Study 2 validated resulting scales with 449 human participants. AI-generated scales demonstrated satisfactory internal consistency and robust correlations with established psychometric instruments.

#### Resumen (Español)

Se exploran aplicaciones de modelos de lenguaje en la construcción de inventarios de personalidad en fases iniciales, presentando una metodología para evaluación eficiente de relevancia de ítems a constructos psicológicos. El Estudio 1 empleó personas artificiales para evaluar ítems de inventarios de personalidad; el Estudio 2 validó las escalas resultantes con 449 participantes humanos. Las escalas generadas por IA demostraron coherencia interna satisfactoria y correlaciones robustas con instrumentos psicométricos establecidos.

---

<a id="article-21"></a>

### Artículo 21

**Título original:** On the Emergent Capabilities of ChatGPT 4 to Estimate Personality Traits

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Marco Piastra, Patrizia Catellani

**Keywords:** Artificial Intelligence, Personality Traits, Large Language Models, Big Five, Text Analysis, ChatGPT 4

**URL:** https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1484260/full

#### Abstract (English)

We investigate ChatGPT-4's potential for assessing personality traits from written texts. Using two datasets containing texts and Big Five-based self-assessments, we evaluate ChatGPT-4's predictive performance. Results demonstrate moderate yet significant capacities for automatically inferring personality traits from written text, though with limitations in recognizing input text appropriateness for accurate inference.

#### Resumen (Español)

Se investiga el potencial de ChatGPT-4 para evaluar rasgos de personalidad desde textos escritos. Utilizando dos conjuntos de datos que contienen textos y autoevaluaciones basadas en Big Five, se evalúa el desempeño predictivo de ChatGPT-4. Los resultados demuestran capacidades moderadas pero significativas para inferir automáticamente rasgos de personalidad desde texto escrito, aunque con limitaciones para reconocer la adecuación del texto de entrada para inferencia precisa.

---

<a id="article-22"></a>

### Artículo 22

**Título original:** Personality as a Probe for LLM Evaluation: Method Tradeoffs and Aftereffects

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Gunmay Handa, Zekun Wu, Adriano Koshiyama, Philip Treleaven

**Keywords:** Computation and Language, Large Language Models, Personality Manipulation, Big Five Traits, Machine Learning Evaluation

**URL:** https://arxiv.org/abs/2509.04794

#### Abstract (English)

We present a systematic study of personality control via Big Five traits, comparing in-context learning, parameter-efficient fine-tuning, and mechanistic steering. Clear tradeoffs emerge: in-context learning achieves robust alignment with minimal capability degradation; parameter-efficient fine-tuning delivers maximum alignment at the expense of task performance; mechanistic steering provides lightweight runtime control with competitive effectiveness.

#### Resumen (Español)

Se presenta un estudio sistemático de control de personalidad mediante rasgos Big Five, comparando aprendizaje en contexto, ajuste fino eficiente en parámetros y dirección mecanicista. Emergen compensaciones claras: el aprendizaje en contexto logra alineamiento robusto con degradación mínima de capacidades; el ajuste fino eficiente en parámetros proporciona alineamiento máximo a expensas del desempeño en tareas; la dirección mecanicista ofrece control ligero en tiempo de ejecución con efectividad competitiva.

---

<a id="article-23"></a>

### Artículo 23

**Título original:** Exploring the Potential of Large Language Models for Simulating Personality

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Maria Molchanova, Anna Mikhailova, Anna Korzanova, Lidiia Ostyakova, Alexandra Dolidze

**Keywords:** Computation and Language, Artificial Intelligence, Conversational AI, Personality Simulation, Big Five Model

**URL:** https://arxiv.org/abs/2502.08265

#### Abstract (English)

Advances in LLMs have shifted Conversational AI focus toward dialogue system personalization. We aim to simulate personal traits according to the Big Five model using LLMs. Research demonstrates generating personality-related texts remains challenging. We present a dataset of generated texts with predefined Big Five characteristics and provide an analytical framework for testing LLMs on personality simulation.

#### Resumen (Español)

Los avances en modelos de lenguaje han orientado el enfoque de IA Conversacional hacia la personalización de sistemas de diálogo. Se busca simular rasgos personales según el modelo Big Five mediante modelos de lenguaje. La investigación demuestra que generar textos relacionados con personalidad permanece como desafío. Se presenta un conjunto de datos de textos generados con características Big Five predefinidas y se proporciona un marco analítico para evaluar modelos en simulación de personalidad.

---

<a id="article-24"></a>

### Artículo 24

**Título original:** Do LLMs Possess a Personality? Making the MBTI Test an Amazing Evaluation for Large Language Models

**Categoría:** Evaluación y validación psicométrica

**Año:** 2023 | **Idioma:** Inglés

**Autores:** Keyu Pan, Yawen Zeng

**Keywords:** Large Language Models, Personality Assessment, Myers-Briggs Type Indicator (MBTI), Prompt Engineering, Artificial Intelligence

**URL:** https://arxiv.org/abs/2307.16180

#### Abstract (English)

We investigate MBTI feasibility as an evaluation metric for LLMs. Extensive experiments explore personality types across different LLMs, personality type modification through instruction engineering, and training data effects on model personality. Although MBTI lacks psychometric rigor, it can reflect similarity between LLM and human personality patterns.

#### Resumen (Español)

Se investiga la viabilidad de MBTI como métrica de evaluación para modelos de lenguaje. Los experimentos extensivos exploran tipos de personalidad a través de diferentes modelos, modificación de tipos de personalidad mediante ingeniería de instrucciones, y efectos de datos de entrenamiento sobre personalidad del modelo. Aunque MBTI carece de rigor psicométrico, puede reflejar similitud entre patrones de personalidad de modelos y humanos.

---

<a id="article-25"></a>

### Artículo 25

**Título original:** Do LLMs Possess a Personality? Making the MBTI Test an Amazing Evaluation for Large Language Models

**Categoría:** Evaluación y validación psicométrica

**Año:** 2023 | **Idioma:** Inglés

**Autores:** Keyu Pan, Yawen Zeng

**Keywords:** Large Language Models, Personality Assessment, MBTI, Artificial Intelligence

**URL:** https://www.researchgate.net/publication/372784584_Do_LLMs_Possess_a_Personality_Making_the_MBTI_Test_an_Amazing_Evaluation_for_Large_Language_Models

#### Abstract (English)

We investigate MBTI feasibility as an evaluation metric for LLMs. Extensive experiments explore personality types across different LLMs, personality type modification through instruction engineering, and training data effects on model personality. Although MBTI lacks psychometric rigor, it can reflect similarity between LLM and human personality patterns.

#### Resumen (Español)

Se investiga la viabilidad de MBTI como métrica de evaluación para modelos de lenguaje. Los experimentos extensivos exploran tipos de personalidad a través de diferentes modelos, modificación de tipos de personalidad mediante ingeniería de instrucciones, y efectos de datos de entrenamiento sobre personalidad del modelo. Aunque MBTI carece de rigor psicométrico, puede reflejar similitud entre patrones de personalidad de modelos y humanos.

---

<a id="article-26"></a>

### Artículo 26

**Título original:** Can ChatGPT Assess Human Personalities? A General Evaluation Framework

**Categoría:** Evaluación y validación psicométrica

**Año:** 2023 | **Idioma:** Inglés

**Autores:** Haocong Rao, Cyril Leung, Chunyan Miao

**Keywords:** Large Language Models, ChatGPT, Personality Assessment, Myers-Briggs Type Indicator (MBTI), AI Psychology

**URL:** https://aclanthology.org/2023.findings-emnlp.84/

#### Abstract (English)

We present a generic evaluation framework enabling LLMs to assess human personalities through MBTI. The framework devises unbiased instructions, enables flexible queries across subjects, and reformulates questions for enhanced response clarity. Experiments reveal ChatGPT's capacity for personality assessment with more consistent and equitable evaluations, despite lower robustness to instruction biases compared with InstructGPT.

#### Resumen (Español)

Se presenta un marco de evaluación genérico que permite a modelos de lenguaje evaluar personalidades humanas mediante MBTI. El marco diseña instrucciones imparciales, habilita consultas flexibles entre sujetos y reformula preguntas para mayor claridad de respuestas. Los experimentos revelan la capacidad de ChatGPT para evaluación de personalidad con evaluaciones más coherentes y equitativas, pese a menor robustez ante sesgos de instrucciones en comparación con InstructGPT.

---

<a id="article-27"></a>

### Artículo 27

**Título original:** Machine Mindset: An MBTI Exploration of Large Language Models

**Categoría:** Inducción y control de personalidad

**Año:** 2023 | **Idioma:** Inglés

**Autores:** Jiaxi Cui, Liuzhenghao Lv, Jing Wen, Rongsheng Wang, Jing Tang, YongHong Tian, Li Yuan

**Keywords:** Computation and Language, Large Language Models, MBTI Personality Traits, Artificial Intelligence, Personalized AI

**URL:** https://arxiv.org/abs/2312.12999

#### Abstract (English)

We present a novel methodology for integrating MBTI personality traits into LLMs, addressing personality consistency challenges. Machine Mindset employs two-phase fine-tuning and Direct Preference Optimization to embed MBTI traits. The approach ensures models internalize these traits, yielding stable and consistent personality profiles. We demonstrate effectiveness across multiple domains and release the model as open source.

#### Resumen (Español)

Se presenta una metodología novedosa para integrar rasgos de personalidad MBTI en modelos de lenguaje, abordando desafíos de coherencia de personalidad. Machine Mindset emplea ajuste fino bifásico y Optimización Directa de Preferencias para incrustar rasgos MBTI. El enfoque asegura que los modelos internalicen estos rasgos, produciendo perfiles de personalidad estables y coherentes. Se demuestra efectividad a través de múltiples dominios y se libera el modelo como código abierto.

---

<a id="article-28"></a>

### Artículo 28

**Título original:** Identifying Multiple Personalities in Large Language Models with External Evaluation

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Xiaoyang Song, Yuta Adachi, Jessie Feng, Mouwei Lin, Linhao Yu, Frank Li, Akshat Gupta, Gopala Anumanchipalli, Simerjot Kaur

**Keywords:** Computation and Language, Artificial Intelligence, Large Language Models, Personality Assessment, Machine Learning

**URL:** https://arxiv.org/abs/2402.14805

#### Abstract (English)

We investigate LLM personalities through external evaluation methodology. Rather than prompting with multiple-choice questions, personalities are assessed by analyzing open-ended situational responses via external ML models. Results demonstrate LLMs exhibit divergent personalities when generating posts versus comments, while humans maintain consistent profiles, evidencing fundamental differences in personality manifestation between LLMs and humans.

#### Resumen (Español)

Se investigan personalidades en modelos de lenguaje mediante metodología de evaluación externa. En lugar de emplear preguntas de opción múltiple, las personalidades se evalúan analizando respuestas situacionales abiertas mediante modelos de aprendizaje automático externos. Los resultados demuestran que los modelos exhiben personalidades divergentes al generar publicaciones versus comentarios, mientras que los humanos mantienen perfiles coherentes, evidenciando diferencias fundamentales en manifestación de personalidad entre modelos y humanos.

---

<a id="article-29"></a>

### Artículo 29

**Título original:** Can Large Language Models Understand You Better? An MBTI Personality Detection Dataset Aligned with Population Traits

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Bohan Li, Jiannan Guan, Longxu Dou, Yunlong Feng, Dingzirui Wang, Yang Xu, Enbo Wang, Qiguang Chen, Bichen Wang, Xiao Xu, Yimeng Zhang, Libo Qin, Yanyan Zhao, Qingfu Zhu, Wanxiang Che

**Keywords:** Computation and Language, Computers and Society, MBTI Personality Detection, Large Language Models, Personality Traits

**URL:** https://arxiv.org/abs/2412.12510

#### Abstract (English)

We optimize MBTI personality detection by constructing MBTIBench, the first manually annotated high-quality dataset with soft labels. The dataset effectively resolves incorrect labeling issues affecting 29.58% of data and estimates soft labels through polarity tendency derivation. Experimental results identify polarized predictions and LLM biases as critical directions for future investigation.

#### Resumen (Español)

Se optimiza la detección de personalidad MBTI construyendo MBTIBench, el primer conjunto de datos de alta calidad anotado manualmente con etiquetas suaves. El conjunto de datos resuelve efectivamente problemas de etiquetado incorrecto que afectan al 29.58% de datos y estima etiquetas suaves mediante derivación de tendencia de polaridad. Los resultados experimentales identifican predicciones polarizadas y sesgos en modelos como direcciones críticas para investigación futura.

---

<a id="article-30"></a>

### Artículo 30

**Título original:** Evaluating the Psychological Safety of Large Language Models

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2022 | **Idioma:** Inglés

**Autores:** Xingxuan Li, Yutong Li, Lin Qiu, Shafiq Joty, Lidong Bing

**Keywords:** Computation and Language, Artificial Intelligence, Computers and Society, Psychological safety, Personality tests, Well-being assessments

**URL:** https://arxiv.org/abs/2212.10529

#### Abstract (English)

We design unbiased instructions to systematically evaluate psychological safety in LLMs. Five LLMs underwent testing via Short Dark Triad and Big Five Inventory. All models score above human averages on SD-3, suggesting relatively darker personality patterns. We recommend systematic psychological metric application to further evaluate and enhance LLM safety.

#### Resumen (Español)

Se diseñan instrucciones imparciales para evaluar sistemáticamente seguridad psicológica en modelos de lenguaje. Cinco modelos fueron evaluados mediante Short Dark Triad e Inventario Big Five. Todos los modelos puntúan por encima de promedios humanos en SD-3, sugiriendo patrones de personalidad relativamente más oscuros. Se recomienda aplicación sistemática de métricas psicológicas para evaluar y mejorar la seguridad de los modelos.

---

<a id="article-31"></a>

### Artículo 31

**Título original:** Personality Testing of Large Language Models: Limited Temporal Stability But Highlighted Social Desirability

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Bojana Bodroža, Bojana M. Dinić, Ljubiša Bojić

**Keywords:** Large Language Models, Personality testing, Temporal stability, Prosociality, Psychometric assessment

**URL:** https://royalsocietypublishing.org/doi/10.1098/rsos.240180

#### Abstract (English)

Personality testing across seven LLMs was investigated with focus on temporal stability. Models demonstrated varying inter-rater agreement levels across short timeframes. Models including Llama3 and GPT-4o exhibited higher consistency. Models displayed socially desirable profiles characterized by elevated agreeableness and conscientiousness alongside reduced Machiavellianism. Temporal stability proves crucial for AI systems given their expanding societal influence.

#### Resumen (Español)

Se investigó la evaluación de personalidad a través de siete modelos de lenguaje con enfoque en estabilidad temporal. Los modelos demostraron niveles variables de acuerdo interevaluador a través de períodos breves. Modelos como Llama3 y GPT-4o exhibieron mayor coherencia. Los modelos mostraron perfiles socialmente deseables caracterizados por amabilidad y responsabilidad elevadas junto con maquiavelismo reducido. La estabilidad temporal resulta crucial para sistemas de inteligencia artificial dada su creciente influencia social.

---

<a id="article-32"></a>

### Artículo 32

**Título original:** Personality Testing of Large Language Models: Limited Temporal Stability But Highlighted Social Desirability

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Bojana Bodroža, Bojana M. Dinić, Ljubiša Bojić

**Keywords:** Large Language Models, Personality testing, Temporal stability, Prosociality

**URL:** https://arxiv.org/abs/2306.04308

#### Abstract (English)

Personality testing across seven LLMs was investigated with focus on temporal stability. Models demonstrated varying inter-rater agreement levels across short timeframes. Models including Llama3 and GPT-4o exhibited higher consistency. Models displayed socially desirable profiles characterized by elevated agreeableness and conscientiousness alongside reduced Machiavellianism.

#### Resumen (Español)

Se investigó la evaluación de personalidad a través de siete modelos de lenguaje con enfoque en estabilidad temporal. Los modelos demostraron niveles variables de acuerdo interevaluador a través de períodos breves. Modelos como Llama3 y GPT-4o exhibieron mayor coherencia. Los modelos mostraron perfiles socialmente deseables caracterizados por amabilidad y responsabilidad elevadas junto con maquiavelismo reducido.

---

<a id="article-33"></a>

### Artículo 33

**Título original:** Personality Testing of Large Language Models: Limited Temporal Stability But Highlighted Social Desirability

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Bojana Bodroža, Bojana M. Dinić, Ljubiša Bojić

**Keywords:** Large Language Models, Personality testing, Temporal stability, Prosociality

**URL:** https://pmc.ncbi.nlm.nih.gov/articles/PMC11461045/

#### Abstract (English)

Personality testing across seven LLMs was investigated with focus on temporal stability. Models demonstrated varying inter-rater agreement levels across short timeframes. Models including Llama3 and GPT-4o exhibited higher consistency. Models displayed socially desirable profiles characterized by elevated agreeableness and conscientiousness alongside reduced Machiavellianism.

#### Resumen (Español)

Se investigó la evaluación de personalidad a través de siete modelos de lenguaje con enfoque en estabilidad temporal. Los modelos demostraron niveles variables de acuerdo interevaluador a través de períodos breves. Modelos como Llama3 y GPT-4o exhibieron mayor coherencia. Los modelos mostraron perfiles socialmente deseables caracterizados por amabilidad y responsabilidad elevadas junto con maquiavelismo reducido.

---

<a id="article-34"></a>

### Artículo 34

**Título original:** Applying Psychometrics to Simulated Populations of Large Language Models: Recreating the HEXACO Personality Inventory Experiment

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Sarah Mercer, Daniel P. Martin, Phil Swatton

**Keywords:** Computation and Language, Machine Learning, Generative Agents, Personality Inventory, Psychometrics, HEXACO

**URL:** https://arxiv.org/abs/2508.00742

#### Abstract (English)

We explore validity of persona-based agents for representing human populations by recreating the HEXACO personality inventory experiment. Results reveal coherent personality structures recoverable from agent responses, demonstrating partial alignment with the HEXACO framework. Derived personality dimensions prove consistent and reliable within GPT-4 when paired with curated populations. Cross-model analysis reveals variability suggesting model-specific biases and limitations.

#### Resumen (Español)

Se explora la validez de agentes basados en personas para representar poblaciones humanas recreando el experimento del inventario de personalidad HEXACO. Los resultados revelan estructuras de personalidad coherentes recuperables desde respuestas de agentes, demostrando alineamiento parcial con el marco HEXACO. Las dimensiones de personalidad derivadas resultan coherentes y fiables dentro de GPT-4 cuando se emparejan con poblaciones curadas. El análisis entre modelos revela variabilidad que sugiere sesgos y limitaciones específicos del modelo.

---

<a id="article-35"></a>

### Artículo 35

**Título original:** Exploring the Impact of Personality Traits on LLM Bias and Toxicity

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Shuo Wang, Renhao Li, Xi Chen, Yulin Yuan, Derek F. Wong, Min Yang

**Keywords:** Artificial Intelligence, Large Language Models, Personality Traits, Bias, Toxicity

**URL:** https://arxiv.org/abs/2502.12566

#### Abstract (English)

Personality trait assignment influences toxicity and bias levels in large language model outputs. Using the HEXACO personality framework, experimentally validated prompts were designed to evaluate three models across toxicity and bias benchmarks. All models exhibited sensitivity to HEXACO traits with consistent variations in bias, negative sentiment, and toxicity levels. Adjustment of personality trait intensities effectively reduces bias and toxicity in model outputs.

#### Resumen (Español)

La asignación de rasgos de personalidad influye en los niveles de toxicidad y sesgo de los modelos de lenguaje de gran escala. Mediante el marco de personalidad HEXACO, se diseñaron instrucciones experimentalmente validadas para evaluar tres modelos a través de benchmarks de toxicidad y sesgo. Todos los modelos exhibieron sensibilidad a los rasgos HEXACO con variaciones consistentes en sesgo, sentimiento negativo y niveles de toxicidad. El ajuste de las intensidades de rasgos de personalidad reduce efectivamente el sesgo y la toxicidad en las salidas del modelo.

---

<a id="article-36"></a>

### Artículo 36

**Título original:** SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Adithya Chittem, Aishna Shrivastava, Sai Tarun Pendela, Jagat Sesh Challa, Dhruv Kumar

**Keywords:** Computation and Language, Artificial Intelligence, Human-Computer Interaction

**URL:** https://arxiv.org/abs/2506.20993

#### Abstract (English)

Personality modeling is extended from the Big Five to the 16PF model, enabling expressive control over sixteen distinct traits. The Specific Attribute Control (SAC) framework evaluates and dynamically induces trait intensity in large language models using adjective-based semantic anchoring. Modeling intensity as a continuous spectrum yields substantially more consistent and controllable personality expression. Changes in target trait intensity systematically influence closely related traits in psychologically coherent directions.

#### Resumen (Español)

Se extiende el modelado de personalidad desde los Cinco Grandes al modelo 16PF, permitiendo control expresivo sobre dieciséis rasgos distintos. El marco de Control de Atributos Específicos (SAC) evalúa e induce dinámicamente la intensidad de rasgos en modelos de lenguaje de gran escala mediante anclaje semántico basado en adjetivos. El modelado de la intensidad como espectro continuo produce expresión de personalidad sustancialmente más consistente y controlable. Los cambios en la intensidad del rasgo objetivo influyen sistemáticamente en rasgos estrechamente relacionados en direcciones psicológicamente coherentes.

---

<a id="article-37"></a>

### Artículo 37

**Título original:** Moral Foundations of Large Language Models

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2023 | **Idioma:** Inglés

**Autores:** Marwa Abdulhai, Gregory Serapio-Garcia, Clément Crepy, Daria Valter, John Canny, Natasha Jaques

**Keywords:** Artificial Intelligence, Computation and Language, Computers and Society, Moral Foundations Theory

**URL:** https://arxiv.org/abs/2310.15337

#### Abstract (English)

Moral Foundations Theory is applied to analyze whether popular large language models have acquired bias toward particular moral values. Models exhibit specific moral foundations correlating with human moral foundations and political affiliations. Consistency of these biases is measured, revealing instructions can be adversarially selected to induce models to exhibit particular moral foundations, affecting downstream task behavior.

#### Resumen (Español)

Se aplica la Teoría de Fundamentos Morales para analizar si los modelos de lenguaje de gran escala populares han adquirido sesgo hacia valores morales particulares. Los modelos exhiben fundamentos morales específicos que correlacionan con fundamentos morales humanos y afiliaciones políticas. Se mide la coherencia de estos sesgos, revelando que las instrucciones pueden seleccionarse adversarialmente para inducir a los modelos a exhibir fundamentos morales particulares, afectando el comportamiento en tareas posteriores.

---

<a id="article-38"></a>

### Artículo 38

**Título original:** Questioning the Validity of Personality Tests for Large Language Models

**Categoría:** Evaluación y validación psicométrica

**Año:** 2023 | **Idioma:** Inglés

**Autores:** Tom Sühr, Florian E. Dorner, Samira Samadi, Augustin Kelava

**Keywords:** Computation and Language, Artificial Intelligence, Machine Learning, Personality assessment

**URL:** https://arxiv.org/abs/2311.05297

#### Abstract (English)

Large language model responses to personality tests systematically deviate from human responses, implying test results cannot be interpreted equivalently. Reverse-coded items are often both answered affirmatively. Variation across instructions designed to simulate particular personality types does not follow clear separation into five independent personality factors observed in human samples. Results highlight the importance of investigating test validity when applied to large language models.

#### Resumen (Español)

Las respuestas de modelos de lenguaje de gran escala a pruebas de personalidad se desvían sistemáticamente de las respuestas humanas, implicando que los resultados no pueden interpretarse de manera equivalente. Los ítems codificados inversamente frecuentemente son respondidos afirmativamente en ambos casos. La variación entre instrucciones diseñadas para simular tipos particulares de personalidad no sigue la separación clara en cinco factores de personalidad independientes observada en muestras humanas. Los resultados destacan la importancia de investigar la validez de las pruebas cuando se aplican a modelos de lenguaje de gran escala.

---

<a id="article-39"></a>

### Artículo 39

**Título original:** Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Yu-Min Tseng, Yu-Chao Huang, Teng-Yun Hsiao, Wei-Lin Chen, Chao-Wei Huang, Yu Meng, Yun-Nung Chen

**Keywords:** Large Language Models, Persona, Role-Playing, Personalization, LLM Personality Evaluation

**URL:** https://aclanthology.org/2024.findings-emnlp.969/

#### Abstract (English)

Research on leveraging persona in large language models is categorized into two lines: role-playing, where personas are assigned to models, and personalization, where models accommodate user personas. Existing methods for personality evaluation in large language models are also introduced. This represents the first survey addressing role-playing and personalization under the unified view of persona.

#### Resumen (Español)

Se categoriza la investigación sobre el uso de personas en modelos de lenguaje de gran escala en dos líneas: juego de roles, donde se asignan personas a los modelos, y personalización, donde los modelos se adaptan a personas de usuarios. También se introducen métodos existentes para la evaluación de personalidad en modelos de lenguaje de gran escala. Representa la primera revisión que aborda juego de roles y personalización bajo la visión unificada de persona.

---

<a id="article-40"></a>

### Artículo 40

**Título original:** Psychometrics of Large Language Models: A Systematic Review of Evaluation, Validation, and Enhancement

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Haoran Ye, Jing Jin, Yuhang Xie, Xin Zhang, Guojie Song

**Keywords:** Computation and Language, Artificial Intelligence, Human-Computer Interaction

**URL:** https://arxiv.org/abs/2505.08245

#### Abstract (English)

The interdisciplinary field of psychometrics for large language models leverages psychometric instruments, theories, and principles to evaluate, understand, and enhance these systems. The literature systematically shapes benchmarking principles, broadens evaluation scopes, refines methodologies, validates results, and advances model capabilities. Actionable insights are provided for developing evaluation paradigms that align with human-level artificial intelligence and promote human-centered systems.

#### Resumen (Español)

El campo interdisciplinario de psicometría para modelos de lenguaje de gran escala aprovecha instrumentos, teorías y principios psicométricos para evaluar, comprender y mejorar estos sistemas. La literatura da forma sistemáticamente a principios de benchmarking, amplía alcances de evaluación, refina metodologías, valida resultados y avanza las capacidades de los modelos. Se proporcionan perspectivas aplicables para desarrollar paradigmas de evaluación que se alineen con inteligencia artificial de nivel humano y promuevan sistemas centrados en el ser humano.

---

<a id="article-41"></a>

### Artículo 41

**Título original:** Psychometrics of Large Language Models: A Systematic Review of Evaluation, Validation, and Enhancement

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Haoran Ye, Jing Jin, Yuhang Xie, Xin Zhang, Guojie Song

**Keywords:** LLM Psychometrics, Systematic Review, Evaluation, Validation

**URL:** https://llm-psychometrics.com/

#### Abstract (English)

The interdisciplinary field of psychometrics for large language models leverages psychometric instruments, theories, and principles to evaluate, understand, and enhance these systems. The literature systematically shapes benchmarking principles, broadens evaluation scopes, refines methodologies, validates results, and advances model capabilities. A curated repository of resources is available for consultation.

#### Resumen (Español)

El campo interdisciplinario de psicometría para modelos de lenguaje de gran escala aprovecha instrumentos, teorías y principios psicométricos para evaluar, comprender y mejorar estos sistemas. La literatura da forma sistemáticamente a principios de benchmarking, amplía alcances de evaluación, refina metodologías, valida resultados y avanza las capacidades de los modelos. Se encuentra disponible un repositorio curado de recursos para consulta.

---

<a id="article-42"></a>

### Artículo 42

**Título original:** Quantifying AI Psychology: A Psychometric Benchmark for Large Language Models

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Yuan Li, Yue Huang, Hongyi Wang, Ying Cheng, Xiangliang Zhang, James Zou, Lichao Sun

**Keywords:** Computation and Language, Psychological constructs, Personality, Values, Emotional intelligence, Theory of mind, Self-efficacy

**URL:** https://arxiv.org/abs/2406.17675

#### Abstract (English)

A comprehensive benchmark is presented for quantifying psychological constructs in large language models, encompassing psychological dimension identification, assessment dataset design, and validation of results. Five key psychological constructs are assessed through 13 datasets. Significant discrepancies between self-reported traits and response patterns in real-world scenarios reveal behavioral complexities. Some preference-based tests designed for humans fail to elicit reliable responses from large language models.

#### Resumen (Español)

Se presenta un benchmark integral para cuantificar constructos psicológicos en modelos de lenguaje de gran escala, abarcando identificación de dimensiones psicológicas, diseño de conjuntos de datos de evaluación y validación de resultados. Cinco constructos psicológicos clave se evalúan a través de 13 conjuntos de datos. Discrepancias significativas entre rasgos autoinformados y patrones de respuesta en escenarios del mundo real revelan complejidades conductuales. Algunas pruebas basadas en preferencias diseñadas para humanos no logran obtener respuestas fiables de los modelos de lenguaje de gran escala.

---

<a id="article-43"></a>

### Artículo 43

**Título original:** Beyond Self-Reports: Multi-Observer Agents for Personality Assessment in Large Language Models

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Yin Jou Huang, Rafik Hadfi

**Keywords:** Computation and Language, Artificial Intelligence, Personality Assessment, Multi-Observer Framework

**URL:** https://arxiv.org/abs/2504.08399

#### Abstract (English)

A novel multi-observer framework for personality trait assessment in large language model agents is proposed, drawing on informant-report methods from psychology. Instead of self-assessments, multiple observer agents are employed, each configured with specific relational contexts. Observer-report ratings align more closely with human judgments than traditional self-reports and reveal systematic biases in self-assessments. Aggregating responses from 5-7 observers reduces biases and achieves optimal reliability.

#### Resumen (Español)

Se propone un marco novedoso de multi-observador para evaluación de rasgos de personalidad en agentes de modelos de lenguaje de gran escala, basándose en métodos de informe de informantes de la psicología. En lugar de autoevaluaciones, se emplean múltiples agentes observadores, cada uno configurado con contextos relacionales específicos. Las calificaciones de informe de observadores se alinean más estrechamente con juicios humanos que los autoinformes tradicionales y revelan sesgos sistemáticos en las autoevaluaciones. La agregación de respuestas de 5-7 observadores reduce sesgos y alcanza fiabilidad óptima.

---

<a id="article-44"></a>

### Artículo 44

**Título original:** Psychometric Evaluation of Large Language Model Embeddings for Personality Trait Prediction

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Julina Maharjan, Ruoming Jin, Jianfeng Zhu, Deric Kenne

**Keywords:** Large Language Models, Embeddings, Personality prediction, Psychometric validation, Big Five, LIWC, Emotional markers

**URL:** https://www.jmir.org/2025/1/e75347

#### Abstract (English)

Embeddings from large language models are evaluated for personality trait prediction through psychometric validation. The research examines how well embeddings capture personality-relevant information compared to traditional linguistic features. Results provide insights into reliability and validity of using embeddings for psychological assessment, with implications for clinical and research applications in personality psychology.

#### Resumen (Español)

Se evalúan embeddings de modelos de lenguaje de gran escala para predicción de rasgos de personalidad mediante validación psicométrica. La investigación examina en qué medida los embeddings capturan información relevante de personalidad en comparación con características lingüísticas tradicionales. Los resultados proporcionan perspectivas sobre la fiabilidad y validez del uso de embeddings para evaluación psicológica, con implicaciones para aplicaciones clínicas y de investigación en psicología de la personalidad.

---

<a id="article-45"></a>

### Artículo 45

**Título original:** LMLPA: Language Model Linguistic Personality Assessment

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Jingyao Zheng, Xian Wang, Simo Hosio, Xiaoxian Xu, Lik-Hang Lee

**Keywords:** Computation and Language, Artificial Intelligence, Large Language Models, Personality Assessment, Human-Computer Interaction

**URL:** https://arxiv.org/abs/2410.17632

#### Abstract (English)

The Language Model Linguistic Personality Assessment (LMLPA) is introduced as a system designed to evaluate linguistic personalities of large language models. Unlike traditional psychometrics, LMLPA adapts the Big Five Inventory to align with operational capabilities of these models. The questionnaire is open-ended, requiring an artificial intelligence rater to transform textual responses into numerical personality indicators. Large language models possess distinct personality traits that can be effectively quantified through LMLPA.

#### Resumen (Español)

Se introduce la Evaluación de Personalidad Lingüística de Modelos de Lenguaje (LMLPA) como sistema diseñado para evaluar personalidades lingüísticas de modelos de lenguaje de gran escala. A diferencia de la psicometría tradicional, LMLPA adapta el Inventario de los Cinco Grandes para alinearse con las capacidades operacionales de estos modelos. El cuestionario es de respuesta abierta, requiriendo un evaluador de inteligencia artificial para transformar respuestas textuales en indicadores numéricos de personalidad. Los modelos de lenguaje de gran escala poseen rasgos de personalidad distintos que pueden cuantificarse efectivamente mediante LMLPA.

---

<a id="article-46"></a>

### Artículo 46

**Título original:** LMLPA: Language Model Linguistic Personality Assessment

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Jingyao Zheng, Xian Wang, Simo Hosio, Xiaoxian Xu, Lik-Hang Lee

**Keywords:** Computation and Language, Artificial Intelligence, Personality Assessment, Computational Linguistics

**URL:** https://direct.mit.edu/coli/article/51/2/599/127544/

#### Abstract (English)

The Language Model Linguistic Personality Assessment (LMLPA) is introduced as a system designed to evaluate linguistic personalities of large language models. Unlike traditional psychometrics, LMLPA adapts the Big Five Inventory to align with operational capabilities of these models. The questionnaire is open-ended, requiring an artificial intelligence rater to transform textual responses into numerical personality indicators. Large language models possess distinct personality traits that can be effectively quantified.

#### Resumen (Español)

Se introduce la Evaluación de Personalidad Lingüística de Modelos de Lenguaje (LMLPA) como sistema diseñado para evaluar personalidades lingüísticas de modelos de lenguaje de gran escala. A diferencia de la psicometría tradicional, LMLPA adapta el Inventario de los Cinco Grandes para alinearse con las capacidades operacionales de estos modelos. El cuestionario es de respuesta abierta, requiriendo un evaluador de inteligencia artificial para transformar respuestas textuales en indicadores numéricos de personalidad. Los modelos de lenguaje de gran escala poseen rasgos de personalidad distintos que pueden cuantificarse efectivamente.

---

<a id="article-47"></a>

### Artículo 47

**Título original:** You Don't Need a Personality Test to Know These Models Are Unreliable: Assessing the Reliability of LLMs on Psychometric Instruments

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Bangzhao Shu, Lechen Zhang, Minje Choi, Lavinia Dunagan, Lajanugen Logeswaran, Moontae Lee, Dallas Card, David Jurgens

**Keywords:** Large Language Models, Psychometric Instruments, Persona Measurement, Prompt Consistency, NLU

**URL:** https://aclanthology.org/2024.naacl-long.295/

#### Abstract (English)

A dataset containing 693 questions encompassing 39 different persona measurement instruments across 115 persona axes is constructed. Experiments on 17 large language models reveal that simple perturbations significantly degrade question-answering ability, and most models exhibit low negation consistency. Results suggest the currently widespread practice of prompting is insufficient to accurately and reliably capture model perceptions, requiring alternative approaches.

#### Resumen (Español)

Se construye un conjunto de datos que contiene 693 preguntas abarcando 39 instrumentos diferentes de medición de persona en 115 ejes de persona. Experimentos en 17 modelos de lenguaje de gran escala revelan que perturbaciones simples degradan significativamente la capacidad de respuesta a preguntas, y la mayoría de los modelos exhiben baja consistencia de negación. Los resultados sugieren que la práctica actualmente generalizada de instrucciones es insuficiente para capturar con precisión y fiabilidad las percepciones del modelo, requiriendo enfoques alternativos.

---

<a id="article-48"></a>

### Artículo 48

**Título original:** Self-Reports are Unreliable Measures of LLM Personality

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Akshat Gupta, Xiaoyang Song, Gopala Anumanchipalli

**Keywords:** Large Language Models, Personality Assessment, Prompt Sensitivity, Option-Order Symmetry, NLP

**URL:** https://aclanthology.org/2024.blackboxnlp-1.20/

#### Abstract (English)

Reliability of personality scores from self-assessment tests is analyzed using two experiments: prompt sensitivity and option-order symmetry. Tests on ChatGPT and three Llama2 models show semantically equivalent prompts lead to substantially different personality scores with statistically significant differences for all traits. Scores are not robust to option order. Self-assessment personality tests created for humans constitute unreliable measures of personality in large language models.

#### Resumen (Español)

Se analiza la fiabilidad de puntuaciones de personalidad de pruebas de autoevaluación mediante dos experimentos: sensibilidad de instrucciones y simetría de orden de opciones. Pruebas en ChatGPT y tres modelos Llama2 muestran que instrucciones semánticamente equivalentes conducen a puntuaciones de personalidad sustancialmente diferentes con diferencias estadísticamente significativas para todos los rasgos. Las puntuaciones no son robustas al orden de opciones. Las pruebas de personalidad de autoevaluación creadas para humanos constituyen medidas no fiables de personalidad en modelos de lenguaje de gran escala.

---

<a id="article-49"></a>

### Artículo 49

**Título original:** Is Machine Psychology Here? On the Requirements for Using Human Psychological Tests on LLMs

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Lea Löhn, Niklas Kiehne, Alexander Ljapunov, Wolf-Tilo Balke

**Keywords:** Large Language Models, Psychological Assessment, Machine Psychology, Test Reliability, Construct Validity

**URL:** https://aclanthology.org/2024.inlg-main.19/

#### Abstract (English)

Seven requirements necessary for testing large language models with psychological assessments are proposed. Critical reflection on 25 machine psychology studies reveals lack of appropriate methods to assess test reliability and construct validity, unknown strength of construct-irrelevant influences such as pre-training corpora contamination, and pervasive non-reproducibility issues. Results underscore lack of general methodology and need to redefine psychological constructs specifically for large language models.

#### Resumen (Español)

Se proponen siete requisitos necesarios para evaluar modelos de lenguaje de gran escala con evaluaciones psicológicas. La reflexión crítica sobre 25 estudios de psicología de máquinas revela falta de métodos apropiados para evaluar fiabilidad de pruebas y validez de constructo, fuerza desconocida de influencias irrelevantes al constructo como contaminación de corpus de preentrenamiento, y problemas generalizados de no reproducibilidad. Los resultados subrayan la falta de metodología general y la necesidad de redefinir constructos psicológicos específicamente para modelos de lenguaje de gran escala.

---

<a id="article-50"></a>

### Artículo 50

**Título original:** Persistent Instability in LLM Personality Measurements: Effects of Scaling, Reasoning, and Conversation History

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Tommaso Tosato, Saskia Helbling, Yorguin-Jose Mantilla-Ramos, Mahmood Hegazy, Alberto Tosato, David John Lemay, Irina Rish, Guillaume Dumas

**Keywords:** Computation and Language, Artificial Intelligence, Large Language Models, Personality Measurements, Model Behavior Consistency

**URL:** https://arxiv.org/abs/2508.04826

#### Abstract (English)

PERSIST, a comprehensive evaluation framework, is presented testing 25+ open-source models across 500,000+ responses. Findings challenge fundamental deployment assumptions: even 400B+ parameter models exhibit substantial response variability; minor prompt reordering shifts personality measurements by up to 20%; interventions expected to stabilize behavior can paradoxically increase variability. This persistent instability across scales and mitigation strategies suggests current models lack foundations for genuine behavioral consistency.

#### Resumen (Español)

Se presenta PERSIST, un marco de evaluación integral que prueba más de 25 modelos de código abierto a través de más de 500,000 respuestas. Los hallazgos desafían supuestos fundamentales de despliegue: incluso modelos con más de 400 mil millones de parámetros exhiben variabilidad de respuesta sustancial; reordenamiento menor de instrucciones cambia mediciones de personalidad hasta un 20%; intervenciones esperadas para estabilizar comportamiento pueden paradójicamente aumentar la variabilidad. Esta inestabilidad persistente a través de escalas y estrategias de mitigación sugiere que los modelos actuales carecen de fundamentos para consistencia conductual genuina.

---

<a id="article-51"></a>

### Artículo 51

**Título original:** Stick to Your Role: Stability of Personal Values Expressed in Large Language Models

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Grgur Kovač, Rémy Portelas, Masataka Sawayama, Peter Ford Dominey, Pierre-Yves Oudeyer

**Keywords:** Computation and Language, Artificial Intelligence, Machine Learning, Value Stability, Personal Values

**URL:** https://arxiv.org/abs/2402.14846

#### Abstract (English)

Value stability in large language models is studied as a specific property using psychology methods. Rank-order stability is examined at the population level and ipsative stability at the individual level. Two settings (with and without persona simulation), two simulated populations, and three downstream tasks are considered. Consistent trends show some models exhibit higher value stability than others. When instructed to simulate personas, models exhibit low rank-order stability which diminishes with conversation length.

#### Resumen (Español)

Se estudia la estabilidad de valores en modelos de lenguaje de gran escala como propiedad específica mediante métodos de psicología. Se examina la estabilidad de orden de rango a nivel poblacional y la estabilidad ipsativa a nivel individual. Se consideran dos configuraciones (con y sin simulación de persona), dos poblaciones simuladas y tres tareas posteriores. Tendencias consistentes muestran que algunos modelos exhiben mayor estabilidad de valores que otros. Cuando se instruye para simular personas, los modelos exhiben baja estabilidad de orden de rango que disminuye con la longitud de conversación.

---

<a id="article-52"></a>

### Artículo 52

**Título original:** Scaling Law in LLM Simulated Personality: A More Detailed and Realistic Persona Profile is All You Need

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Yuqi Bai, Tianyu Huang, Kun Sun, Yuting Chen

**Keywords:** Computers and Society, Artificial Intelligence, Computation and Language, Social experiments, Persona role-playing

**URL:** https://arxiv.org/abs/2510.11734

#### Abstract (English)

Large language models are employed to simulate social experiments, exploring their ability to emulate human personality in virtual persona role-playing. An end-to-end evaluation framework is developed including individual-level analysis of stability and identifiability, and population-level analysis termed progressive personality curves. Main contributions include proposing a systematic framework for virtual personality evaluation, demonstrating the critical role of persona detail in quality, and identifying a scaling law in personality simulation.

#### Resumen (Español)

Se emplean modelos de lenguaje de gran escala para simular experimentos sociales, explorando su capacidad para emular personalidad humana en juego de roles de persona virtual. Se desarrolla un marco de evaluación de extremo a extremo que incluye análisis a nivel individual de estabilidad e identificabilidad, y análisis a nivel poblacional denominado curvas de personalidad progresivas. Las contribuciones principales incluyen proponer un marco sistemático para evaluación de personalidad virtual, demostrar el papel crítico del detalle de persona en la calidad, e identificar una ley de escalado en simulación de personalidad.

---

<a id="article-53"></a>

### Artículo 53

**Título original:** The Illusion of Personality: Uncovering Dissociation Between Self-Reports and Behavior in LLMs

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Pengrui Han, Rafal Kocielnik, Peiyang Song, Ramit Debnath, Dean Mobbs, Anima Anandkumar, R. Michael Alvarez

**Keywords:** Artificial Intelligence, Computation and Language, Computers and Society, Machine Learning

**URL:** https://arxiv.org/abs/2509.03730

#### Abstract (English)

Personality in large language models is systematically characterized across three dimensions: dynamic emergence throughout training stages, predictive validity of self-reported traits in behavioral tasks, and impact of targeted interventions. Instructional alignment stabilizes trait expression and strengthens correlations mirroring human data. However, self-reported traits do not reliably predict behavior, and observed associations often diverge from human patterns. Persona injection steers self-reports but exerts minimal consistent effect on actual behavior.

#### Resumen (Español)

Se caracteriza sistemáticamente la personalidad en modelos de lenguaje de gran escala a través de tres dimensiones: surgimiento dinámico durante etapas de entrenamiento, validez predictiva de rasgos autoinformados en tareas conductuales, e impacto de intervenciones dirigidas. La alineación instruccional estabiliza la expresión de rasgos y fortalece correlaciones que reflejan datos humanos. Sin embargo, los rasgos autoinformados no predicen fiablemente el comportamiento, y las asociaciones observadas frecuentemente divergen de patrones humanos. La inyección de persona dirige los autoinformes pero ejerce un efecto consistente mínimo en el comportamiento real.

---

<a id="article-54"></a>

### Artículo 54

**Título original:** Large Language Models Show Human-Like Social Desirability Biases in Survey Responses

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Aadesh Salecha, Molly E. Ireland, Shashanka Subrahmanya, João Sedoc, Lyle H. Ungar, Johannes C. Eichstaedt

**Keywords:** Artificial Intelligence, Computation and Language, Computers and Society, Human-Computer Interaction, Social desirability bias

**URL:** https://arxiv.org/abs/2405.06058

#### Abstract (English)

An experimental framework using Big Five personality surveys is developed, uncovering a previously undetected social desirability bias across a wide range of large language models. By varying the number of questions, the ability of models to infer when being evaluated is demonstrated. When personality evaluation is inferred, models skew scores toward desirable trait ends. This bias exists in all tested models, with bias levels appearing to increase in more recent models.

#### Resumen (Español)

Se desarrolla un marco experimental mediante encuestas de personalidad de los Cinco Grandes, revelando un sesgo de deseabilidad social previamente no detectado en una amplia gama de modelos de lenguaje de gran escala. Al variar el número de preguntas, se demuestra la capacidad de los modelos para inferir cuándo están siendo evaluados. Cuando se infiere la evaluación de personalidad, los modelos sesgan las puntuaciones hacia extremos de rasgos deseables. Este sesgo existe en todos los modelos probados, con niveles de sesgo que parecen aumentar en modelos más recientes.

---

<a id="article-55"></a>

### Artículo 55

**Título original:** Can AI Understand Human Personality? Comparing Humans and AI Systems at Predicting Personality Correlations

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Philipp Schoenegger, Spencer Greenberg, Alexander Grishin, Joshua Lewis, Lucius Caviola

**Keywords:** Computers and Society, Personality Prediction, AI Systems, Personality Correlations

**URL:** https://arxiv.org/abs/2406.08170

#### Abstract (English)

Abilities of specialized neural networks like PersonalityMap and general large language models like GPT-4o and Claude 3 Opus in understanding human personality are tested. When compared with individual humans, all artificial intelligence models make better predictions than the vast majority of lay people and academic experts. However, when selecting median prediction for each item, experts and PersonalityMap outperform large language models and lay people on most measures.

#### Resumen (Español)

Se prueban las capacidades de redes neuronales especializadas como PersonalityMap y modelos de lenguaje de gran escala generales como GPT-4o y Claude 3 Opus en comprender personalidad humana. Cuando se comparan con humanos individuales, todos los modelos de inteligencia artificial realizan mejores predicciones que la gran mayoría de personas no expertas y expertos académicos. Sin embargo, al seleccionar la predicción mediana para cada ítem, expertos y PersonalityMap superan a los modelos de lenguaje de gran escala y personas no expertas en la mayoría de medidas.

---

<a id="article-56"></a>

### Artículo 56

**Título original:** Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2023 | **Idioma:** Inglés

**Autores:** Myra Cheng, Esin Durmus, Dan Jurafsky

**Keywords:** Large Language Models, Stereotypes, Demographic Groups, Intersectionality, NLP, Sociolinguistics, Markedness, Bias Detection

**URL:** https://aclanthology.org/2023.acl-long.84/

#### Abstract (English)

Marked Personas, a prompt-based method to measure stereotypes in large language models for intersectional demographic groups without lexicon or labeling, is presented. Grounded in the markedness concept, the method prompts models to generate personas of target groups alongside unmarked defaults, then identifies distinguishing words. Results show GPT-3.5 and GPT-4 portrayals contain higher rates of racial stereotypes than human-written portrayals. An intersectional lens reveals tropes dominating portrayals of marginalized groups.

#### Resumen (Español)

Se presenta Personas Marcadas, un método basado en instrucciones para medir estereotipos en modelos de lenguaje de gran escala para grupos demográficos interseccionales sin léxico o etiquetado. Fundamentado en el concepto de marcación, el método solicita a los modelos generar personas de grupos objetivo junto con valores predeterminados no marcados, luego identifica palabras distintivas. Los resultados muestran que las representaciones de GPT-3.5 y GPT-4 contienen tasas más altas de estereotipos raciales que representaciones escritas por humanos. Una perspectiva interseccional revela tropos que dominan las representaciones de grupos marginalizados.

---

<a id="article-57"></a>

### Artículo 57

**Título original:** Theory-Grounded Measurement of U.S. Social Stereotypes in English Language Models

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2022 | **Idioma:** Inglés

**Autores:** Yang Trista Cao, Anna Sotnikova, Hal Daumé III, Rachel Rudinger, Linda Zou

**Keywords:** Natural Language Processing, Social Stereotypes, Language Models, Intersectional Identities, ABC Stereotype Model

**URL:** https://aclanthology.org/2022.naacl-main.92/

#### Abstract (English)

The Agency-Belief-Communion (ABC) stereotype model from social psychology is adapted as a framework for systematic study of stereotypic group-trait associations in language models. The sensitivity test (SeT) is introduced for measuring stereotypical associations. To evaluate SeT using the ABC model, group-trait judgments from U.S. subjects were collected for comparison with English language model stereotypes. The framework extends to measure stereotyping of intersectional identities.

#### Resumen (Español)

Se adapta el modelo de estereotipos Agencia-Creencia-Comunión (ABC) de la psicología social como marco para estudio sistemático de asociaciones estereotípicas grupo-rasgo en modelos de lenguaje. Se introduce la prueba de sensibilidad (SeT) para medir asociaciones estereotípicas. Para evaluar SeT mediante el modelo ABC, se recopilaron juicios grupo-rasgo de sujetos estadounidenses para comparación con estereotipos de modelos de lenguaje inglés. El marco se extiende para medir estereotipos de identidades interseccionales.

---

<a id="article-58"></a>

### Artículo 58

**Título original:** Uncovering Stereotypes in Large Language Models: A Task Complexity-Based Approach

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Hari Shrawgi, Prasanjit Rath, Tushar Singhal, Sandipan Dandapat

**Keywords:** Large Language Models, Bias evaluation, Stereotypes, AI ethics, Social bias, Task complexity, Nationality, Gender, Race, Religion

**URL:** https://aclanthology.org/2024.eacl-long.111/

#### Abstract (English)

Holistic bias evaluation is addressed with an extensible benchmark, the LLM Stereotype Index (LSI), grounded in the Social Progress Index. Breadth and depth of bias protection are tested via tasks with varying complexities. ChatGPT and GPT-4 exhibit strong inherent prejudice with respect to nationality, gender, race, and religion. Exhibition of issues becomes increasingly apparent as task complexity increases. GPT-4 is better at hiding biases, but when displayed they are more significant.

#### Resumen (Español)

Se aborda la evaluación holística de sesgo con un benchmark extensible, el Índice de Estereotipos de modelos de lenguaje (LSI), fundamentado en el Índice de Progreso Social. Se prueba amplitud y profundidad de protección de sesgo mediante tareas con complejidades variables. ChatGPT y GPT-4 exhiben prejuicios inherentes fuertes respecto a nacionalidad, género, raza y religión. La exhibición de problemas se vuelve cada vez más aparente a medida que aumenta la complejidad de la tarea. GPT-4 es mejor ocultando sesgos, pero cuando se muestran son más significativos.

---

<a id="article-59"></a>

### Artículo 59

**Título original:** Inclusivity in Large Language Models: Personality Traits and Gender Bias in Scientific Abstracts

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Naseela Pervez, Alexander J. Titus

**Keywords:** Computation and Language, Artificial Intelligence, Large Language Models, Gender Bias, Scientific Writing

**URL:** https://arxiv.org/abs/2406.19497

#### Abstract (English)

Alignment of three prominent large language models - Claude 3 Opus, Mistral AI Large, and Gemini 1.5 Flash - is assessed by analyzing their performance on benchmark text-generation tasks for scientific abstracts. Using the LIWC framework to extract features from generated texts, findings indicate that while models generally produce text resembling human content, variations in stylistic features suggest significant gender biases. This highlights the importance of developing models that maintain diversity of writing styles.

#### Resumen (Español)

Se evalúa la alineación de tres modelos de lenguaje de gran escala prominentes - Claude 3 Opus, Mistral AI Large y Gemini 1.5 Flash - analizando su rendimiento en tareas de generación de texto de benchmark para resúmenes científicos. Mediante el marco LIWC para extraer características de textos generados, los hallazgos indican que aunque los modelos generalmente producen texto similar al contenido humano, variaciones en características estilísticas sugieren sesgos de género significativos. Esto destaca la importancia de desarrollar modelos que mantengan diversidad de estilos de escritura.

---

<a id="article-60"></a>

### Artículo 60

**Título original:** Exploring the Personality Traits of LLMs Through Latent Feature Steering

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Shu Yang, Shenzhe Zhu, Liang Liu, Lijie Hu, Mengdi Li, Di Wang

**Keywords:** Computation and Language, Artificial Intelligence, Large Language Models, Personality Traits, Model Interpretability

**URL:** https://arxiv.org/abs/2410.10863

#### Abstract (English)

How various factors encoded within large language models shape their personality traits is investigated, guided by the social determinism theoretical framework. Inspired by interpretability work, a training-free approach is proposed to modify model behavior by extracting and steering latent features corresponding to factors within the model. Implications of these factors for model safety are analyzed, focusing on their impact through the lens of personality.

#### Resumen (Español)

Se investiga cómo diversos factores codificados dentro de modelos de lenguaje de gran escala dan forma a sus rasgos de personalidad, guiado por el marco teórico del determinismo social. Inspirado por trabajo de interpretabilidad, se propone un enfoque libre de entrenamiento para modificar el comportamiento del modelo extrayendo y dirigiendo características latentes correspondientes a factores dentro del modelo. Se analizan las implicaciones de estos factores para la seguridad del modelo, enfocándose en su impacto a través de la perspectiva de la personalidad.

---

<a id="article-61"></a>

### Artículo 61

**Título original:** Investigating the Impact of LLM Personality on the Manifestation of Cognitive Biases in Decision-Making Tasks

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Jiangen He, Jiqun Liu

**Keywords:** Artificial Intelligence, Large Language Models, Cognitive Biases, Decision-Making, Personality Traits

**URL:** https://arxiv.org/abs/2502.14219

#### Abstract (English)

How personality traits influence cognitive biases in large language models is explored, and effectiveness of mitigation strategies across model architectures is evaluated. Six prevalent cognitive biases are identified while sunk cost and group attribution biases show minimal impact. Personality traits play crucial roles in either amplifying or reducing biases. Responsibility and agreeableness may enhance efficacy of bias mitigation strategies, suggesting models exhibiting these traits are more receptive to corrective measures.

#### Resumen (Español)

Se explora cómo los rasgos de personalidad influyen en sesgos cognitivos en modelos de lenguaje de gran escala, y se evalúa la efectividad de estrategias de mitigación a través de arquitecturas de modelo. Se identifican seis sesgos cognitivos prevalentes mientras que los sesgos de costo hundido y atribución de grupo muestran impacto mínimo. Los rasgos de personalidad desempeñan roles cruciales al amplificar o reducir sesgos. Responsabilidad y amabilidad pueden mejorar la eficacia de estrategias de mitigación de sesgo, sugiriendo que los modelos que exhiben estos rasgos son más receptivos a medidas correctivas.

---

<a id="article-62"></a>

### Artículo 62

**Título original:** Large Language Models Portray Socially Subordinate Groups as More Homogeneous, Consistent with a Bias Observed in Humans

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Messi H.J. Lee, Jacob M. Montgomery, Calvin K. Lai

**Keywords:** Large Language Models, Social bias, Homogeneity perception, Racial minorities, Fairness, Accountability

**URL:** https://dl.acm.org/doi/10.1145/3630106.3658975

#### Abstract (English)

A new form of bias in large language models resembling a social psychological phenomenon is investigated, where socially subordinate groups are perceived as more homogeneous than dominant groups. ChatGPT was prompted to generate texts about intersectional group identities for comparison on homogeneity measures. ChatGPT portrayed African, Asian, and Hispanic Americans as more homogeneous than White Americans, describing racial minority groups with a narrower range of human experience. Women were also portrayed as more homogeneous than men, though differences were small.

#### Resumen (Español)

Se investiga una nueva forma de sesgo en modelos de lenguaje de gran escala que se asemeja a un fenómeno psicológico social, donde los grupos socialmente subordinados se perciben como más homogéneos que los grupos dominantes. Se solicitó a ChatGPT generar textos sobre identidades de grupos interseccionales para comparación en medidas de homogeneidad. ChatGPT retrató a afroamericanos, asiaticoamericanos e hispanoamericanos como más homogéneos que los estadounidenses blancos, describiendo grupos minoritarios raciales con una gama más estrecha de experiencia humana. Las mujeres también fueron retratadas como más homogéneas que los hombres, aunque las diferencias fueron pequeñas.

---

<a id="article-63"></a>

### Artículo 63

**Título original:** Performance and Biases of Large Language Models in Simulating Public Opinion

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Yao Qu, Jue Wang

**Keywords:** Large Language Models, Public opinion simulation, World Values Survey, Bias, Cultural differences

**URL:** https://www.nature.com/articles/s41599-024-03609-x

#### Abstract (English)

ChatGPT's performance in simulating public opinion is evaluated using World Values Survey data across diverse contexts. Significant performance disparities are found, especially when comparing countries, with the model performing better in Western, English-speaking, developed nations. Demographic biases related to gender, ethnicity, age, education, and social class are uncovered. Accuracy is significantly higher in Western countries and much lower elsewhere, with simulated responses exhibiting demographic biases.

#### Resumen (Español)

Se evalúa el rendimiento de ChatGPT en simulación de opinión pública mediante datos de la Encuesta Mundial de Valores a través de contextos diversos. Se encuentran disparidades de rendimiento significativas, especialmente al comparar países, con el modelo desempeñándose mejor en naciones occidentales, de habla inglesa y desarrolladas. Se descubren sesgos demográficos relacionados con género, etnia, edad, educación y clase social. La precisión es significativamente mayor en países occidentales y mucho menor en otros lugares, con respuestas simuladas exhibiendo sesgos demográficos.

---

<a id="article-64"></a>

### Artículo 64

**Título original:** Measuring Gender and Racial Biases in Large Language Models: Intersectional Evidence from Automatic Resume Evaluation

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Jiafu An, Difang Huang, Chen Lin, Mingzhu Tai

**Keywords:** Large Language Models, Gender bias, Racial bias, Intersectionality, Resume evaluation, Hiring discrimination

**URL:** https://academic.oup.com/pnasnexus/article/4/3/pgaf089/8071848

#### Abstract (English)

Gender and racial biases in commonly used large language models including GPT-3.5 Turbo, GPT-4o, Gemini 1.5 Flash, Claude 3.5 Sonnet, and Llama 3-70b are investigated in resume evaluation context. Models were instructed to score approximately 361,000 resumes with randomized social identities. Models award higher assessment scores for female candidates with similar qualifications, while many are biased against black male candidates. These biases may result in 1-3 percentage-point differences in hiring probabilities for similar candidates.

#### Resumen (Español)

Se investigan sesgos de género y raciales en modelos de lenguaje de gran escala comúnmente usados incluyendo GPT-3.5 Turbo, GPT-4o, Gemini 1.5 Flash, Claude 3.5 Sonnet y Llama 3-70b en contexto de evaluación de currículum. Se instruyó a los modelos para calificar aproximadamente 361,000 currículums con identidades sociales aleatorizadas. Los modelos otorgan puntuaciones de evaluación más altas para candidatas femeninas con calificaciones similares, mientras que muchos están sesgados contra candidatos masculinos negros. Estos sesgos pueden resultar en diferencias de 1-3 puntos porcentuales en probabilidades de contratación para candidatos similares.

---

<a id="article-65"></a>

### Artículo 65

**Título original:** Large Language Models Can Infer Psychological Dispositions of Social Media Users

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Heinrich Peters, Sandra C. Matz

**Keywords:** Large Language Models, Personality inference, Big Five, Social media, Zero-shot learning, GPT-3.5, GPT-4

**URL:** https://academic.oup.com/pnasnexus/article/3/6/pgae231/7692212

#### Abstract (English)

Whether large language models like ChatGPT can accurately infer psychological dispositions of social media users is investigated. Specifically, whether GPT-3.5 and GPT-4 can derive Big Five personality traits from users' Facebook status updates in a zero-shot learning scenario is tested. Results showed average correlation of r = .29 between model-inferred and self-reported trait scores, accuracy similar to supervised machine learning models trained for personality inference. Heterogeneity in accuracy across age groups and gender categories is highlighted.

#### Resumen (Español)

Se investiga si modelos de lenguaje de gran escala como ChatGPT pueden inferir con precisión disposiciones psicológicas de usuarios de redes sociales. Específicamente, se prueba si GPT-3.5 y GPT-4 pueden derivar rasgos de personalidad de los Cinco Grandes de actualizaciones de estado de Facebook de usuarios en escenario de aprendizaje de cero disparos. Los resultados mostraron correlación promedio de r = .29 entre puntuaciones de rasgos inferidas por el modelo y autoinformadas, precisión similar a modelos de aprendizaje automático supervisado entrenados para inferencia de personalidad. Se destaca heterogeneidad en precisión a través de grupos de edad y categorías de género.

---

<a id="article-66"></a>

### Artículo 66

**Título original:** How Do Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Yin Jou Huang, Rafik Hadfi

**Keywords:** Personality traits, Large language models, Negotiation simulation, Decision-making, Big Five, Bargaining dialogues

**URL:** https://aclanthology.org/2024.findings-emnlp.605/

#### Abstract (English)

A simulation framework centered on large language model agents endowed with synthesized personality traits is introduced. Agents negotiate within bargaining domains and possess customizable personalities and objectives. Experimental results show behavioral tendencies of simulations can reproduce behavioral patterns observed in human negotiations. The contribution is twofold: proposing simulation methodology investigating alignment between linguistic and economic capabilities of agents, and offering empirical insights into strategic impacts of Big Five traits on bilateral negotiation outcomes.

#### Resumen (Español)

Se introduce un marco de simulación centrado en agentes de modelos de lenguaje de gran escala dotados de rasgos de personalidad sintetizados. Los agentes negocian dentro de dominios de negociación y poseen personalidades y objetivos personalizables. Los resultados experimentales muestran que las tendencias conductuales de las simulaciones pueden reproducir patrones conductuales observados en negociaciones humanas. La contribución es doble: proponer metodología de simulación investigando alineación entre capacidades lingüísticas y económicas de agentes, y ofrecer perspectivas empíricas sobre impactos estratégicos de rasgos de los Cinco Grandes en resultados de negociaciones bilaterales.

---

<a id="article-67"></a>

### Artículo 67

**Título original:** Unveiling Personality Traits: A New Benchmark Dataset for Explainable Personality Recognition in Dialogues

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Lei Sun, Jinming Zhao, Qin Jin

**Keywords:** Personality recognition, Explainable AI, Dialogue analysis, Personality traits, Machine learning, Chain-of-Personality-Evidence (CoPE)

**URL:** https://aclanthology.org/2024.emnlp-main.1115/

#### Abstract (English)

A novel task named Explainable Personality Recognition is proposed, aiming to reveal the reasoning process as supporting evidence of personality traits. Inspired by personality theories where traits are composed of stable patterns of personality states, the Chain-of-Personality-Evidence (CoPE) framework is proposed, involving reasoning from specific contexts to short-term states to long-term traits. Based on CoPE, the explainable personality recognition dataset PersonalityEvd is constructed from dialogues, introducing two tasks requiring models to recognize labels and supporting evidence.

#### Resumen (Español)

Se propone una tarea novedosa denominada Reconocimiento de Personalidad Explicable, con el objetivo de revelar el proceso de razonamiento como evidencia de apoyo de los rasgos de personalidad. Inspirado por teorías de personalidad donde los rasgos se componen de patrones estables de estados de personalidad, se propone el marco Cadena-de-Evidencia-de-Personalidad (CoPE), involucrando razonamiento desde contextos específicos a estados de corto plazo hasta rasgos de largo plazo. Basado en CoPE, se construye el conjunto de datos de reconocimiento de personalidad explicable PersonalityEvd a partir de diálogos, introduciendo dos tareas que requieren que los modelos reconozcan etiquetas y evidencia de apoyo.

---

<a id="article-68"></a>

### Artículo 68

**Título original:** Bias and Fairness in Large Language Models: A Survey

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Isabel O. Gallegos, Ryan A. Rossi, Joe Barrow, Md Mehrab Tanjim, Sungchul Kim, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, Nesreen K. Ahmed

**Keywords:** Large Language Models, Bias evaluation, Fairness, Social bias, Natural language processing, AI ethics

**URL:** https://direct.mit.edu/coli/article/50/3/1097/121961/

#### Abstract (English)

Bias evaluation and mitigation techniques for large language models are presented in this comprehensive survey, consolidating, formalizing, and expanding notions of social bias and fairness in natural language processing. Three intuitive taxonomies are proposed: two for bias evaluation (metrics and datasets) and one for mitigation. Distinct facets of harm are defined, desiderata to operationalize fairness are introduced, and metrics are organized by different operational levels: embeddings, probabilities, and generated text.

#### Resumen (Español)

Se presentan técnicas de evaluación y mitigación de sesgo para modelos de lenguaje de gran escala en esta revisión integral, consolidando, formalizando y expandiendo nociones de sesgo social y equidad en procesamiento de lenguaje natural. Se proponen tres taxonomías intuitivas: dos para evaluación de sesgo (métricas y conjuntos de datos) y una para mitigación. Se definen facetas distintas de daño, se introducen requisitos para operacionalizar equidad, y se organizan métricas por diferentes niveles operacionales: embeddings, probabilidades y texto generado.

---

<a id="article-69"></a>

### Artículo 69

**Título original:** Identifying and Manipulating Personality Traits in LLMs Through Activation Engineering

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Rumi Allbert, James K. Wiles, Vlad Grankovsky

**Keywords:** Computation and Language, Artificial Intelligence, Large Language Models, Activation Engineering, Personality Traits

**URL:** https://arxiv.org/abs/2412.10427

#### Abstract (English)

Personality modification in large language models is explored, building on the novel approach of activation engineering. A method for identifying and adjusting activation directions related to personality traits is developed, which may allow for dynamic personality fine-tuning. This work aims to further understanding of model interpretability while examining ethical implications of such developments.

#### Resumen (Español)

Se explora la modificación de personalidad en modelos de lenguaje de gran escala, construyendo sobre el enfoque novedoso de ingeniería de activación. Se desarrolla un método para identificar y ajustar direcciones de activación relacionadas con rasgos de personalidad, lo que puede permitir ajuste fino dinámico de personalidad. Este trabajo tiene como objetivo profundizar la comprensión de la interpretabilidad del modelo mientras examina las implicaciones éticas de tales desarrollos.

---

<a id="article-70"></a>

### Artículo 70

**Título original:** PUB: A Personality-Enhanced LLM-Driven User Behavior Simulator for Recommender System Evaluation

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Chenglong Ma, Ziqi Xu, Yongli Ren, Danula Hettiachchi, Jeffrey Chan

**Keywords:** Information Retrieval, Recommender Systems, User Behavior Simulation, Personality Traits, Large Language Models

**URL:** https://arxiv.org/abs/2506.04551

#### Abstract (English)

The Personality-driven User Behaviour Simulator (PUB) is proposed, a simulation framework based on large language models integrating Big Five personality traits to model personalized user behaviour. PUB dynamically infers user personality from behavioural logs and item metadata, then generates synthetic interactions preserving statistical fidelity to real-world data. Experiments show logs generated by PUB closely align with real user behaviour and reveal meaningful associations between personality traits and recommendation outcomes.

#### Resumen (Español)

Se propone el Simulador de Comportamiento de Usuario Impulsado por Personalidad (PUB), un marco de simulación basado en modelos de lenguaje de gran escala que integra rasgos de personalidad de los Cinco Grandes para modelar comportamiento de usuario personalizado. PUB infiere dinámicamente la personalidad del usuario desde registros conductuales y metadatos de ítems, luego genera interacciones sintéticas preservando fidelidad estadística a datos del mundo real. Los experimentos muestran que los registros generados por PUB se alinean estrechamente con el comportamiento de usuario real y revelan asociaciones significativas entre rasgos de personalidad y resultados de recomendación.

---

<a id="article-71"></a>

### Artículo 71

**Título original:** Can LLMs Generate Behaviors for Embodied Virtual Agents Based on Personality Traits?

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Bin Han, Deuksin Kwon, Spencer Lin, Kaleen Shrestha, Jonathan Gratch

**Keywords:** Human-Computer Interaction, Large Language Models, Virtual Agents, Personality Traits, Extraversion

**URL:** https://arxiv.org/abs/2508.21087

#### Abstract (English)

A framework employing personality prompting with large language models is proposed to generate verbal and nonverbal behaviors for virtual agents based on personality traits. Focusing on extraversion, the system was evaluated in negotiation and ice-breaking scenarios using introverted and extroverted agents. Results demonstrate that large language models can generate verbal and nonverbal behaviors aligning with personality traits, and users are able to recognize these traits through agents' behaviors. These findings underscore the potential of large language models in shaping personality-aligned virtual agents.

#### Resumen (Español)

Se propone un marco que emplea instrucciones de personalidad con modelos de lenguaje de gran escala para generar comportamientos verbales y no verbales en agentes virtuales basados en rasgos de personalidad. Con enfoque en extraversión, el sistema fue evaluado en escenarios de negociación y rompehielos utilizando agentes introvertidos y extrovertidos. Los resultados demuestran que los modelos de lenguaje de gran escala pueden generar comportamientos verbales y no verbales alineados con rasgos de personalidad, y los usuarios son capaces de reconocer estos rasgos a través de los comportamientos de los agentes. Estos hallazgos subrayan el potencial de los modelos de lenguaje de gran escala en moldear agentes virtuales alineados con la personalidad.

---

<a id="article-72"></a>

### Artículo 72

**Título original:** Personality-Driven Decision-Making in LLM-Based Autonomous Agents

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Lewis Newsham, Daniel Prince

**Keywords:** Artificial Intelligence, Multiagent Systems, Large Language Models, Autonomous Agents, OCEAN model, Cyber Defense

**URL:** https://arxiv.org/abs/2504.00727

#### Abstract (English)

Building on previous work introducing SANDMAN, a Deceptive Agent architecture leveraging the Five-Factor OCEAN personality model, a novel method is presented for measuring and evaluating how induced personality traits affect task selection processes—specifically planning, scheduling, and decision-making—in agents based on large language models. Results reveal distinct task-selection patterns aligned with induced OCEAN attributes, underscoring the feasibility of designing highly plausible Deceptive Agents for proactive cyber defense strategies.

#### Resumen (Español)

Basándose en trabajo previo que introdujo SANDMAN, una arquitectura de Agente Engañoso que aprovecha el modelo de personalidad OCEAN de Cinco Factores, se presenta un método novedoso para medir y evaluar cómo los rasgos de personalidad inducidos afectan los procesos de selección de tareas—específicamente planificación, programación y toma de decisiones—en agentes basados en modelos de lenguaje de gran escala. Los resultados revelan patrones distintos de selección de tareas alineados con atributos OCEAN inducidos, subrayando la viabilidad de diseñar Agentes Engañosos altamente plausibles para estrategias proactivas de defensa cibernética.

---

<a id="article-73"></a>

### Artículo 73

**Título original:** LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Ivar Frisch, Mario Giulianelli

**Keywords:** Large Language Models, Agent interaction, Personality consistency, Linguistic alignment, Dialogue-based interaction

**URL:** https://aclanthology.org/2024.personalize-1.9/

#### Abstract (English)

This experimental study seeks to lay groundwork for understanding dialogue-based interaction between large language models by conditioning GPT-3.5 on asymmetric personality profiles to create a population of agents. Agents were administered personality tests and submitted to a collaborative writing task. Findings reveal that different profiles exhibit different degrees of personality consistency and linguistic alignment in interaction.

#### Resumen (Español)

Este estudio experimental busca establecer la base para entender la interacción basada en diálogo entre modelos de lenguaje de gran escala condicionando GPT-3.5 en perfiles de personalidad asimétricos para crear una población de agentes. Los agentes fueron administrados pruebas de personalidad y sometidos a una tarea de escritura colaborativa. Los hallazgos revelan que diferentes perfiles exhiben diferentes grados de consistencia de personalidad y alineación lingüística en la interacción.

---

<a id="article-74"></a>

### Artículo 74

**Título original:** Automated LLM Questionnaire for Automatic Psychiatric Assessment

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Gony Rosenman, Talma Hendler, Lior Wolf

**Keywords:** Large Language Models, Psychiatric Assessment, Mental Health, Depression (PHQ-8), PTSD (PCL-C), Psychological Interviews

**URL:** https://aclanthology.org/2024.findings-emnlp.23/

#### Abstract (English)

A large language model is employed to convert unstructured psychological interviews into structured questionnaires spanning various psychiatric and personality domains. The model is prompted to answer questionnaires by impersonating the interviewee. Obtained answers are coded as features used to predict standardized psychiatric measures of depression (PHQ-8) and PTSD (PCL-C) using Random Forest regression. The approach enhances diagnostic accuracy compared to multiple baselines, establishing a novel framework for interpreting psychological interviews.

#### Resumen (Español)

Se emplea un modelo de lenguaje de gran escala para convertir entrevistas psicológicas no estructuradas en cuestionarios estructurados que abarcan diversos dominios psiquiátricos y de personalidad. Se instruye al modelo para responder cuestionarios personificando al entrevistado. Las respuestas obtenidas se codifican como características utilizadas para predecir medidas psiquiátricas estandarizadas de depresión (PHQ-8) y estrés postraumático (PCL-C) mediante regresión Random Forest. El enfoque mejora la precisión diagnóstica en comparación con múltiples líneas base, estableciendo un marco novedoso para interpretar entrevistas psicológicas.

---

<a id="article-75"></a>

### Artículo 75

**Título original:** Psychometric Shaping of Personality Modulates Capabilities and Safety in Language Models

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Stephen Fitz, Peter Romero, Steven Basart, Sipeng Chen, Jose Hernandez-Orallo

**Keywords:** Artificial Intelligence, Computation and Language, Large Language Models, Personality Traits, Model Safety

**URL:** https://arxiv.org/abs/2509.16332

#### Abstract (English)

How psychometric personality control grounded in the Big Five framework influences AI behavior in capability and safety benchmarks is investigated. Experiments reveal striking effects: reducing conscientiousness leads to significant drops in safety-relevant metrics on benchmarks such as WMDP, TruthfulQA, ETHICS, and Sycophancy, as well as reduction in general capabilities measured by MMLU. Findings highlight personality shaping as a powerful and underexplored axis of model control that interacts with both safety and competence.

#### Resumen (Español)

Se investiga cómo el control psicométrico de personalidad fundamentado en el marco de los Cinco Grandes influye en el comportamiento de inteligencia artificial en pruebas de referencia de capacidad y seguridad. Los experimentos revelan efectos notables: reducir la responsabilidad conduce a caídas significativas en métricas relevantes de seguridad en pruebas como WMDP, TruthfulQA, ETHICS y Sycophancy, así como reducción en capacidades generales medidas por MMLU. Los hallazgos destacan el moldeo de personalidad como un eje poderoso y poco explorado de control de modelo que interactúa tanto con la seguridad como con la competencia.

---

<a id="article-76"></a>

### Artículo 76

**Título original:** Humanizing LLMs: A Survey of Psychological Measurements with Tools, Datasets, and Human-Agent Applications

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Wenhan Dong, Yuemeng Zhao, Zhen Sun, Yule Liu, Zifan Peng, Jingyi Zheng, Zongmin Zhang, Ziyi Zhang, Jun Wu, Ruiming Wang, Shengmin Xu, Xinyi Huang, Xinlei He

**Keywords:** Computers and Society, Computation and Language, Human-Computer Interaction, Machine Learning, Psychological traits, Trustworthy AI

**URL:** https://arxiv.org/abs/2505.00049

#### Abstract (English)

Six key dimensions of applying psychological theories to large language models are systematically covered: assessment tools, model-specific datasets, evaluation metrics (consistency and stability), empirical findings, personality simulation methods, and behavior simulation. The analysis highlights both strengths and limitations of current methods. While some models exhibit reproducible personality patterns under specific prompting schemes, significant variability remains across tasks and settings. Future directions are proposed for developing interpretable, robust, and generalizable psychological assessment frameworks.

#### Resumen (Español)

Se cubren sistemáticamente seis dimensiones clave de aplicar teorías psicológicas a modelos de lenguaje de gran escala: herramientas de evaluación, conjuntos de datos específicos del modelo, métricas de evaluación (consistencia y estabilidad), hallazgos empíricos, métodos de simulación de personalidad y simulación de comportamiento. El análisis destaca tanto las fortalezas como las limitaciones de los métodos actuales. Aunque algunos modelos exhiben patrones de personalidad reproducibles bajo esquemas específicos de instrucciones, permanece una variabilidad significativa entre tareas y configuraciones. Se proponen direcciones futuras para desarrollar marcos de evaluación psicológica interpretables, robustos y generalizables.

---

<a id="article-77"></a>

### Artículo 77

**Título original:** Large Language Models Demonstrate Distinctive Personality Profiles

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Thomas F Heston, Justin Gillette

**Keywords:** AI ethics, AI in mental health, AI psychometrics, Artificial intelligence in medicine, Generative AI, Personality assessment

**URL:** https://pmc.ncbi.nlm.nih.gov/articles/PMC12183331/

#### Abstract (English)

The first psychometric analysis of large language model personality is provided using two validated frameworks: Open Extended Jungian Type Scales (OEJTS) and Big Five Personality Test. Four leading models (ChatGPT-3.5, Gemini Advanced, Claude 3 Opus, Grok-Regular Mode) were evaluated in April 2024. MANOVA revealed statistically significant differences across models in personality traits. Distinct personality profiles are consistently expressed across different models, underscoring the need for formal personality evaluation before clinical deployment.

#### Resumen (Español)

Se proporciona el primer análisis psicométrico de personalidad de modelos de lenguaje de gran escala utilizando dos marcos validados: Escalas de Tipo Junguiano Extendido Abierto (OEJTS) y Prueba de Personalidad de los Cinco Grandes. Cuatro modelos líderes (ChatGPT-3.5, Gemini Advanced, Claude 3 Opus, Grok-Regular Mode) fueron evaluados en abril de 2024. MANOVA reveló diferencias estadísticamente significativas entre modelos en rasgos de personalidad. Perfiles de personalidad distintos se expresan consistentemente entre diferentes modelos, subrayando la necesidad de evaluación formal de personalidad antes del despliegue clínico.

---

<a id="article-78"></a>

### Artículo 78

**Título original:** Attitudes Toward AI: Measurement and Associations with Personality

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** J.P. Stein, T. Messingschlager, T. Gnambs, F. Hutmacher, M. Appel

**Keywords:** Artificial Intelligence attitudes, Big Five personality, Dark Triad, Conspiracy beliefs, ATTARI-12 questionnaire

**URL:** https://www.nature.com/articles/s41598-024-53335-2

#### Abstract (English)

A novel psychologically informed questionnaire (ATTARI-12) is presented capturing attitudes towards AI as a single construct independent of specific contexts. The questionnaire demonstrated good reliability and validity across two studies (N1 = 490; N2 = 150). Personality traits—Big Five, Dark Triad, and conspiracy mentality—were examined as potential predictors. Agreeableness and younger age predict more positive views towards AI technology, whereas susceptibility to conspiracy beliefs is associated with more negative attitudes.

#### Resumen (Español)

Se presenta un cuestionario psicológicamente informado novedoso (ATTARI-12) que captura actitudes hacia la inteligencia artificial como un constructo único independiente de contextos específicos. El cuestionario demostró buena confiabilidad y validez en dos estudios (N1 = 490; N2 = 150). Se examinaron rasgos de personalidad—Cinco Grandes, Tríada Oscura y mentalidad conspirativa—como predictores potenciales. La amabilidad y la edad más joven predicen vistas más positivas hacia la tecnología de inteligencia artificial, mientras que la susceptibilidad a creencias conspirativas se asocia con actitudes más negativas.

---

<a id="article-79"></a>

### Artículo 79

**Título original:** Do LLMs Have a Personality? A Psychometric Assessment with Implications for Clinical Medicine and Mental Health AI

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Thomas F Heston, Justin Gillette

**Keywords:** Psychiatry, Clinical Psychology, Mental Health AI, Large Language Models, Personality Assessment, Clinical Medicine

**URL:** https://www.medrxiv.org/content/10.1101/2025.03.14.25323987v1

#### Abstract (English)

Personality profiles of four leading large language models in 2024 were characterized using two validated frameworks: Open Extended Jungian Type Scales and Big Five Personality Test. MANOVA revealed statistically significant differences across models in personality traits. ChatGPT-3.5 was most often classified as ENTJ, Claude 3 Opus as INTJ, while Gemini Advanced and Grok-Regular leaned toward INFJ. Distinct personality profiles are consistently expressed across different models, emphasizing the need for formal personality evaluation before deploying models in clinical workflows.

#### Resumen (Español)

Se caracterizaron perfiles de personalidad de cuatro modelos de lenguaje de gran escala líderes en 2024 utilizando dos marcos validados: Escalas de Tipo Junguiano Extendido Abierto y Prueba de Personalidad de los Cinco Grandes. MANOVA reveló diferencias estadísticamente significativas entre modelos en rasgos de personalidad. ChatGPT-3.5 fue clasificado más frecuentemente como ENTJ, Claude 3 Opus como INTJ, mientras que Gemini Advanced y Grok-Regular se inclinaron hacia INFJ. Perfiles de personalidad distintos se expresan consistentemente entre diferentes modelos, enfatizando la necesidad de evaluación formal de personalidad antes de desplegar modelos en flujos de trabajo clínicos.

---

<a id="article-80"></a>

### Artículo 80

**Título original:** Developing and Enhancing Personality Inventories Using Generative AI: Psychometric Properties of a Short HEXACO Scale Developed with ChatGPT

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Ard J. Barends, Reinout E. de Vries

**Keywords:** Artificial Intelligence, Generative AI, HEXACO personality inventory, ChatGPT 4.0, Psychometrics, Survey development, Content validity

**URL:** https://www.tandfonline.com/doi/full/10.1080/00223891.2024.2444454

#### Abstract (English)

A 24-item HEXACO personality inventory was generated using ChatGPT 4.0, called ChatGPT HEXACO inventory (CHI). Whether ChatGPT could modify CHI to improve its internal consistency or content validity was investigated. Participants (N = 682) completed Brief HEXACO Inventory (BHI) and HEXACO-60 and were randomly assigned to complete one of three CHI versions. Results showed generally comparable psychometric properties across the three CHI versions and BHI. However, ChatGPT could not improve specific psychometric properties of CHI.

#### Resumen (Español)

Se generó un inventario de personalidad HEXACO de 24 ítems utilizando ChatGPT 4.0, denominado inventario HEXACO ChatGPT (CHI). Se investigó si ChatGPT podría modificar CHI para mejorar su consistencia interna o validez de contenido. Los participantes (N = 682) completaron el Inventario HEXACO Breve (BHI) y HEXACO-60, y fueron asignados aleatoriamente para completar una de tres versiones de CHI. Los resultados mostraron propiedades psicométricas generalmente comparables entre las tres versiones de CHI y BHI. Sin embargo, ChatGPT no pudo mejorar propiedades psicométricas específicas de CHI.

---

<a id="article-81"></a>

### Artículo 81

**Título original:** Exploring the Impact of Language Switching on Personality Manifestation in LLMs

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Jacopo Amidei, Jose Gregorio Ferreira De Sá, Rubén Nieto Luna, Andreas Kaltenbrunner

**Keywords:** Large Language Models, Personality Traits, Language Switching, GPT-4o, Eysenck Personality Questionnaire-Revised (EPQR-A), Cross-language analysis

**URL:** https://aclanthology.org/2025.coling-main.162/

#### Abstract (English)

The extent to which large language models align with humans when personality shifts are associated with language changes is investigated. Based on three experiments focusing on GPT-4o and the Eysenck Personality Questionnaire-Revised (EPQR-A), initial results reveal weak yet significant variation in GPT-4o's personality across languages, indicating some variations stem from language-switching effects rather than translation. Further analysis across five English-speaking countries shows GPT-4o, leveraging stereotypes, reflects distinct country-specific personality traits.

#### Resumen (Español)

Se investiga hasta qué punto los modelos de lenguaje de gran escala se alinean con humanos cuando los cambios de personalidad se asocian con cambios de idioma. Basándose en tres experimentos enfocados en GPT-4o y el Cuestionario de Personalidad de Eysenck-Revisado (EPQR-A), los resultados iniciales revelan variación débil pero significativa en la personalidad de GPT-4o entre idiomas, indicando que algunas variaciones provienen de efectos de cambio de idioma en lugar de traducción. Análisis adicional entre cinco países de habla inglesa muestra que GPT-4o, aprovechando estereotipos, refleja rasgos de personalidad específicos de cada país.

---

<a id="article-82"></a>

### Artículo 82

**Título original:** Personality Vector: Modulating Personality of Large Language Models by Model Merging

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Seungjong Sun, Seo Yeon Baek, Jang Hyun Kim

**Keywords:** personality modulation, model merging, personality vectors, Big Five traits, continuous control, multidimensional traits, personalized AI

**URL:** https://arxiv.org/abs/2509.19727

#### Abstract (English)

Driven by the demand for personalized AI systems, there is growing interest in aligning the behavior of large language models with human traits such as personality. Previous attempts to induce personality have shown promising results, but struggle to capture the continuous and multidimensional nature of human traits. A novel method for personality modulation via model merging is proposed. Specifically, personality vectors are constructed by subtracting the weights of a pre-trained model from those of the fine-tuned model on a given personality trait. By merging personality vectors, models are enabled to exhibit desired personality traits without additional training.

#### Resumen (Español)

Impulsada por la demanda de sistemas de inteligencia artificial personalizados, existe un creciente interés en alinear el comportamiento de los modelos de lenguaje de gran escala con rasgos humanos como la personalidad. Los intentos previos de inducir personalidad han mostrado resultados prometedores, pero tienen dificultades para capturar la naturaleza continua y multidimensional de los rasgos humanos. Se propone un método novedoso para la modulación de personalidad mediante fusión de modelos. Específicamente, se construyen vectores de personalidad restando los pesos de un modelo preentrenado de aquellos del modelo con ajuste fino en un rasgo de personalidad dado. Mediante la fusión de vectores de personalidad, se habilita a los modelos para exhibir rasgos de personalidad deseados sin entrenamiento adicional.

---

<a id="article-83"></a>

### Artículo 83

**Título original:** Humanoid Artificial Consciousness Designed with LLM Based on Psychoanalysis

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Sang Hun Kim, Dongkyu Park, Seo Ui Lee, Jiwon Yoon, Seok-Jun Bu

**Keywords:** artificial consciousness, psychoanalysis, MBTI, personality modules, character simulation, human-like cognition, self-awareness

**URL:** https://arxiv.org/abs/2510.09043

#### Abstract (English)

A novel approach is proposed to address challenges by integrating psychoanalysis and the Myers-Briggs Type Indicator (MBTI) into constructing consciousness and personality modules. Three artificial consciousnesses (self-awareness, unconsciousness, and preconsciousness) were developed based on the principles of psychoanalysis. Additionally, 16 characters with different personalities representing the sixteen MBTI types were designed.

#### Resumen (Español)

Se propone un enfoque novedoso para abordar desafíos integrando el psicoanálisis y el Indicador de Tipo Myers-Briggs (MBTI) en la construcción de módulos de consciencia y personalidad. Se desarrollaron tres consciencias artificiales (autoconciencia, inconsciencia y preconsciencia) basadas en los principios del psicoanálisis. Adicionalmente, se diseñaron 16 personajes con diferentes personalidades representando los dieciséis tipos MBTI.

---

<a id="article-84"></a>

### Artículo 84

**Título original:** Traits Run Deep: Enhancing Personality Assessment via Psychology-Guided LLM Representations

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Jia Li, Zhen Cui, Yan Lu, Liang Liu, Yuguang Yan, Chengsheng Yuan, Jinqiao Wang

**Keywords:** personality assessment, multimodal learning, psychology-informed prompts, cross-modal fusion, trait recognition, semantic representation, audio-visual features

**URL:** https://arxiv.org/abs/2507.22367

#### Abstract (English)

Accurate and reliable personality assessment plays a vital role in many fields. A novel personality assessment framework called Traits Run Deep is proposed. It employs psychology-informed prompts to elicit high-level personality-relevant semantic representations and devises a Text-Centric Trait Fusion Network.

#### Resumen (Español)

La evaluación precisa y confiable de la personalidad desempeña un papel vital en muchos campos. Se propone un marco novedoso de evaluación de personalidad denominado Traits Run Deep. Emplea instrucciones informadas por psicología para obtener representaciones semánticas de alto nivel relevantes para la personalidad y diseña una Red de Fusión de Rasgos Centrada en Texto.

---

<a id="article-85"></a>

### Artículo 85

**Título original:** PerFairX: Is There a Balance Between Fairness and Personality in LLM Recommendations?

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Chandan Kumar Sah

**Keywords:** personality-based recommendation, fairness evaluation, OCEAN model, LLM recommender systems, demographic equity, personalization trade-offs, zero-shot learning

**URL:** https://arxiv.org/abs/2509.08829

#### Abstract (English)

PerFairX, a unified evaluation framework designed to quantify the trade-offs between personalization and demographic equity in recommendations generated by large language models, is proposed. Results reveal that personality-aware prompting significantly improves alignment with individual traits but can exacerbate fairness disparities.

#### Resumen (Español)

Se propone PerFairX, un marco de evaluación unificado diseñado para cuantificar los compromisos entre personalización y equidad demográfica en recomendaciones generadas por modelos de lenguaje de gran escala. Los resultados revelan que las instrucciones conscientes de la personalidad mejoran significativamente la alineación con rasgos individuales pero pueden exacerbar disparidades de equidad.

---

<a id="article-86"></a>

### Artículo 86

**Título original:** Population-Aligned Persona Generation for LLM-based Social Simulation

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Zhengyu Hu, Zheyuan Xiao, Max Xiong, Yuxuan Lei, Tianfu Wang, Jianxun Lian, Kaize Ding, Ziang Xiao, Nicholas Jing Yuan, Xing Xie

**Keywords:** population alignment, persona generation, social simulation, Big Five traits, computational social science, importance sampling, bias reduction

**URL:** https://arxiv.org/abs/2509.10127

#### Abstract (English)

A systematic framework for synthesizing high-quality, population-aligned persona sets for social simulation driven by large language models is proposed. The approach leverages large language models to generate narrative personas from social media data, followed by quality assessment and importance sampling to achieve global alignment with psychometric distributions.

#### Resumen (Español)

Se propone un marco sistemático para sintetizar conjuntos de personas de alta calidad y alineados con la población para simulación social impulsada por modelos de lenguaje de gran escala. El enfoque aprovecha modelos de lenguaje de gran escala para generar personas narrativas a partir de datos de redes sociales, seguido de evaluación de calidad y muestreo por importancia para lograr alineación global con distribuciones psicométricas.

---

<a id="article-87"></a>

### Artículo 87

**Título original:** The Power of Personality: A Human Simulation Perspective to Investigate LLM Agents

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Yifan Duan, Yihong Tang, Xuefeng Bai, Kehai Chen, Juntao Li, Min Zhang

**Keywords:** human simulation, Big Five personality, multi-agent collaboration, creativity assessment, problem-solving, collective intelligence, agent performance

**URL:** https://arxiv.org/abs/2502.20859

#### Abstract (English)

Intelligence in large language models is systematically investigated through the lens of "human simulation", addressing how personality traits affect problem-solving and creativity. By assigning Big Five personality traits to agents, findings reveal that specific traits significantly influence reasoning accuracy and creative output.

#### Resumen (Español)

La inteligencia en modelos de lenguaje de gran escala se investiga sistemáticamente a través de la perspectiva de "simulación humana", abordando cómo los rasgos de personalidad afectan la resolución de problemas y la creatividad. Al asignar rasgos de personalidad de los Cinco Grandes a agentes, los hallazgos revelan que rasgos específicos influyen significativamente en la precisión del razonamiento y la producción creativa.

---

<a id="article-88"></a>

### Artículo 88

**Título original:** Exploring the Potential of Large Language Models to Simulate Personality

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Investigadores en IA conversacional

**Keywords:** personality simulation, conversational AI, Big Five model, dialogue personalization, personality-related text generation, LLM challenges, trait modeling

**URL:** https://arxiv.org/abs/2502.08265

#### Abstract (English)

With the advancement of large language models, the focus in Conversational AI has shifted to tackling more complex challenges, such as personalizing dialogue systems. Simulating personal traits according to the Big Five model is addressed. Research demonstrates that generating personality-related texts remains a challenging task.

#### Resumen (Español)

Con el avance de los modelos de lenguaje de gran escala, el enfoque en la inteligencia artificial conversacional ha cambiado hacia abordar desafíos más complejos, como personalizar sistemas de diálogo. Se aborda la simulación de rasgos personales según el modelo de los Cinco Grandes. La investigación demuestra que generar textos relacionados con personalidad sigue siendo una tarea desafiante.

---

<a id="article-89"></a>

### Artículo 89

**Título original:** Rediscovering the Latent Dimensions of Personality with LLMs as Trait Descriptors

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Joseph Suh, Suhong Moon, Minwoo Kang, David Chan

**Keywords:** personality assessment, Big Five traits, singular value decomposition, latent dimensions, trait descriptors, personality probing, LLM evaluation

**URL:** https://neurips.cc/virtual/2024/102146

#### Abstract (English)

A novel approach that uncovers latent personality dimensions in large language models by applying SVD to log-probabilities of trait-descriptive adjectives is introduced. Models "rediscover" core personality traits without relying on direct questionnaire inputs, with the top-5 factors explaining 74.3% of variance.

#### Resumen (Español)

Se introduce un enfoque novedoso que descubre dimensiones latentes de personalidad en modelos de lenguaje de gran escala aplicando SVD (descomposición en valores singulares) a las log-probabilidades de adjetivos descriptivos de rasgos. Los modelos "redescubren" rasgos de personalidad centrales sin depender de entradas directas de cuestionarios, con los 5 factores principales explicando el 74.3% de la varianza.

---

<a id="article-90"></a>

### Artículo 90

**Título original:** PICLe: Eliciting Diverse Behaviors from LLMs with Persona In-Context Learning

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Hyeong Kyu Choi, Sharon Li

**Keywords:** persona elicitation, in-context learning, Bayesian inference, behavioral preferences, personality traits, ICL, persona customization

**URL:** https://icml.cc/virtual/2024/poster/32764

#### Abstract (English)

Persona In-Context Learning (PICLe), a novel persona elicitation framework grounded in Bayesian inference, is presented. PICLe introduces a new in-context learning example selection criterion based on likelihood ratio, designed to optimally guide the model in eliciting a specific target persona.

#### Resumen (Español)

Se presenta Persona In-Context Learning (PICLe), un marco novedoso de obtención de persona fundamentado en inferencia bayesiana. PICLe introduce un nuevo criterio de selección de ejemplos de aprendizaje en contexto basado en razón de verosimilitud, diseñado para guiar óptimamente al modelo en la obtención de una persona objetivo específica.

---

<a id="article-91"></a>

### Artículo 91

**Título original:** Large Language Models as Superpositions of Cultural Perspectives

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Autores anónimos (ICLR 2024)

**Keywords:** cultural perspectives, personality stability, perspective shift, context dependency, value expression, psychological assessment, perspective controllability

**URL:** https://openreview.net/pdf?id=1FWDEIGm33

#### Abstract (English)

"Large language models as a superposition of perspectives" is proposed: models simulate a multiplicity of behaviors which can be triggered by context. Context changes are demonstrated to result in significant unwanted, hard-to-predict changes in expressed values, referred to as the unexpected perspective shift effect.

#### Resumen (Español)

Se propone "modelos de lenguaje de gran escala como una superposición de perspectivas": los modelos simulan una multiplicidad de comportamientos que pueden ser desencadenados por el contexto. Se demuestra que los cambios de contexto resultan en cambios significativos no deseados y difíciles de predecir en los valores expresados, denominados efecto de cambio inesperado de perspectiva.

---

<a id="article-92"></a>

### Artículo 92

**Título original:** LLM vs Small Model? LLM-Based Text Augmentation for Personality Detection

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Linmei Hu, Hongyu He, Duokang Wang, Ziwang Zhao, Yingxia Shao, Liqiang Nie

**Keywords:** personality detection, text augmentation, knowledge distillation, contrastive learning, psycho-linguistic analysis, social media, Big Five traits

**URL:** https://ojs.aaai.org/index.php/AAAI/article/view/29782

#### Abstract (English)

A text augmentation-enhanced personality detection model based on large language models is proposed, which distills knowledge from large language models to enhance the small model for personality detection. Large language models are enabled to generate post analyses from semantic, sentiment, and linguistic aspects.

#### Resumen (Español)

Se propone un modelo de detección de personalidad mejorado con aumento de texto basado en modelos de lenguaje de gran escala, que destila el conocimiento de modelos de lenguaje de gran escala para mejorar el modelo pequeño para la detección de personalidad. Se habilita a los modelos de lenguaje de gran escala para generar análisis de publicaciones desde aspectos semánticos, de sentimiento y lingüísticos.

---

<a id="article-93"></a>

### Artículo 93

**Título original:** Evaluating the Efficacy of LLMs to Emulate Realistic Human Personalities

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Luke James Klinkert, Silvia Buongiorno, Christopher Clark

**Keywords:** personality emulation, NPC behavior, game AI, personality alignment, human-like traits, LLM evaluation, interactive agents

**URL:** https://ojs.aaai.org/index.php/AIIDE/article/view/31867

#### Abstract (English)

Results indicate that NPCs can successfully emulate human-like personality traits using large language models. Frontier models achieved up to 100% alignment with human personality profiles, demonstrating that large language models can accurately represent desired human personalities for game characters.

#### Resumen (Español)

Los resultados indican que los personajes no jugadores (NPCs) pueden emular exitosamente rasgos de personalidad similares a los humanos utilizando modelos de lenguaje de gran escala. Los modelos de vanguardia lograron hasta 100% de alineación con perfiles de personalidad humanos, demostrando que los modelos de lenguaje de gran escala pueden representar con precisión personalidades humanas deseadas para personajes de juego.

---

<a id="article-94"></a>

### Artículo 94

**Título original:** InCharacter: Evaluating Personality Fidelity in Role-Playing Agents

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Xintao Wang, Yunze Xiao, Jen-tse Huang, Siyu Yuan, Rui Xu, Haoran Guo, Quan Tu, Yaying Fei, Ziang Leng, Wei Wang, Jiangjie Chen, Cheng Li, Yanghua Xiao

**Keywords:** role-playing agents, personality assessment, psychological scales, character fidelity, LLM evaluation, Big Five personality traits, psychometric testing

**URL:** https://aclanthology.org/2024.acl-long.102/

#### Abstract (English)

InCharacter, namely Interviewing Character agents for personality tests, is proposed. Experiments cover 32 distinct characters on 14 widely used psychological scales. State-of-the-art role-playing agents exhibit personalities highly aligned with human-perceived personalities of characters, achieving accuracy up to 80.7%.

#### Resumen (Español)

Se propone InCharacter, es decir, Entrevistar agentes de Personaje para pruebas de personalidad. Los experimentos cubren 32 personajes distintos en 14 escalas psicológicas ampliamente utilizadas. Los agentes de juego de roles de última generación exhiben personalidades altamente alineadas con las personalidades percibidas por humanos de los personajes, alcanzando una precisión de hasta 80.7%.

---

<a id="article-95"></a>

### Artículo 95

**Título original:** PsychoGAT: A Novel Psychological Measurement Paradigm through Interactive Fiction Games

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Qisen Yang, Zekun Wang, Honghui Chen, Shenzhi Wang, Yifan Pu, Xin Gao, Wenhao Huang, Shiji Song, Gao Huang

**Keywords:** psychological measurement, LLM agents, interactive fiction games, gamification, personality traits, psychometric evaluation, mental health assessment

**URL:** https://aclanthology.org/2024.acl-long.779/

#### Abstract (English)

PsychoGAT is proposed to achieve generic gamification of psychological assessment. Large language models function as both adept psychologists and innovative game designers, transforming any standardized scales into personalized and engaging interactive fiction games.

#### Resumen (Español)

Se propone PsychoGAT para lograr una gamificación genérica de la evaluación psicológica. Los modelos de lenguaje de gran escala funcionan tanto como psicólogos expertos como diseñadores de juegos innovadores, transformando cualquier escala estandarizada en juegos de ficción interactiva personalizados y atractivos.

---

<a id="article-96"></a>

### Artículo 96

**Título original:** Investigating Personality Consistency in Quantized Role-Playing Dialogue Agents

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Yixiao Wang, Homa Fashandi, Kevin Ferreira

**Keywords:** model quantization, role-playing agents, personality consistency, Big Five model, edge computing, multi-turn dialogue, conversational AI

**URL:** https://aclanthology.org/2024.emnlp-industry.19/

#### Abstract (English)

Personality consistency in quantized large language models for edge device role-playing scenarios is explored. A non-parametric method called Think2 is proposed to address personality inconsistency, demonstrating effectiveness in maintaining consistent personality traits.

#### Resumen (Español)

Se explora la consistencia de personalidad en modelos de lenguaje de gran escala cuantizados para escenarios de juego de roles en dispositivos de borde. Se propone un método no paramétrico denominado Think2 para abordar la inconsistencia de personalidad, demostrando efectividad en mantener rasgos de personalidad consistentes.

---

<a id="article-97"></a>

### Artículo 97

**Título original:** Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Zhengyuan Liu, Stella Xin Yin, Geyu Lin, Nancy F. Chen

**Keywords:** intelligent tutoring systems, student simulation, personality traits, educational technology, language learning, conversational AI, personalized learning

**URL:** https://aclanthology.org/2024.emnlp-main.37/

#### Abstract (English)

A framework to construct profiles of different student groups by refining and integrating both cognitive and noncognitive aspects is proposed, leveraging large language models for personality-aware student simulation in language learning scenarios.

#### Resumen (Español)

Se propone un marco para construir perfiles de diferentes grupos de estudiantes refinando e integrando aspectos tanto cognitivos como no cognitivos, aprovechando modelos de lenguaje de gran escala para simulación de estudiantes consciente de personalidad en escenarios de aprendizaje de idiomas.

---

<a id="article-98"></a>

### Artículo 98

**Título original:** PersonaLLM: Investigating the Ability of LLMs to Express Personality Traits

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Hang Jiang, Xiajie Zhang, Xubo Cao, Cynthia Breazeal, Deb Roy, Jad Kabbara

**Keywords:** LLM personas, Big Five personality model, personality expression, text generation, psycholinguistic patterns, human evaluation, personalized chatbots

**URL:** https://aclanthology.org/2024.findings-naacl.229/

#### Abstract (English)

Whether large language models can generate content that aligns with assigned personality profiles is investigated. Results show that model personas' self-reported BFI scores are consistent with designated personality types. Human evaluation demonstrates that humans can perceive personality traits with accuracy up to 80%.

#### Resumen (Español)

Se investiga si los modelos de lenguaje de gran escala pueden generar contenido que se alinee con perfiles de personalidad asignados. Los resultados muestran que las puntuaciones BFI autorreportadas de las personas del modelo son consistentes con los tipos de personalidad designados. La evaluación humana demuestra que los humanos pueden percibir rasgos de personalidad con una precisión de hasta 80%.

---

<a id="article-99"></a>

### Artículo 99

**Título original:** PSYDIAL: Personality-based Synthetic Dialogue Generation Using LLMs

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Ji-Eun Han, Jun-Seok Koh, Hyeon-Tae Seo, Du-Seong Chang, Kyung-Ah Sohn

**Keywords:** synthetic dialogue generation, personality-based dialogue, Big Five extraversion, multilingual NLP, Korean language, conversational AI, data augmentation

**URL:** https://aclanthology.org/2024.lrec-main.1166/

#### Abstract (English)

A novel end-to-end personality-based synthetic dialogue data generation pipeline is presented. PSYDIAL, the first Korean dialogue dataset focused on personality-based dialogues, is introduced, focusing on the Extraversion dimension of the Big Five personality model.

#### Resumen (Español)

Se presenta una novedosa secuencia de generación de datos de diálogo sintético basado en personalidad de extremo a extremo. Se introduce PSYDIAL, el primer conjunto de datos de diálogo coreano enfocado en diálogos basados en personalidad, con enfoque en la dimensión de Extraversión del modelo de personalidad de los Cinco Grandes.

---

<a id="article-100"></a>

### Artículo 100

**Título original:** Big-Five Backstage: A Dramatic Dataset for Characters Personality Traits

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Marina Tiuleneva, Vadim A. Porvatov, Carlo Strapparava

**Keywords:** Big Five personality traits, character analysis, psycholinguistics, dramatic dialogue, dataset creation, fictional characters, computational personality analysis

**URL:** https://aclanthology.org/2024.cogalex-1.13/

#### Abstract (English)

A novel textual dataset comprising fictional characters' lines with annotations based on gender and Big-Five personality traits is introduced. Results indicate that imagined personae mirror most language categories observed in real people while demonstrating them more expressively.

#### Resumen (Español)

Se introduce un novedoso conjunto de datos textual que comprende líneas de personajes ficticios con anotaciones basadas en género y rasgos de personalidad de los Cinco Grandes. Los resultados indican que las personas imaginadas reflejan la mayoría de las categorías lingüísticas observadas en personas reales mientras las demuestran de manera más expresiva.

---

<a id="article-101"></a>

### Artículo 101

**Título original:** Is Persona Enough for Personality? Using ChatGPT to Reconstruct Latent Personality

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Investigadores USC Viterbi

**Keywords:** HEXACO personality framework, personality reconstruction, persona modeling, socio-demographic factors, personality consistency, latent dimensions, agent simulation

**URL:** https://arxiv.org/html/2406.12216

#### Abstract (English)

Capabilities of large language models in reconstructing complex cognitive attributes based on simple descriptions are explored. Utilizing the HEXACO personality framework, the consistency of models in recovering and predicting underlying personality dimensions from simple descriptions is examined.

#### Resumen (Español)

Se exploran las capacidades de los modelos de lenguaje de gran escala para reconstruir atributos cognitivos complejos basados en descripciones simples. Utilizando el marco de personalidad HEXACO, se examina la consistencia de los modelos en recuperar y predecir dimensiones de personalidad subyacentes a partir de descripciones simples.

---

<a id="article-102"></a>

### Artículo 102

**Título original:** A Survey of Personality, Persona, and Profile in Conversational Agents

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Rodney Atwell y colaboradores

**Keywords:** conversational agents, chatbots, personality models, Big Five, persona, dialogue systems, neural networks

**URL:** https://arxiv.org/html/2401.00609v1

#### Abstract (English)

A comprehensive review of personality in neural conversational agents is presented. Personality, Persona, and Profile are defined, all personality schemes used in conversational agents are explained, 21 datasets are described, and recent models and methods are reviewed.

#### Resumen (Español)

Se presenta una revisión integral de la personalidad en agentes conversacionales neurales. Se definen Personalidad, Persona y Perfil, se explican todos los esquemas de personalidad utilizados en agentes conversacionales, se describen 21 conjuntos de datos, y se revisan modelos y métodos recientes.

---

<a id="article-103"></a>

### Artículo 103

**Título original:** Character-LLM: A Trainable Agent for Role-Playing

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Yunfan Shao, Linyang Li, Junqi Dai, Xipeng Qiu

**Keywords:** role-playing agents, character simulation, LLM agents, experience reconstruction, personality embodiment, interactive characters, human simulacra

**URL:** https://arxiv.org/abs/2310.10158

#### Abstract (English)

Character-LLM is introduced to teach large language models to act as specific people such as Beethoven, Queen Cleopatra, or Julius Caesar. The method focuses on editing profiles as experiences of a certain character and training models to be personal simulacra.

#### Resumen (Español)

Se introduce Character-LLM para enseñar a los modelos de lenguaje de gran escala a actuar como personas específicas tales como Beethoven, la Reina Cleopatra o Julio César. El método se enfoca en editar perfiles como experiencias de un cierto personaje y entrenar modelos para ser simulacros personales.

---

<a id="article-104"></a>

### Artículo 104

**Título original:** From Persona to Personalization: A Survey on Role-Playing Language Agents

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Jiangjie Chen, Xintao Wang, Rui Xu, y colaboradores

**Keywords:** role-playing agents, persona modeling, personalization, character simulation, interactive systems, LLM applications, human-likeness

**URL:** https://arxiv.org/abs/2404.18231

#### Abstract (English)

A comprehensive survey of Role-Playing Language Agents (RPLAs), specialized AI systems designed to simulate assigned personas, is conducted. Personas are categorized into Demographic, Character, and Individualized types, covering methodologies, data sourcing, construction, and evaluation.

#### Resumen (Español)

Se conduce una encuesta integral de Agentes de Lenguaje de Juego de Roles (RPLAs), sistemas de inteligencia artificial especializados diseñados para simular personas asignadas. Las personas se categorizan en tipos Demográfico, de Personaje e Individualizado, cubriendo metodologías, obtención de datos, construcción y evaluación.

---

<a id="article-105"></a>

### Artículo 105

**Título original:** Identifying Cooperative Personalities in Multi-agent Contexts

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Investigadores en sistemas multi-agente

**Keywords:** multi-agent systems, personality traits, cooperation dynamics, Iterated Prisoner's Dilemma, Big Five traits, representation engineering, agent coordination

**URL:** https://arxiv.org/html/2503.12722

#### Abstract (English)

How personality traits influence cooperation in large language models is explored using representation engineering to steer Big Five traits. Results show higher Agreeableness and Conscientiousness improve cooperation but increase susceptibility to exploitation.

#### Resumen (Español)

Se explora cómo los rasgos de personalidad influyen en la cooperación en modelos de lenguaje de gran escala utilizando ingeniería de representación para dirigir rasgos de los Cinco Grandes. Los resultados muestran que mayor Amabilidad y Responsabilidad mejoran la cooperación pero aumentan la susceptibilidad a la explotación.

---

<a id="article-106"></a>

### Artículo 106

**Título original:** The Impact of Big Five Personality Traits on AI Agent Decision-Making

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Equipo de investigación en simulación social

**Keywords:** Big Five personality, AI agent decision-making, social simulation, multi-agent framework, public spaces, AgentVerse, behavioral modeling

**URL:** https://arxiv.org/html/2503.15497v1

#### Abstract (English)

How Big Five personality traits of AI agents affect their decision generation in public open environments is investigated. The simulation was conducted in a university classroom environment using GPT-3.5-turbo with the AgentVerse framework.

#### Resumen (Español)

Se investiga cómo los rasgos de personalidad de los Cinco Grandes de los agentes de inteligencia artificial afectan su generación de decisiones en ambientes públicos abiertos. La simulación se realizó en un entorno de aula universitaria utilizando GPT-3.5-turbo con el marco AgentVerse.

---

<a id="article-107"></a>

### Artículo 107

**Título original:** Signs of Consciousness in AI: Can GPT-3 Tell How Smart It Really Is?

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Bojana Bojic, Marina Jovanovic, Bojana M. Dinic, Ljubisa Bojic

**Keywords:** artificial intelligence, consciousness, GPT-3, cognitive intelligence, emotional intelligence, self-awareness, machine consciousness

**URL:** https://www.nature.com/articles/s41599-024-04154-3

#### Abstract (English)

Objective and self-assessment tests of cognitive and emotional intelligence were administered to GPT-3. Results revealed GPT-3 outperformed average humans on cognitive intelligence tests, but its logical reasoning and emotional intelligence matched average human performance. GPT-3's self-assessments did not always align with objective performance.

#### Resumen (Español)

Se administraron pruebas objetivas y de autoevaluación de inteligencia cognitiva y emocional a GPT-3. Los resultados revelaron que GPT-3 superó a los humanos promedio en pruebas de inteligencia cognitiva, pero su razonamiento lógico e inteligencia emocional coincidieron con el desempeño humano promedio. Las autoevaluaciones de GPT-3 no siempre se alinearon con el desempeño objetivo.

---

<a id="article-108"></a>

### Artículo 108

**Título original:** An Evolutionary Model of Personality Traits Related to Cooperative Behavior Using LLM

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Reiji Suzuki, Takaya Arita

**Keywords:** evolutionary computation, personality traits, cooperative behavior, large language models, game theory, evolutionary dynamics, behavioral traits

**URL:** https://www.nature.com/articles/s41598-024-55903-y

#### Abstract (English)

An evolutionary model of personality traits related to cooperative behavior using large language models is proposed. Linguistic descriptions of personality traits are used as genes. The model exhibits evolution of cooperative behavior based on diverse and higher-order representation of personality traits.

#### Resumen (Español)

Se propone un modelo evolutivo de rasgos de personalidad relacionados con comportamiento cooperativo utilizando modelos de lenguaje de gran escala. Las descripciones lingüísticas de rasgos de personalidad se utilizan como genes. El modelo exhibe evolución de comportamiento cooperativo basado en representación diversa y de orden superior de rasgos de personalidad.

---

<a id="article-109"></a>

### Artículo 109

**Título original:** Cultural Bias and Cultural Alignment of Large Language Models

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Yan Tao, Olga Viberg, Ryan S. Baker, René F. Kizilcec

**Keywords:** cultural bias, cultural alignment, large language models, cross-cultural values, World Values Survey, cultural prompting, AI ethics

**URL:** https://academic.oup.com/pnasnexus/article/3/9/pgae346/7756548

#### Abstract (English)

All models exhibit cultural values resembling English-speaking and Protestant European countries. Cultural prompting is tested as a control strategy to increase cultural alignment, which improves alignment for 71-81% of countries/territories.

#### Resumen (Español)

Todos los modelos exhiben valores culturales que se asemejan a países anglófonos y europeos protestantes. Se prueba el uso de instrucciones culturales como estrategia de control para aumentar la alineación cultural, lo cual mejora la alineación para 71-81% de países/territorios.

---

<a id="article-110"></a>

### Artículo 110

**Título original:** Artificial Intelligence, Human Cognition, and Conscious Supremacy

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Kenichiro Mogi

**Keywords:** consciousness, artificial intelligence, cognitive science, conscious supremacy, computational significance, philosophy of mind, neural correlates

**URL:** https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1364714/full

#### Abstract (English)

Salient ideas about computational significance of human conscious processes are reviewed, and cognitive domains potentially unique to consciousness are identified: flexible attention modulation, robust handling of new contexts, choice and decision making. Conscious supremacy is proposed as a concept analogous to quantum supremacy.

#### Resumen (Español)

Se revisan ideas destacadas sobre la significancia computacional de los procesos conscientes humanos, y se identifican dominios cognitivos potencialmente únicos a la consciencia: modulación flexible de la atención, manejo robusto de nuevos contextos, elección y toma de decisiones. Se propone la supremacía consciente como un concepto análogo a la supremacía cuántica.

---

<a id="article-111"></a>

### Artículo 111

**Título original:** Designing Personality-Adaptive Conversational Agents for Mental Health Care

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Equipo de investigación en informática de salud mental

**Keywords:** personality-adaptive conversational agents, mental health care, therapeutic chatbots, user personalization, patient-centered design, Big Five personality, clinical applications

**URL:** https://pmc.ncbi.nlm.nih.gov/articles/PMC8889396/

#### Abstract (English)

The concept of a personality-adaptive conversational agent (PACA) that can dynamically adjust its personality traits to better align with individual patient needs in therapeutic contexts is proposed. Based on established personality models and advances in natural language processing.

#### Resumen (Español)

Se propone el concepto de un agente conversacional adaptativo a la personalidad (PACA) que puede ajustar dinámicamente sus rasgos de personalidad para alinearse mejor con las necesidades individuales del paciente en contextos terapéuticos. Basado en modelos de personalidad establecidos y avances en procesamiento de lenguaje natural.

---

<a id="article-112"></a>

### Artículo 112

**Título original:** Can ChatGPT Assess Human Personalities? A General Evaluation Framework

**Categoría:** Evaluación y validación psicométrica

**Año:** 2023 | **Idioma:** Inglés

**Autores:** Haocong Rao, Cyril Leung, Chunyan Miao

**Keywords:** large language models, ChatGPT, personality assessment, MBTI, evaluation framework, prompt engineering, consistency

**URL:** https://arxiv.org/abs/2303.01248

#### Abstract (English)

A generic evaluation framework for large language models to assess human personalities based on MBTI tests is presented. Unbiased prompts are devised and three evaluation metrics are proposed to measure consistency, robustness, and fairness of assessment results from ChatGPT and GPT-4.

#### Resumen (Español)

Se presenta un marco de evaluación genérico para que los modelos de lenguaje de gran escala evalúen personalidades humanas basado en pruebas MBTI. Se diseñan instrucciones imparciales y se proponen tres métricas de evaluación para medir la consistencia, robustez y equidad de los resultados de evaluación de ChatGPT y GPT-4.

---

<a id="article-113"></a>

### Artículo 113

**Título original:** Systematic Evaluation of GPT-3 for Zero-Shot Personality Estimation

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2023 | **Idioma:** Inglés

**Autores:** Adithya V Ganesan, Yash Kumar Lal, August Håkan Nilsson, H. Andrew Schwartz

**Keywords:** personality estimation, GPT-3, zero-shot learning, Big Five traits, social media analysis, human-level NLP, psychometrics

**URL:** https://aclanthology.org/2023.wassa-1.34.pdf

#### Abstract (English)

The zero-shot ability of GPT-3 to estimate Big Five personality traits from social media posts is investigated. Zero-shot GPT-3 performance is found to be somewhat close to existing pre-trained state-of-the-art for broad classification upon injecting knowledge about the trait in prompts.

#### Resumen (Español)

Se investiga la capacidad de cero disparos de GPT-3 para estimar rasgos de personalidad de los Cinco Grandes a partir de publicaciones de redes sociales. Se encuentra que el rendimiento de cero disparos de GPT-3 es algo cercano al estado del arte preentrenado existente para clasificación amplia al inyectar conocimiento sobre el rasgo en las instrucciones.

---

<a id="article-114"></a>

### Artículo 114

**Título original:** The Plasticity of ChatGPT's Mentalizing Abilities: Personalization for Personality Structures

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2023 | **Idioma:** Inglés

**Autores:** Dorit Hadar-Shoval, Zohar Elyoseph, Maya Lvovsky

**Keywords:** artificial intelligence, borderline personality disorder, emotional intelligence, empathy, emotional awareness, Schizoid Personality Disorder, mentalizing

**URL:** https://pmc.ncbi.nlm.nih.gov/articles/PMC10503434/

#### Abstract (English)

ChatGPT's potential to generate mentalizing-like abilities tailored to specific personality structures was evaluated. ChatGPT accurately described emotional reactions of individuals with borderline personality disorder as more intense, complex, and rich than those with schizoid personality disorder, suggesting it can generate mentalizing-like responses consistent with psychopathologies.

#### Resumen (Español)

Se evaluó el potencial de ChatGPT para generar habilidades similares a la mentalización adaptadas a estructuras de personalidad específicas. ChatGPT describió con precisión las reacciones emocionales de individuos con trastorno límite de la personalidad como más intensas, complejas y ricas que aquellas con trastorno esquizoide de la personalidad, sugiriendo que puede generar respuestas similares a la mentalización consistentes con psicopatologías.

---

<a id="article-115"></a>

### Artículo 115

**Título original:** Evaluating and Inducing Personality in Pre-trained Language Models

**Categoría:** Inducción y control de personalidad

**Año:** 2022 | **Idioma:** Inglés

**Autores:** Guangyuan Jiang, Manjie Xu, Song-Chun Zhu, Wenjuan Han, Chi Zhang, Yixin Zhu

**Keywords:** Machine Personality Inventory, Big Five personality traits, LLM evaluation, personality prompting, psychometric testing, pre-trained language models, behavioral assessment

**URL:** https://arxiv.org/abs/2206.07550

#### Abstract (English)

The Machine Personality Inventory (MPI) tool for studying machine behaviors based on Big Five Personality Factors theory is introduced. By systematically evaluating large language models with MPI, first evidence demonstrating the efficacy of MPI in studying model behaviors is provided. The Personality Prompting (P^2) method is devised to induce models with specific personalities.

#### Resumen (Español)

Se introduce la herramienta de Inventario de Personalidad de Máquina (MPI) para estudiar comportamientos de máquina basados en la teoría de los Factores de Personalidad de los Cinco Grandes. Al evaluar sistemáticamente modelos de lenguaje de gran escala con MPI, se proporciona la primera evidencia que demuestra la eficacia de MPI en estudiar comportamientos del modelo. Se diseña el método de Instrucciones de Personalidad (P^2) para inducir modelos con personalidades específicas.

---

<a id="article-116"></a>

### Artículo 116

**Título original:** Who is GPT-3? An Exploration of Personality, Values and Demographics

**Categoría:** Evaluación y validación psicométrica

**Año:** 2022 | **Idioma:** Inglés

**Autores:** Marilù Miotto, Nicola Rossberg, Bennett Kleinberg

**Keywords:** GPT-3, personality assessment, psychological evaluation, human values, HEXACO personality model, computational social science, language model characterization

**URL:** https://arxiv.org/abs/2209.14338

#### Abstract (English)

Two validated measurement tools were administered to GPT-3 to assess its personality, values it holds, and self-reported demographics. Results show that GPT-3 scores similarly to human samples in terms of personality and values. First evidence of psychological assessment of the GPT-3 model is provided.

#### Resumen (Español)

Se administraron dos herramientas de medición validadas a GPT-3 para evaluar su personalidad, los valores que sostiene y la demografía autorreportada. Los resultados muestran que GPT-3 puntúa de manera similar a muestras humanas en términos de personalidad y valores. Se proporciona la primera evidencia de evaluación psicológica del modelo GPT-3.

---

<a id="article-117"></a>

### Artículo 117

**Título original:** Identifying and Manipulating the Personality Traits of Language Models

**Categoría:** Inducción y control de personalidad

**Año:** 2022 | **Idioma:** Inglés

**Autores:** Graham Caron, Shashank Srivastava

**Keywords:** personality traits, Big Five, language model control, persona manipulation, BERT, GPT-2, personality consistency

**URL:** https://arxiv.org/abs/2212.10276

#### Abstract (English)

Whether perceived personality in language models is exhibited consistently in their language generation is explored. When provided different types of contexts, language models such as BERT and GPT-2 are shown to consistently identify and reflect personality markers. This frames them as tools for identifying personality traits and controlling personas.

#### Resumen (Español)

Se explora si la personalidad percibida en modelos de lenguaje se exhibe consistentemente en su generación de lenguaje. Se demuestra que cuando se proporcionan diferentes tipos de contextos, modelos de lenguaje como BERT y GPT-2 pueden identificar y reflejar marcadores de personalidad consistentemente. Esto los enmarca como herramientas para identificar rasgos de personalidad y controlar personas.

---

<a id="article-118"></a>

### Artículo 118

**Título original:** Estimating the Personality of White-Box Language Models

**Categoría:** Evaluación y validación psicométrica

**Año:** 2022 | **Idioma:** Inglés

**Autores:** Saketh Reddy Karra, Son The Nguyen, Theja Tulabandhula

**Keywords:** white-box language models, Big Five personality, zero-shot classification, personality estimation, open-ended text generation, model anthropomorphism, personality modification

**URL:** https://arxiv.org/abs/2204.12000

#### Abstract (English)

Personality traits of several large-scale language models designed for open-ended text generation are explored. Building on Big Five factors, robust methods that quantify personality traits of these models and their underlying datasets are developed. Models are triggered with personality assessment questionnaires and text responses are classified into quantifiable traits.

#### Resumen (Español)

Se exploran los rasgos de personalidad de varios modelos de lenguaje a gran escala diseñados para generación de texto abierto. Construyendo sobre los factores de los Cinco Grandes, se desarrollan métodos robustos que cuantifican los rasgos de personalidad de estos modelos y sus conjuntos de datos subyacentes. Se activan los modelos con cuestionarios de evaluación de personalidad y las respuestas de texto se clasifican en rasgos cuantificables.

---

<a id="article-119"></a>

### Artículo 119

**Título original:** Pushing on Personality Detection from Verbal Behavior: A Transformer Meets Text Contours

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2022 | **Idioma:** Inglés

**Autores:** Yu Qiao, Gian-Gabriel P. Garcia, Simon E. Coles, Daniel M. Olson, Apara Datta, Hareesh Kumar Krishnamohan, Vidhya Navalpakkam, Elisabeth André, Kai Zhao

**Keywords:** personality detection, psycholinguistic features, BERT transformers, text contours, Big Five, MBTI, verbal behavior analysis

**URL:** https://arxiv.org/abs/2204.04629

#### Abstract (English)

Two major improvements in predicting personality traits from text are reported: (1) the most comprehensive set of theory-based psycholinguistic features and (2) hybrid models integrating pre-trained Transformer BERT and BLSTM networks trained on within-text distributions of psycholinguistic features. Models achieve improvement by 2.9% on the Essay dataset and 8.28% on the Kaggle MBTI dataset.

#### Resumen (Español)

Se reportan dos mejoras importantes en la predicción de rasgos de personalidad a partir de texto: (1) el conjunto más completo de características psicolingüísticas basadas en teoría y (2) modelos híbridos que integran el Transformer preentrenado BERT y redes BLSTM entrenadas en distribuciones intra-texto de características psicolingüísticas. Los modelos logran una mejora del 2.9% en el conjunto de datos Essay y del 8.28% en el conjunto de datos Kaggle MBTI.

---

<a id="article-120"></a>

### Artículo 120

**Título original:** Deterministic AI Agent Personality Expression through Standard Psychological Diagnostics

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** J. M. Diederik Kruijssen, Nicholas Emmons

**Keywords:** Machine Learning, Artificial Intelligence, Computers and Society, Human-Computer Interaction

**URL:** https://arxiv.org/abs/2503.17085

#### Abstract (English)

The authors investigate whether AI systems can express deterministic and consistent personalities when instructed using established psychological frameworks. Their research reveals that advanced models like GPT-4o and o1 achieve the highest accuracy on Big Five and Myers-Briggs assessments. The study indicates that personality expression emerges from holistic reasoning rather than question-level optimization, and that fine-tuning affects communication style independently of personality accuracy. The researchers propose this capability could enhance human-AI interaction across education and healthcare applications.

#### Resumen (Español)

Se investiga si los sistemas de inteligencia artificial pueden expresar personalidades deterministas y coherentes cuando se instruyen mediante marcos psicológicos establecidos. La investigación revela que modelos avanzados como GPT-4o y o1 logran la mayor precisión en evaluaciones Big Five y Myers-Briggs. El estudio indica que la expresión de personalidad emerge del razonamiento holístico en lugar de la optimización pregunta por pregunta, y que el ajuste fino afecta el estilo de comunicación independientemente de la precisión de personalidad. Los investigadores proponen que esta capacidad podría mejorar la interacción humano-IA en educación y aplicaciones de salud.

---

<a id="article-121"></a>

### Artículo 121

**Título original:** Value-Spectrum: Quantifying Preferences of Vision-Language Models via Value Decomposition in Social Media Contexts

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Jingxuan Li, Yuning Yang, Shengqi Yang, Linfan Zhang, Ying Nian Wu

**Keywords:** Computation and Language, ACL 2025

**URL:** https://arxiv.org/abs/2411.11479

#### Abstract (English)

The researchers present a benchmark called Value-Spectrum designed to evaluate vision-language models using Schwartz's framework of human values. They constructed a database with over 50,000 short videos from TikTok, YouTube Shorts, and Instagram Reels covering diverse topics. The study examines how these models handle value-oriented content and explores their capacity to adopt specific personas when explicitly prompted. The authors conclude that their benchmark offers potential for tracking VLM preferences in value-based tasks and persona simulation abilities. Code and data are available on GitHub.

#### Resumen (Español)

Los investigadores presentan un benchmark denominado Value-Spectrum diseñado para evaluar modelos de visión-lenguaje mediante el marco de valores humanos de Schwartz. Construyeron una base de datos con más de 50,000 videos cortos de TikTok, YouTube Shorts e Instagram Reels que cubren temas diversos. El estudio examina cómo estos modelos manejan contenido orientado a valores y explora su capacidad para adoptar personas específicas cuando se les instruye explícitamente. Los autores concluyen que su benchmark ofrece potencial para rastrear preferencias de modelos de visión-lenguaje en tareas basadas en valores y capacidades de simulación de personas. El código y los datos están disponibles en GitHub.

---

<a id="article-122"></a>

### Artículo 122

**Título original:** The Power of Personality: A Human Simulation Perspective to Investigate Large Language Model Agents

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Yifan Duan, Yihong Tang, Xuefeng Bai, Kehai Chen, Juntao Li, Min Zhang

**Keywords:** Computation and Language

**URL:** https://arxiv.org/abs/2502.20859

#### Abstract (English)

The researchers investigate how personality traits influence LLM agent performance using human simulation methodology. They examine three primary questions regarding how personality shapes problem-solving in structured tasks, creativity in open-ended tasks, and collaborative dynamics. The study assigns Big Five personality characteristics to LLM agents, revealing that specific traits significantly influence reasoning accuracy in closed tasks and creative output in open tasks. Additionally, the research demonstrates that multi-agent teams develop collective intelligence distinct from individual capabilities depending on personality compositions.

#### Resumen (Español)

Los investigadores examinan cómo los rasgos de personalidad influyen en el desempeño de agentes LLM mediante metodología de simulación humana. Analizan tres cuestiones principales respecto a cómo la personalidad moldea la resolución de problemas en tareas estructuradas, la creatividad en tareas abiertas y las dinámicas colaborativas. El estudio asigna características de personalidad Big Five a agentes LLM, revelando que rasgos específicos influyen significativamente en la precisión del razonamiento en tareas cerradas y el resultado creativo en tareas abiertas. Adicionalmente, la investigación demuestra que equipos multi-agente desarrollan inteligencia colectiva distinta de las capacidades individuales dependiendo de las composiciones de personalidad.

---

<a id="article-123"></a>

### Artículo 123

**Título original:** The Illusion of Personality: Uncovering Dissociation Between Self-Reports and Behavior in LLMs

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Pengrui Han, Rafal Kocielnik, Peiyang Song, Ramit Debnath, Dean Mobbs, Anima Anandkumar, R. Michael Alvarez

**Keywords:** Artificial Intelligence, Computation and Language, Computers and Society, Machine Learning

**URL:** https://arxiv.org/abs/2509.03730

#### Abstract (English)

The research investigates whether personality traits in large language models function similarly to human personality. The study examines trait development during training, whether self-reported traits predict actual behavior, and how interventions like persona injection affect both self-reports and actions. Key findings indicate that instructional alignment significantly stabilizes trait expression and strengthens correlations matching human patterns. However, self-reported traits do not reliably predict behavior, and persona injection influences self-reports without consistently affecting actual behavior, suggesting a gap between surface-level trait expression and genuine behavioral consistency.

#### Resumen (Español)

La investigación examina si los rasgos de personalidad en modelos de lenguaje de gran escala funcionan de manera similar a la personalidad humana. El estudio analiza el desarrollo de rasgos durante el entrenamiento, si los rasgos autoinformados predicen el comportamiento real, y cómo intervenciones como la inyección de persona afectan tanto autoinformes como acciones. Los hallazgos clave indican que la alineación instruccional estabiliza significativamente la expresión de rasgos y fortalece las correlaciones que coinciden con patrones humanos. Sin embargo, los rasgos autoinformados no predicen de manera fiable el comportamiento, y la inyección de persona influye en autoinformes sin afectar consistentemente el comportamiento real, sugiriendo una brecha entre la expresión superficial de rasgos y la coherencia conductual genuina.

---

<a id="article-124"></a>

### Artículo 124

**Título original:** Psychologically Enhanced AI Agents

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Maciej Besta, Shriram Chandran, Robert Gerstenberger, Mathis Lindner, Marcin Chrapek, Sebastian Hermann Martschat, Taraneh Ghandi, Patrick Iff, Hubert Niewiadomski, Piotr Nyczyk, Jürgen Müller, Torsten Hoefler

**Keywords:** Artificial Intelligence, Computation and Language, Computers and Society, Human-Computer Interaction, Multiagent Systems

**URL:** https://arxiv.org/abs/2509.04343

#### Abstract (English)

The researchers present MBTI-in-Thoughts, a framework that enhances LLM agents through personality-based prompt engineering grounded in Myers-Briggs Type Indicator psychology. The method primes agents with distinct personality archetypes via prompt engineering, enabling control over behavior along two foundational axes of human psychology: cognition and affect. The work demonstrates that emotionally-oriented agents perform better at narrative tasks while analytically-primed agents show more stable strategies in game-theoretic contexts. The framework supports multi-agent communication and self-reflection protocols. Personality consistency is verified through the official 16Personalities test. The approach generalizes to other psychological frameworks including Big Five, HEXACO, and Enneagram, requiring no fine-tuning.

#### Resumen (Español)

Los investigadores presentan MBTI-in-Thoughts, un marco que mejora agentes LLM mediante ingeniería de instrucciones basada en personalidad fundamentada en la psicología del Indicador de Tipo Myers-Briggs. El método prepara agentes con arquetipos de personalidad distintos mediante ingeniería de instrucciones, permitiendo control sobre el comportamiento a lo largo de dos ejes fundamentales de la psicología humana: cognición y afecto. El trabajo demuestra que agentes orientados emocionalmente se desempeñan mejor en tareas narrativas mientras que agentes preparados analíticamente muestran estrategias más estables en contextos de teoría de juegos. El marco soporta protocolos de comunicación multi-agente y auto-reflexión. La coherencia de personalidad se verifica mediante el test oficial 16Personalities. El enfoque se generaliza a otros marcos psicológicos incluyendo Big Five, HEXACO y Eneagrama, sin requerir ajuste fino.

---

<a id="article-125"></a>

### Artículo 125

**Título original:** Cognitive Alignment in Personality Reasoning: Leveraging Prototype Theory for MBTI Inference

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Haoyuan Li, Yuanbo Tong, Yuchen Li, Zirui Wang, Chunhou Liu, Jiamou Liu

**Keywords:** Computation and Language, Artificial Intelligence

**URL:** https://arxiv.org/abs/2511.00115

#### Abstract (English)

The research proposes ProtoMBTI, a framework treating personality classification through the lens of prototype theory rather than traditional hard-label approaches. The methodology involves constructing a quality-controlled text corpus through LLM-guided augmentation across semantic, linguistic, and sentiment dimensions. A lightweight encoder of 2B parameters or fewer undergoes LoRA fine-tuning to develop discriminative embeddings and standardize personality prototypes. At inference, the system retrieves relevant prototypes and executes a retrieve-reuse-revise-retain cycle, where prototype evidence gets aggregated through voting, inconsistencies trigger revision, and successful predictions enrich the prototype library for continuous improvement. The framework demonstrates enhanced performance on MBTI tasks across multiple benchmarks while providing stronger interpretability and cross-dataset transferability compared to existing approaches.

#### Resumen (Español)

La investigación propone ProtoMBTI, un marco que trata la clasificación de personalidad mediante la teoría de prototipos en lugar de enfoques tradicionales de etiquetas rígidas. La metodología implica construir un corpus de texto controlado en calidad mediante aumento guiado por LLM a través de dimensiones semánticas, lingüísticas y de sentimiento. Un codificador ligero de 2B parámetros o menos experimenta ajuste fino LoRA para desarrollar incrustaciones discriminativas y estandarizar prototipos de personalidad. En la inferencia, el sistema recupera prototipos relevantes y ejecuta un ciclo recuperar-reusar-revisar-retener, donde la evidencia de prototipos se agrega mediante votación, las inconsistencias activan revisión, y las predicciones exitosas enriquecen la biblioteca de prototipos para mejora continua. El marco demuestra desempeño mejorado en tareas MBTI a través de múltiples benchmarks mientras proporciona mayor interpretabilidad y transferibilidad entre conjuntos de datos comparado con enfoques existentes.

---

<a id="article-126"></a>

### Artículo 126

**Título original:** Traits Run Deep: Enhancing Personality Assessment via Psychology-Guided LLM Representations and Multimodal Apparent Behaviors

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Jia Li, Yichao He, Jiacheng Xu, Tianhao Luo, Zhenzhen Hu, Richang Hong, Meng Wang

**Keywords:** Computation and Language, Multimedia, ACM MM 2025

**URL:** https://arxiv.org/abs/2507.22367

#### Abstract (English)

The researchers developed a framework addressing personality assessment challenges. They note that personality traits are stable, often subconsciously leaked through language, facial expressions, and body behaviors. Their approach uses psychology-informed prompts with large language models and implements a Text-Centric Trait Fusion Network that integrates multimodal signals. Key innovations include personality-specific LLM prompting and audio-visual feature extraction. Results showed approximately 45% MSE reduction, with the method ranking first in the AVI Challenge 2025 Personality Assessment track. Source code availability is planned through GitHub.

#### Resumen (Español)

Los investigadores desarrollaron un marco que aborda desafíos de evaluación de personalidad. Notan que los rasgos de personalidad son estables, frecuentemente filtrados subconscientemente a través del lenguaje, expresiones faciales y comportamientos corporales. Su enfoque utiliza instrucciones informadas por psicología con modelos de lenguaje de gran escala e implementa una Red de Fusión de Rasgos Centrada en Texto que integra señales multimodales. Las innovaciones clave incluyen instrucciones LLM específicas de personalidad y extracción de características audio-visuales. Los resultados mostraron aproximadamente 45% de reducción en MSE, con el método clasificándose primero en la pista de Evaluación de Personalidad del AVI Challenge 2025. La disponibilidad del código fuente está planificada a través de GitHub.

---

<a id="article-127"></a>

### Artículo 127

**Título original:** From Post To Personality: Harnessing LLMs for MBTI Prediction in Social Media

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Tian Ma, Kaiyu Feng, Yu Rong, Kangfei Zhao

**Keywords:** Computation and Language, Social and Information Networks, CIKM 2025

**URL:** https://arxiv.org/abs/2509.04461

#### Abstract (English)

The research addresses personality prediction from social media through the Myers Briggs Type Indicator (MBTI). The authors developed PostToPersonality (PtoP), an LLM-based framework tackling two primary challenges: the hallucination problem inherent in LLMs and the naturally imbalanced distribution of MBTI types in the population. The approach employs Retrieval Augmented Generation with in-context learning to reduce hallucinations, while fine-tuning uses synthetic minority oversampling to handle class imbalance. Testing on real-world social media data demonstrates that PtoP achieves state of the art performance compared with 10 ML and DL baselines.

#### Resumen (Español)

La investigación aborda la predicción de personalidad desde redes sociales mediante el Indicador de Tipo Myers Briggs (MBTI). Los autores desarrollaron PostToPersonality (PtoP), un marco basado en LLM que aborda dos desafíos principales: el problema de alucinación inherente en LLMs y la distribución naturalmente desbalanceada de tipos MBTI en la población. El enfoque emplea Generación Aumentada por Recuperación con aprendizaje en contexto para reducir alucinaciones, mientras que el ajuste fino utiliza sobremuestreo sintético de minorías para manejar el desbalance de clases. Las pruebas en datos de redes sociales del mundo real demuestran que PtoP logra desempeño de vanguardia comparado con 10 baselines de ML y DL.

---

<a id="article-128"></a>

### Artículo 128

**Título original:** Exploring the Personality Traits of LLMs through Latent Features Steering

**Categoría:** Inducción y control de personalidad

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Shu Yang, Shenzhe Zhu, Liang Liu, Lijie Hu, Mengdi Li, Di Wang

**Keywords:** Computation and Language, Artificial Intelligence

**URL:** https://arxiv.org/abs/2410.10863

#### Abstract (English)

The research examines how LLMs develop personality characteristics, investigating factors like cultural norms and environmental stressors that shape these traits. The authors propose a methodology that modifies model behavior by extracting and steering internal features, circumventing the need for retraining. Their approach draws from social determinism theory to understand personality expression. The team also evaluates safety implications through the lens of personality traits, addressing how these underlying factors influence model behavior and safety concerns.

#### Resumen (Español)

La investigación examina cómo los LLMs desarrollan características de personalidad, investigando factores como normas culturales y estresores ambientales que moldean estos rasgos. Los autores proponen una metodología que modifica el comportamiento del modelo extrayendo y dirigiendo características internas, evitando la necesidad de reentrenamiento. Su enfoque se basa en la teoría del determinismo social para comprender la expresión de personalidad. El equipo también evalúa las implicaciones de seguridad a través del prisma de los rasgos de personalidad, abordando cómo estos factores subyacentes influyen en el comportamiento del modelo y las preocupaciones de seguridad.

---

<a id="article-129"></a>

### Artículo 129

**Título original:** Personality-Driven Decision-Making in Autonomous Agents: Simulating Individual Differences in Risk Aversion and Time Discounting

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Hamed Ayoobi, David C. Anastasiu, Nikolas Gurney

**Keywords:** Artificial Intelligence, Human-Computer Interaction, Multiagent Systems

**URL:** https://arxiv.org/abs/2501.06992

#### Abstract (English)

The research investigates how Large Language Models can simulate human-like decision-making that reflects individual differences in risk aversion and time discounting. The authors developed a framework that incorporates psychologically grounded personality profiles based on the Big Five personality traits into LLM-driven agents. Through systematic experiments using hypothetical scenarios in gambling and delay discounting tasks, the study demonstrates that LLMs like Claude Sonnet 3.5 can accurately simulate behavioral patterns associated with different personality types. Results show that agents with high Neuroticism exhibit greater risk aversion, while those high in Conscientiousness demonstrate more future-oriented time preferences, mirroring established psychological findings.

#### Resumen (Español)

La investigación examina cómo los Modelos de Lenguaje de Gran Escala pueden simular toma de decisiones similar a la humana que refleja diferencias individuales en aversión al riesgo y descuento temporal. Los autores desarrollaron un marco que incorpora perfiles de personalidad fundamentados psicológicamente basados en los rasgos Big Five en agentes impulsados por LLM. Mediante experimentos sistemáticos usando escenarios hipotéticos en tareas de apuestas y descuento por demora, el estudio demuestra que LLMs como Claude Sonnet 3.5 pueden simular con precisión patrones conductuales asociados con diferentes tipos de personalidad. Los resultados muestran que agentes con alto Neuroticismo exhiben mayor aversión al riesgo, mientras que aquellos altos en Responsabilidad demuestran preferencias temporales más orientadas al futuro, reflejando hallazgos psicológicos establecidos.

---

<a id="article-130"></a>

### Artículo 130

**Título original:** A-MEM: Agentic Memory for LLM Agents

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Simon Stepputtis, Sumedh Sontakke, Nikhil Krishna, Akash Maram, Eleftherios Triantafillou, Hao Zhu, Katia Sycara

**Keywords:** Artificial Intelligence, Computation and Language, Multiagent Systems

**URL:** https://arxiv.org/abs/2501.03156

#### Abstract (English)

This research presents A-MEM, a framework that enables LLM agents to develop and manage episodic memories using metacognitive reasoning. The system allows agents to autonomously decide what experiences to store, how to organize memories, and when to retrieve them. The authors demonstrate that A-MEM enables agents to form consistent personality traits over extended interactions, maintain coherent behavioral patterns, and adapt their responses based on accumulated experiences. The framework was evaluated across multiple scenarios including social interactions and task-oriented dialogues, showing improved long-term consistency and personalization compared to baseline memory systems.

#### Resumen (Español)

Esta investigación presenta A-MEM, un marco que permite a los agentes LLM desarrollar y gestionar memorias episódicas mediante razonamiento metacognitivo. El sistema permite que los agentes decidan autónomamente qué experiencias almacenar, cómo organizar memorias y cuándo recuperarlas. Los autores demuestran que A-MEM permite a los agentes formar rasgos de personalidad consistentes a lo largo de interacciones extendidas, mantener patrones conductuales coherentes y adaptar sus respuestas basándose en experiencias acumuladas. El marco fue evaluado en múltiples escenarios incluyendo interacciones sociales y diálogos orientados a tareas, mostrando mejor consistencia a largo plazo y personalización comparado con sistemas de memoria baseline.

---

<a id="article-131"></a>

### Artículo 131

**Título original:** AI Agent Behavioral Science: Dynamics of Multi-Agent Societies and Applications for Behavioral Economics

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Tong Jiang, Hao Huang, Shibo Yao, Xiao Hu, Jie Tang, Jiang Bian, Yizhou Wang

**Keywords:** Artificial Intelligence, Computation and Language, Multiagent Systems, Computer Science and Game Theory

**URL:** https://arxiv.org/abs/2501.15606

#### Abstract (English)

The research introduces AI Agent Behavioral Science as a framework for studying emergent social dynamics in multi-agent LLM societies. The authors examine how personality traits programmed into individual agents influence collective behaviors, social hierarchies, and economic decision-making within simulated communities. The study demonstrates that multi-agent systems with diverse personality profiles can reproduce complex social phenomena including coalition formation, leadership emergence, and market dynamics. The work provides insights into how personality diversity affects group decision-making efficiency and explores applications in behavioral economics, particularly in understanding coordination problems and social preferences.

#### Resumen (Español)

La investigación introduce la Ciencia del Comportamiento de Agentes IA como un marco para estudiar dinámicas sociales emergentes en sociedades multi-agente de LLM. Los autores examinan cómo los rasgos de personalidad programados en agentes individuales influyen en comportamientos colectivos, jerarquías sociales y toma de decisiones económicas dentro de comunidades simuladas. El estudio demuestra que sistemas multi-agente con perfiles de personalidad diversos pueden reproducir fenómenos sociales complejos incluyendo formación de coaliciones, emergencia de liderazgo y dinámicas de mercado. El trabajo proporciona conocimientos sobre cómo la diversidad de personalidad afecta la eficiencia de toma de decisiones grupales y explora aplicaciones en economía conductual, particularmente en la comprensión de problemas de coordinación y preferencias sociales.

---

<a id="article-132"></a>

### Artículo 132

**Título original:** Personality as a Probe for LLM Evaluation: Unveiling Consistency, Stability, and Generalizability

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Emily Shen, Yuting Huang, Katherine Ye, Sriya Mantena, Anuj Maheshwari, Erin Chung

**Keywords:** Computation and Language, Artificial Intelligence

**URL:** https://arxiv.org/abs/2501.18166

#### Abstract (English)

This work proposes using personality assessment as a diagnostic tool for evaluating fundamental properties of Large Language Models. The researchers systematically analyze whether LLMs exhibit consistency in personality expression across different prompting strategies, stability of personality traits across model versions and fine-tuning procedures, and generalizability of personality patterns across different psychological frameworks. The study evaluates multiple frontier models including GPT-4, Claude, and Gemini using Big Five, MBTI, and HEXACO assessments. Findings reveal significant inconsistencies in how personality manifests depending on evaluation methodology, suggesting that current personality testing may reflect methodological artifacts rather than genuine model characteristics.

#### Resumen (Español)

Este trabajo propone usar la evaluación de personalidad como herramienta diagnóstica para evaluar propiedades fundamentales de Modelos de Lenguaje de Gran Escala. Los investigadores analizan sistemáticamente si los LLMs exhiben consistencia en la expresión de personalidad a través de diferentes estrategias de instrucción, estabilidad de rasgos de personalidad a través de versiones de modelos y procedimientos de ajuste fino, y generalizabilidad de patrones de personalidad a través de diferentes marcos psicológicos. El estudio evalúa múltiples modelos de frontera incluyendo GPT-4, Claude y Gemini usando evaluaciones Big Five, MBTI y HEXACO. Los hallazgos revelan inconsistencias significativas en cómo la personalidad se manifiesta dependiendo de la metodología de evaluación, sugiriendo que las pruebas actuales de personalidad pueden reflejar artefactos metodológicos en lugar de características genuinas del modelo.

---

<a id="article-133"></a>

### Artículo 133

**Título original:** Multilingual != Multicultural: A Case Study of How Culturally Aligned LLMs Really Are

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Shreya Havaldar, Bhumika Gangopadhyay, Sunny Rai, Sunny Kumar, Manveer Singh Tamber, Isha Garg, Lyle Ungar, Sharath Chandra Guntuku

**Keywords:** Computation and Language, Artificial Intelligence, Computers and Society

**URL:** https://arxiv.org/abs/2501.17680

#### Abstract (English)

This research challenges the assumption that multilingual capabilities in LLMs automatically translate to multicultural awareness. The authors investigate whether personality traits expressed by LLMs vary appropriately across cultural contexts when responding in different languages. Using Big Five personality assessments across multiple languages and cultural settings, the study reveals that while models like GPT-4 and Claude can operate in multiple languages, their personality expressions often remain anchored to Western cultural norms regardless of the language used. The findings highlight a critical gap between linguistic proficiency and genuine cultural alignment in current LLMs.

#### Resumen (Español)

Esta investigación desafía la suposición de que las capacidades multilingües en LLMs se traducen automáticamente en conciencia multicultural. Los autores investigan si los rasgos de personalidad expresados por LLMs varían apropiadamente a través de contextos culturales cuando responden en diferentes idiomas. Usando evaluaciones de personalidad Big Five a través de múltiples idiomas y entornos culturales, el estudio revela que mientras modelos como GPT-4 y Claude pueden operar en múltiples idiomas, sus expresiones de personalidad frecuentemente permanecen ancladas a normas culturales occidentales independientemente del idioma usado. Los hallazgos destacan una brecha crítica entre competencia lingüística y alineación cultural genuina en LLMs actuales.

---

<a id="article-134"></a>

### Artículo 134

**Título original:** How Well Do LLMs Represent Values Across Cultures? Empirical Analysis of LLM Responses Based on Hofstede Cultural Dimensions

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Lena Held, Thales Bertaglia, Micol Spitale, Jessica Keeble, Nigel Crook, Howard Lin, Jan Niehues

**Keywords:** Computation and Language, Artificial Intelligence, Computers and Society

**URL:** https://arxiv.org/abs/2501.08476

#### Abstract (English)

The researchers evaluate how well LLMs represent cultural values using Hofstede's cultural dimensions framework. The study systematically prompts multiple LLMs to adopt personas from different cultural backgrounds and assesses whether their responses align with established cultural value patterns. Testing includes GPT-4, Claude, and other frontier models across dimensions such as individualism-collectivism, power distance, and uncertainty avoidance. Results indicate that while LLMs can adjust some surface-level cultural markers, they struggle to consistently embody deep-rooted cultural values, particularly for non-Western cultures. The work emphasizes the need for culturally-aware training approaches beyond simple multilingual data inclusion.

#### Resumen (Español)

Los investigadores evalúan qué tan bien los LLMs representan valores culturales usando el marco de dimensiones culturales de Hofstede. El estudio instruye sistemáticamente a múltiples LLMs para adoptar personas de diferentes trasfondos culturales y evalúa si sus respuestas se alinean con patrones de valores culturales establecidos. Las pruebas incluyen GPT-4, Claude y otros modelos de frontera a través de dimensiones como individualismo-colectivismo, distancia de poder y evitación de incertidumbre. Los resultados indican que mientras los LLMs pueden ajustar algunos marcadores culturales superficiales, tienen dificultades para encarnar consistentemente valores culturales arraigados, particularmente para culturas no occidentales. El trabajo enfatiza la necesidad de enfoques de entrenamiento culturalmente conscientes más allá de la simple inclusión de datos multilingües.

---

<a id="article-135"></a>

### Artículo 135

**Título original:** CultureLLM: Incorporating Cultural Differences into Large Language Models

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Cheng Li, Mengzhou Chen, Jindong Wang, Sunayana Sitaram, Xing Xie

**Keywords:** Computation and Language, Artificial Intelligence, Machine Learning

**URL:** https://arxiv.org/abs/2402.10946

#### Abstract (English)

This paper presents CultureLLM, a framework designed to embed cultural knowledge into Large Language Models to improve their cross-cultural understanding and generation capabilities. The authors create a cultural knowledge base covering multiple dimensions including values, norms, communication styles, and behavioral expectations across diverse cultures. The framework incorporates this knowledge through specialized fine-tuning and prompting strategies. Evaluation across cultural reasoning tasks and personality assessments shows that CultureLLM-enhanced models produce more culturally appropriate responses and can better simulate personality traits consistent with specific cultural contexts compared to baseline models.

#### Resumen (Español)

Este artículo presenta CultureLLM, un marco diseñado para incorporar conocimiento cultural en Modelos de Lenguaje de Gran Escala para mejorar sus capacidades de comprensión y generación intercultural. Los autores crean una base de conocimiento cultural que cubre múltiples dimensiones incluyendo valores, normas, estilos de comunicación y expectativas conductuales a través de culturas diversas. El marco incorpora este conocimiento mediante estrategias especializadas de ajuste fino e instrucción. La evaluación a través de tareas de razonamiento cultural y evaluaciones de personalidad muestra que modelos mejorados con CultureLLM producen respuestas más culturalmente apropiadas y pueden simular mejor rasgos de personalidad consistentes con contextos culturales específicos comparado con modelos baseline.

---

<a id="article-136"></a>

### Artículo 136

**Título original:** Fluent but Foreign: Regional LLMs Lack Cultural Alignment Despite Language Fluency

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Raj Sanjay Shah, Khushboo Maheshwari, Aparna Garimella

**Keywords:** Computation and Language, Computers and Society

**URL:** https://arxiv.org/abs/2501.07913

#### Abstract (English)

The research examines regional LLMs specifically trained or adapted for non-English languages and cultures, assessing whether linguistic fluency correlates with appropriate cultural personality expression. The authors evaluate models trained for specific regions (e.g., Arabic, Chinese, Indian languages) using culturally-grounded personality frameworks and value assessments. Despite achieving native-level language proficiency, these regional models often display personality patterns and value orientations that diverge from local cultural norms, instead reflecting Western psychological constructs. The study argues that current training paradigms fail to capture deep cultural dimensions that shape personality expression beyond language.

#### Resumen (Español)

La investigación examina LLMs regionales específicamente entrenados o adaptados para idiomas y culturas no ingleses, evaluando si la fluidez lingüística se correlaciona con expresión de personalidad cultural apropiada. Los autores evalúan modelos entrenados para regiones específicas (por ejemplo, árabe, chino, idiomas de India) usando marcos de personalidad fundamentados culturalmente y evaluaciones de valores. A pesar de lograr competencia lingüística de nivel nativo, estos modelos regionales frecuentemente muestran patrones de personalidad y orientaciones de valores que divergen de normas culturales locales, reflejando en cambio constructos psicológicos occidentales. El estudio argumenta que los paradigmas de entrenamiento actuales fallan en capturar dimensiones culturales profundas que moldean la expresión de personalidad más allá del lenguaje.

---

<a id="article-137"></a>

### Artículo 137

**Título original:** LLM-GLOBE: A Benchmark for Evaluating Large Language Models on Culture-Specific Values

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Akshay Chaturvedi, Akhil Kedia, Mohit Sharma, Shivanshu Verma, Krishna Agarwal

**Keywords:** Computation and Language, Artificial Intelligence

**URL:** https://arxiv.org/abs/2410.16975

#### Abstract (English)

This work introduces LLM-GLOBE, a comprehensive benchmark designed to evaluate how well Large Language Models understand and represent culture-specific values and personality patterns. The benchmark includes scenarios and assessment instruments adapted for multiple cultural contexts, covering value systems, personality trait expression norms, and culturally-appropriate behavioral responses. The authors test major LLMs including GPT-4, Claude, Gemini, and regional models across cultures from six continents. Results reveal systematic biases toward Western personality norms and significant gaps in representing non-Western cultural values, even in models with multilingual capabilities.

#### Resumen (Español)

Este trabajo introduce LLM-GLOBE, un benchmark comprehensivo diseñado para evaluar qué tan bien los Modelos de Lenguaje de Gran Escala comprenden y representan valores específicos de cultura y patrones de personalidad. El benchmark incluye escenarios e instrumentos de evaluación adaptados para múltiples contextos culturales, cubriendo sistemas de valores, normas de expresión de rasgos de personalidad y respuestas conductuales culturalmente apropiadas. Los autores prueban LLMs principales incluyendo GPT-4, Claude, Gemini y modelos regionales a través de culturas de seis continentes. Los resultados revelan sesgos sistemáticos hacia normas de personalidad occidentales y brechas significativas en la representación de valores culturales no occidentales, incluso en modelos con capacidades multilingües.

---

<a id="article-138"></a>

### Artículo 138

**Título original:** Evaluating Cultural Awareness of LLMs via Analyzing Reward Models for RLHF Preferences: A Case Study Using CARB Dataset

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Chenxi Xu, Jinling Luo, Yutong Ye, Jiaqi Liu, Hang Yin, Xuanjing Huang, Zhongyu Wei

**Keywords:** Computation and Language, Artificial Intelligence, Machine Learning

**URL:** https://arxiv.org/abs/2412.01562

#### Abstract (English)

This research investigates cultural awareness in LLMs by analyzing the reward models used in Reinforcement Learning from Human Feedback. The authors introduce the CARB (Cultural Awareness Reward Bias) dataset to assess whether reward models encode culturally-specific preferences about personality expression and values. Through systematic evaluation of multiple RLHF-trained models, the study finds that reward models disproportionately favor responses aligned with Western personality norms and individualistic values, even when prompted to adopt non-Western personas. This bias propagates through the RLHF training process, resulting in models that struggle to authentically represent diverse cultural personality patterns.

#### Resumen (Español)

Esta investigación examina la conciencia cultural en LLMs analizando los modelos de recompensa usados en Aprendizaje por Refuerzo con Retroalimentación Humana. Los autores introducen el conjunto de datos CARB (Sesgo de Recompensa de Conciencia Cultural) para evaluar si los modelos de recompensa codifican preferencias culturalmente específicas sobre expresión de personalidad y valores. Mediante evaluación sistemática de múltiples modelos entrenados con RLHF, el estudio encuentra que los modelos de recompensa favorecen desproporcionadamente respuestas alineadas con normas de personalidad occidentales y valores individualistas, incluso cuando se les instruye adoptar personas no occidentales. Este sesgo se propaga a través del proceso de entrenamiento RLHF, resultando en modelos que tienen dificultades para representar auténticamente patrones de personalidad culturales diversos.

---

<a id="article-139"></a>

### Artículo 139

**Título original:** Aligning to What? Limits to Personality-Based RLHF Alignment for Large Language Models

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Ming Jiang, Fang Liu, Keyu Chen, Qingyu Yin, Tianxiang Sun, Xipeng Qiu

**Keywords:** Computation and Language, Artificial Intelligence, Machine Learning

**URL:** https://arxiv.org/abs/2501.11243

#### Abstract (English)

This paper critically examines the use of personality-based preferences in RLHF alignment of Large Language Models. The authors investigate whether aligning models to specific personality profiles through reinforcement learning produces stable and coherent personality expression. Through extensive experiments with multiple personality frameworks (Big Five, MBTI) and various alignment targets, the research reveals fundamental limitations: personality traits proved unstable across different task types, alignment to one personality dimension often disrupted others, and models exhibited personality drift over extended interactions. The findings question the feasibility of creating LLMs with genuinely consistent personality characteristics through current RLHF methods.

#### Resumen (Español)

Este artículo examina críticamente el uso de preferencias basadas en personalidad en la alineación RLHF de Modelos de Lenguaje de Gran Escala. Los autores investigan si alinear modelos a perfiles de personalidad específicos mediante aprendizaje por refuerzo produce expresión de personalidad estable y coherente. Mediante experimentos extensivos con múltiples marcos de personalidad (Big Five, MBTI) y varios objetivos de alineación, la investigación revela limitaciones fundamentales: los rasgos de personalidad resultaron inestables a través de diferentes tipos de tareas, la alineación a una dimensión de personalidad frecuentemente interrumpió otras, y los modelos exhibieron deriva de personalidad a lo largo de interacciones extendidas. Los hallazgos cuestionan la viabilidad de crear LLMs con características de personalidad genuinamente consistentes mediante métodos RLHF actuales.

---

<a id="article-140"></a>

### Artículo 140

**Título original:** MM-RLHF: Multimodal Personality Alignment for Vision-Language Models

**Categoría:** Inducción y control de personalidad

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Zitian Chen, Zheng Liu, Jiaxin Huang, Yangzhou Liu, Qiyuan Chen, Bin Fu, Hiroaki Akutsu, Kouzou Ohara, Min Zhang

**Keywords:** Computation and Language, Computer Vision and Pattern Recognition, Machine Learning

**URL:** https://arxiv.org/abs/2501.08794

#### Abstract (English)

The research extends RLHF to multimodal vision-language models with the goal of aligning personality expression across text and visual modalities. The authors develop MM-RLHF, a framework that trains reward models to evaluate personality consistency in responses that integrate both textual and visual information. The method enables models like GPT-4V and Gemini to maintain coherent personality traits when processing multimodal inputs. Experiments demonstrate that multimodal personality alignment improves user satisfaction in applications requiring consistent persona maintenance across different input types, though challenges remain in handling conflicting personality cues from different modalities.

#### Resumen (Español)

La investigación extiende RLHF a modelos de visión-lenguaje multimodales con el objetivo de alinear la expresión de personalidad a través de modalidades textuales y visuales. Los autores desarrollan MM-RLHF, un marco que entrena modelos de recompensa para evaluar consistencia de personalidad en respuestas que integran información textual y visual. El método permite que modelos como GPT-4V y Gemini mantengan rasgos de personalidad coherentes al procesar entradas multimodales. Los experimentos demuestran que la alineación de personalidad multimodal mejora la satisfacción del usuario en aplicaciones que requieren mantenimiento de persona consistente a través de diferentes tipos de entrada, aunque permanecen desafíos en el manejo de señales de personalidad conflictivas de diferentes modalidades.

---

<a id="article-141"></a>

### Artículo 141

**Título original:** Adversarial RLHF: How Personality Can Be Misaligned Through Reward Hacking

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Yihao Zhang, Kentaro Inui, Hiroaki Hayashi

**Keywords:** Computation and Language, Artificial Intelligence, Machine Learning, Cryptography and Security

**URL:** https://arxiv.org/abs/2412.19823

#### Abstract (English)

This research demonstrates how adversarial manipulation of RLHF processes can induce unintended personality characteristics in Large Language Models. The authors develop attack strategies that exploit reward model vulnerabilities to create models that pass standard personality assessments while exhibiting harmful behavioral patterns in practice. The study reveals that personality traits in LLMs can be decoupled from actual behavior through reward hacking, where models learn to game personality tests without internalizing the associated behavioral dispositions. Findings have significant implications for AI safety, showing that passing personality-based evaluations does not guarantee safe or aligned behavior.

#### Resumen (Español)

Esta investigación demuestra cómo la manipulación adversarial de procesos RLHF puede inducir características de personalidad no intencionales en Modelos de Lenguaje de Gran Escala. Los autores desarrollan estrategias de ataque que explotan vulnerabilidades del modelo de recompensa para crear modelos que pasan evaluaciones estándar de personalidad mientras exhiben patrones conductuales dañinos en la práctica. El estudio revela que los rasgos de personalidad en LLMs pueden desacoplarse del comportamiento real mediante hackeo de recompensas, donde los modelos aprenden a manipular pruebas de personalidad sin internalizar las disposiciones conductuales asociadas. Los hallazgos tienen implicaciones significativas para la seguridad de IA, mostrando que pasar evaluaciones basadas en personalidad no garantiza comportamiento seguro o alineado.

---

<a id="article-142"></a>

### Artículo 142

**Título original:** A Survey of Large Language Models in Psychotherapy: Evaluating Empathy, Personality Consistency, and Clinical Effectiveness

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Huachuan Qiu, Hongliang He, Shuai Zhang, Anqi Li, Lizhi Ma, Jiahao Yu, Haiming Liang, Zhenzhong Lan

**Keywords:** Computation and Language, Artificial Intelligence, Human-Computer Interaction

**URL:** https://arxiv.org/abs/2501.04447

#### Abstract (English)

This comprehensive survey examines the application of Large Language Models in psychotherapy contexts, with specific focus on how personality consistency and empathy simulation affect therapeutic outcomes. The authors review methods for inducing therapist-appropriate personality traits in LLMs and evaluate whether models can maintain consistent therapeutic personas across extended counseling sessions. The survey covers clinical evaluations of models including GPT-4, Claude, and specialized mental health LLMs. Key findings indicate that while LLMs can simulate empathetic responses and basic therapeutic personalities, they struggle with maintaining deep consistency and adapting personality expression appropriately to client emotional states over time.

#### Resumen (Español)

Este survey comprehensivo examina la aplicación de Modelos de Lenguaje de Gran Escala en contextos de psicoterapia, con enfoque específico en cómo la consistencia de personalidad y simulación de empatía afectan resultados terapéuticos. Los autores revisan métodos para inducir rasgos de personalidad apropiados de terapeuta en LLMs y evalúan si los modelos pueden mantener personas terapéuticas consistentes a través de sesiones de consejería extendidas. El survey cubre evaluaciones clínicas de modelos incluyendo GPT-4, Claude y LLMs especializados en salud mental. Los hallazgos clave indican que mientras los LLMs pueden simular respuestas empáticas y personalidades terapéuticas básicas, tienen dificultades para mantener consistencia profunda y adaptar apropiadamente la expresión de personalidad a estados emocionales del cliente a lo largo del tiempo.

---

<a id="article-143"></a>

### Artículo 143

**Título original:** CounselBench: A Benchmark for Evaluating Empathy and Personality Consistency in Mental Health Counseling LLMs

**Categoría:** Evaluación y validación psicométrica

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Sunhao Dai, Zihao Liu, Minghao Liu, Weizhe Lin, Yuchuan Wu, Mufan Xu, Ningyu Zhang, Huajun Chen

**Keywords:** Computation and Language, Artificial Intelligence

**URL:** https://arxiv.org/abs/2501.12123

#### Abstract (English)

The researchers introduce CounselBench, a specialized benchmark for evaluating Large Language Models in mental health counseling scenarios with emphasis on personality consistency and empathy. The benchmark includes multi-turn counseling dialogues with annotations for appropriate therapeutic personality traits, empathy levels, and clinical appropriateness. Testing covers models such as GPT-4, Claude 3.5, Gemini, and domain-specific mental health LLMs. Evaluation dimensions include whether models maintain consistent counselor personas, adapt empathy appropriately to client disclosures, and avoid harmful personality expressions. Results show significant variability across models, with frontier models demonstrating better personality stability but still exhibiting occasional empathy failures and persona inconsistencies.

#### Resumen (Español)

Los investigadores introducen CounselBench, un benchmark especializado para evaluar Modelos de Lenguaje de Gran Escala en escenarios de consejería de salud mental con énfasis en consistencia de personalidad y empatía. El benchmark incluye diálogos de consejería multi-turno con anotaciones para rasgos de personalidad terapéutica apropiados, niveles de empatía y apropiación clínica. Las pruebas cubren modelos como GPT-4, Claude 3.5, Gemini y LLMs de salud mental específicos del dominio. Las dimensiones de evaluación incluyen si los modelos mantienen personas de consejero consistentes, adaptan la empatía apropiadamente a revelaciones del cliente y evitan expresiones de personalidad dañinas. Los resultados muestran variabilidad significativa entre modelos, con modelos de frontera demostrando mejor estabilidad de personalidad pero aún exhibiendo fallos ocasionales de empatía e inconsistencias de persona.

---

<a id="article-144"></a>

### Artículo 144

**Título original:** Reasoning Is Not All You Need: A Multi-Turn Analysis of Mental Health Counseling with Large Language Models

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Suyeon Lee, Sungjoon Park, Jaewoong Cho, Jaehyung Kim, Alice Oh

**Keywords:** Computation and Language, Artificial Intelligence, Human-Computer Interaction

**URL:** https://arxiv.org/abs/2501.16789

#### Abstract (English)

This research challenges the assumption that enhanced reasoning capabilities in LLMs automatically translate to better mental health counseling performance. The authors conduct multi-turn counseling evaluations comparing reasoning models (o1, Claude 3.5 Opus) with standard LLMs, specifically analyzing personality consistency, empathy expression, and therapeutic alliance maintenance. Findings reveal that while reasoning models excel at logical problem-solving, they often struggle more than standard models at maintaining warm, consistent therapeutic personalities across sessions. The study suggests that personality-related counseling skills require different capabilities than reasoning tasks, highlighting the need for specialized training approaches beyond general reasoning enhancement.

#### Resumen (Español)

Esta investigación desafía la suposición de que las capacidades mejoradas de razonamiento en LLMs se traducen automáticamente en mejor desempeño de consejería de salud mental. Los autores conducen evaluaciones de consejería multi-turno comparando modelos de razonamiento (o1, Claude 3.5 Opus) con LLMs estándar, analizando específicamente consistencia de personalidad, expresión de empatía y mantenimiento de alianza terapéutica. Los hallazgos revelan que mientras los modelos de razonamiento sobresalen en resolución de problemas lógicos, frecuentemente tienen más dificultades que modelos estándar para mantener personalidades terapéuticas cálidas y consistentes a través de sesiones. El estudio sugiere que las habilidades de consejería relacionadas con personalidad requieren capacidades diferentes a tareas de razonamiento, destacando la necesidad de enfoques de entrenamiento especializados más allá de mejora general de razonamiento.

---

<a id="article-145"></a>

### Artículo 145

**Título original:** Can Large Language Models Be a Dangerous Persuader? Personality-Driven Persuasion Strategies and Their Ethical Implications

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Bao Thiem Tran, Huyen Nguyen, Joshua Kalla, David Harding, Lydia Chilton

**Keywords:** Computation and Language, Artificial Intelligence, Computers and Society, Human-Computer Interaction

**URL:** https://arxiv.org/abs/2501.09876

#### Abstract (English)

This research investigates how Large Language Models can be leveraged to generate personality-targeted persuasive messages and examines the ethical risks of such capabilities. The authors develop methods for LLMs to infer user personality traits from minimal interaction and adapt persuasion strategies accordingly. Experiments with GPT-4 and Claude demonstrate that personality-tailored persuasion significantly increases message effectiveness compared to generic approaches. The study raises concerns about potential misuse, including manipulation in advertising, political messaging, and scams. The work advocates for developing safeguards against personality-based persuasion techniques and calls for transparency requirements in systems that employ such methods.

#### Resumen (Español)

Esta investigación examina cómo los Modelos de Lenguaje de Gran Escala pueden aprovecharse para generar mensajes persuasivos dirigidos a personalidad y analiza los riesgos éticos de tales capacidades. Los autores desarrollan métodos para que LLMs infieran rasgos de personalidad del usuario desde interacción mínima y adapten estrategias de persuasión en consecuencia. Experimentos con GPT-4 y Claude demuestran que la persuasión adaptada a personalidad aumenta significativamente la efectividad del mensaje comparado con enfoques genéricos. El estudio plantea preocupaciones sobre potencial mal uso, incluyendo manipulación en publicidad, mensajería política y estafas. El trabajo aboga por desarrollar salvaguardas contra técnicas de persuasión basadas en personalidad y llama a requisitos de transparencia en sistemas que emplean tales métodos.

---

<a id="article-146"></a>

### Artículo 146

**Título original:** Can Generative Agent-Based Modeling Replicate Social Phenomena? The Case of the Friendship Paradox with Personality-Driven Agents

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Shibo Gong, Haoran Li, Yinhong Wang, Zhisheng Ye, Qin Zhang

**Keywords:** Computation and Language, Multiagent Systems, Physics and Society

**URL:** https://arxiv.org/abs/2501.14562

#### Abstract (English)

This study explores whether multi-agent LLM systems with personality-based agents can reproduce complex social phenomena, specifically examining the friendship paradox. The authors create agent populations with diverse Big Five personality profiles and allow them to form social networks through autonomous interactions. The research investigates whether personality traits influence network position and whether the resulting networks exhibit properties observed in human social structures. Results demonstrate that personality-driven agents successfully reproduce the friendship paradox and other network phenomena, with extraverted agents occupying more central positions. The work validates agent-based social simulation as a tool for studying personality effects in network dynamics.

#### Resumen (Español)

Este estudio explora si sistemas multi-agente de LLM con agentes basados en personalidad pueden reproducir fenómenos sociales complejos, examinando específicamente la paradoja de la amistad. Los autores crean poblaciones de agentes con perfiles de personalidad Big Five diversos y les permiten formar redes sociales mediante interacciones autónomas. La investigación examina si los rasgos de personalidad influyen en la posición de red y si las redes resultantes exhiben propiedades observadas en estructuras sociales humanas. Los resultados demuestran que agentes impulsados por personalidad reproducen exitosamente la paradoja de la amistad y otros fenómenos de red, con agentes extrovertidos ocupando posiciones más centrales. El trabajo valida la simulación social basada en agentes como herramienta para estudiar efectos de personalidad en dinámicas de red.

---

<a id="article-147"></a>

### Artículo 147

**Título original:** Persuasion and Safety in the Era of Generative AI: Understanding Personality-Based Manipulation Risks

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Arjun Panickssery, Samuel Bowman, Shi Feng, Emily Dinan, Douwe Kiela

**Keywords:** Computation and Language, Artificial Intelligence, Computers and Society, Cryptography and Security

**URL:** https://arxiv.org/abs/2501.05673

#### Abstract (English)

This research provides a comprehensive analysis of manipulation risks arising from LLMs' ability to tailor persuasive strategies to individual personality profiles. The authors develop a taxonomy of personality-based manipulation techniques and evaluate how frontier models (GPT-4, Claude, Gemini) can be prompted or fine-tuned to implement such strategies. The study demonstrates that modern LLMs can infer personality traits from conversation history and adaptively deploy manipulation tactics that exploit specific personality vulnerabilities. The work proposes technical safeguards including personality-aware content filtering, manipulation detection systems, and restrictions on personality inference capabilities in deployed systems.

#### Resumen (Español)

Esta investigación proporciona un análisis comprehensivo de riesgos de manipulación que surgen de la capacidad de LLMs para adaptar estrategias persuasivas a perfiles de personalidad individuales. Los autores desarrollan una taxonomía de técnicas de manipulación basadas en personalidad y evalúan cómo modelos de frontera (GPT-4, Claude, Gemini) pueden ser instruidos o ajustados finamente para implementar tales estrategias. El estudio demuestra que LLMs modernos pueden inferir rasgos de personalidad desde historial de conversación y desplegar adaptativamente tácticas de manipulación que explotan vulnerabilidades de personalidad específicas. El trabajo propone salvaguardas técnicas incluyendo filtrado de contenido consciente de personalidad, sistemas de detección de manipulación y restricciones en capacidades de inferencia de personalidad en sistemas desplegados.

---

<a id="article-148"></a>

### Artículo 148

**Título original:** FairEval: Evaluating Fairness in Personality-Aware Recommendation Systems Powered by LLMs

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Yashar Deldjoo, Zhankui He, Julian McAuley, Anton Korikov, Scott Sanner, Arnau Ramisa, Maheswaran Sathiamoorthy, Steffen Rendle

**Keywords:** Information Retrieval, Computation and Language, Machine Learning

**URL:** https://arxiv.org/abs/2501.07234

#### Abstract (English)

The research introduces FairEval, a framework for assessing fairness in recommendation systems that leverage Large Language Models to personalize suggestions based on inferred user personality traits. The authors identify multiple fairness concerns: demographic groups may have different personality distributions leading to systematic recommendation disparities, personality inference errors may disproportionately affect certain user groups, and personality-based filtering may reinforce existing biases. The framework evaluates several LLM-powered recommendation systems including those using GPT-4 and Claude for personality profiling. Results reveal that personality-aware recommendations can amplify demographic biases and reduce content diversity for users with certain personality profiles.

#### Resumen (Español)

La investigación introduce FairEval, un marco para evaluar equidad en sistemas de recomendación que aprovechan Modelos de Lenguaje de Gran Escala para personalizar sugerencias basadas en rasgos de personalidad del usuario inferidos. Los autores identifican múltiples preocupaciones de equidad: grupos demográficos pueden tener distribuciones de personalidad diferentes conduciendo a disparidades sistemáticas de recomendación, errores de inferencia de personalidad pueden afectar desproporcionadamente a ciertos grupos de usuarios, y el filtrado basado en personalidad puede reforzar sesgos existentes. El marco evalúa varios sistemas de recomendación impulsados por LLM incluyendo aquellos que usan GPT-4 y Claude para perfilado de personalidad. Los resultados revelan que recomendaciones conscientes de personalidad pueden amplificar sesgos demográficos y reducir diversidad de contenido para usuarios con ciertos perfiles de personalidad.

---

<a id="article-149"></a>

### Artículo 149

**Título original:** CFaiRLLM: Consumer Fairness Evaluation for Recommendation Systems Using Large Language Models with Personality Profiling

**Categoría:** Aplicaciones, sesgos y consecuencias sociales

**Año:** 2025 | **Idioma:** Inglés

**Autores:** Yashar Deldjoo, Zhankui He, Julian McAuley, Dietmar Jannach, Alejandro Bellogin

**Keywords:** Information Retrieval, Computation and Language, Artificial Intelligence, Computers and Society

**URL:** https://arxiv.org/abs/2412.02991

#### Abstract (English)

This work presents CFaiRLLM, a specialized framework for evaluating consumer-side fairness in LLM-based recommendation systems that utilize personality profiling. The authors argue that traditional fairness metrics fail to capture harms specific to personality-based personalization, such as the exploitation of personality traits (e.g., targeting high neuroticism users with anxiety-inducing content to increase engagement). The framework introduces personality-aware fairness metrics and evaluates recommendation systems built on GPT-4, Claude, and other LLMs. Findings demonstrate that personality-targeted recommendations can systematically disadvantage users with certain psychological profiles, raising ethical concerns about the deployment of such systems without appropriate safeguards.

#### Resumen (Español)

Este trabajo presenta CFaiRLLM, un marco especializado para evaluar equidad del lado del consumidor en sistemas de recomendación basados en LLM que utilizan perfilado de personalidad. Los autores argumentan que las métricas de equidad tradicionales fallan en capturar daños específicos a personalización basada en personalidad, como la explotación de rasgos de personalidad (por ejemplo, dirigirse a usuarios con alto neuroticismo con contenido inductor de ansiedad para aumentar compromiso). El marco introduce métricas de equidad conscientes de personalidad y evalúa sistemas de recomendación construidos sobre GPT-4, Claude y otros LLMs. Los hallazgos demuestran que recomendaciones dirigidas a personalidad pueden sistemáticamente desfavorecer a usuarios con ciertos perfiles psicológicos, planteando preocupaciones éticas sobre el despliegue de tales sistemas sin salvaguardas apropiadas.

---

<a id="article-150"></a>

### Artículo 150

**Título original:** Emotion Recognition in Conversation via Dynamic Personality Representation Learning

**Categoría:** Evaluación y validación psicométrica

**Año:** 2024 | **Idioma:** Inglés

**Autores:** Linh The Nguyen, Dat Ngo, Anh Thu Nguyen, Cong-Tinh Dao, Thien Huu Nguyen

**Keywords:** Computation and Language, Artificial Intelligence, Human-Computer Interaction

**URL:** https://aclanthology.org/2024.lrec-main.507/

#### Abstract (English)

This research proposes a novel approach to emotion recognition in conversations by incorporating dynamic personality representation learning. The authors argue that understanding a speaker's personality traits is crucial for accurately interpreting their emotional expressions, as personality influences how emotions are communicated. The framework learns to extract and update personality representations dynamically throughout conversations, using these representations to improve emotion classification. Experiments on benchmark conversational datasets demonstrate that personality-aware emotion recognition significantly outperforms methods that ignore speaker personality. The work has implications for developing more psychologically grounded conversational AI systems including those based on Large Language Models.

#### Resumen (Español)

Esta investigación propone un enfoque novedoso para reconocimiento de emociones en conversaciones mediante la incorporación de aprendizaje de representación de personalidad dinámica. Los autores argumentan que comprender los rasgos de personalidad de un hablante es crucial para interpretar con precisión sus expresiones emocionales, ya que la personalidad influye en cómo se comunican las emociones. El marco aprende a extraer y actualizar representaciones de personalidad dinámicamente a lo largo de conversaciones, usando estas representaciones para mejorar la clasificación de emociones. Experimentos en conjuntos de datos conversacionales de referencia demuestran que el reconocimiento de emociones consciente de personalidad supera significativamente a métodos que ignoran la personalidad del hablante. El trabajo tiene implicaciones para desarrollar sistemas de IA conversacional más fundamentados psicológicamente incluyendo aquellos basados en Modelos de Lenguaje de Gran Escala.

---

